{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Network Cleaning\n",
    "\n",
    "Having extracted the raw network from the .osm.pbf, we now implement the standard process to topologically clean / simplify the network, per standard GOSTnets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the usual suspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peartree version: 0.6.1 \n",
      "networkx version: 2.3 \n",
      "matplotlib version: 3.0.3 \n",
      "osmnx version: 0.9 \n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import os, sys, time\n",
    "import pandas as pd\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST_PublicGoods\\GOSTNets\\GOSTNets')\n",
    "import GOSTnet as gn\n",
    "import importlib\n",
    "importlib.reload(gn)\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "importlib.reload(ox)\n",
    "from shapely.ops import unary_union\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import LineString, MultiLineString, Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This read in process is specific to Yemen, which used the originally developed 'extract from a combo .csv' process. Newer implmentations (See: Sierra Leone, GOSTnets examples folder) read in directly from a saved gpickle. This is the preferred technique as it saves a lot of faff. Nonetheless, the below works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def InitialReadIn(fpath, country):\n",
    "    \n",
    "    # define the precis filename\n",
    "    ffile = r'%s_combo.csv' % country\n",
    "    \n",
    "    # read in the combo dataframe, rename as edges_1\n",
    "    edges_1 = pd.read_csv(os.path.join(fpath, ffile))\n",
    "\n",
    "    # copy\n",
    "    edges = edges_1.copy()\n",
    "\n",
    "    # the list of nodes will be all the unique values in the u and v columns, by definition (start and end of each edge)\n",
    "    node_bunch = list(set(list(edges['u']) + list(edges['v'])))\n",
    "\n",
    "    # Write a function for converting the rows into edges that a nx graph will accept (i.e. in format (u,v,data))\n",
    "    def convert(x):\n",
    "        # obviously the start (u) will be equal to ... u\n",
    "        u = x.u\n",
    "        v = x.v\n",
    "        \n",
    "        # here we load the attributes in the DataFrame we want to retain on the edges in the graph\n",
    "        data = {'Wkt':loads(x.Wkt),\n",
    "               'id':x.id,\n",
    "               'infra_type':x.infra_type, \n",
    "               'osm_id':x.osm_id,\n",
    "               'country': x.country,\n",
    "               'key': x.key, \n",
    "               'length':x.length}\n",
    "        \n",
    "        # return an object in the correct edge format \n",
    "        return (u, v, data)\n",
    "    \n",
    "    # apply this function to every row in the edges DF\n",
    "    edge_bunch = edges.apply(lambda x: convert(x), axis = 1).tolist()\n",
    "    \n",
    "    # open a blank multidigraph\n",
    "    G = nx.MultiDiGraph()\n",
    "    \n",
    "    # add the nodes first, then the edges\n",
    "    G.add_nodes_from(node_bunch)\n",
    "    G.add_edges_from(edge_bunch)\n",
    "    \n",
    "    # for each node, split out the x and y coordinates (see Step 1 for why this works)\n",
    "    for u, data in G.nodes(data = True):\n",
    "        q = tuple(float(x) for x in u[1:-1].split(','))\n",
    "        data['x'] = q[0]\n",
    "        data['y'] = q[1]\n",
    "\n",
    "    # relabel node IDs as integers for simplicity's sake\n",
    "    G = nx.convert_node_labels_to_integers(G)\n",
    "\n",
    "    # make a GeoDataFrame of the nodes, save down\n",
    "    gdfnodes = gn.node_gdf_from_graph(G)\n",
    "    gdfnodes.to_csv(os.path.join(wpath, '%s_pre_processing_nodes.csv' % country))\n",
    "    \n",
    "    # make a GeoDataFrame of the edges, save down\n",
    "    gdfedges = gn.edge_gdf_from_graph(G, geom_col = 'Wkt')\n",
    "    gdfedges.to_csv(os.path.join(wpath, '%s_pre_processing_edges.csv' % country))\n",
    "    \n",
    "    # we shouldn't have lost any edges along the way. Check this here!    \n",
    "    print('These two should equal: A) length of final df: %s | B) length of original df: %s' % (len(gdfedges), len(edges_1)))\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having loaded the raw data into a nx MultiDiGraph type object, we can now proceed with the standard GOSTnets cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CleanNetwork(G, wpath, country, UTM, WGS = {'init': 'epsg:4326'}, junctdist = 50, verbose = False):\n",
    "    \n",
    "    # Squeezes clusters of nodes down to a single node if they are within the snapping tolerance\n",
    "    a = gn.simplify_junctions(G, UTM, WGS, junctdist)\n",
    "\n",
    "    # ensures all streets are two-way\n",
    "    a = gn.add_missing_reflected_edges(a)\n",
    "    \n",
    "    #save progress\n",
    "    if verbose is True: \n",
    "        gn.save(a, 'a', wpath)\n",
    "    \n",
    "    # Finds and deletes interstital nodes based on node degree\n",
    "    b = gn.custom_simplify(a)\n",
    "    \n",
    "    # rectify geometry\n",
    "    for u, v, data in b.edges(data = True):\n",
    "        if type(data['Wkt']) == list:\n",
    "                data['Wkt'] = gn.unbundle_geometry(data['Wkt'])\n",
    "    \n",
    "    # save progress\n",
    "    if verbose is True: \n",
    "        gn.save(b, 'b', wpath)\n",
    "    \n",
    "    # For some reason CustomSimplify doesn't return a MultiDiGraph. Fix that here\n",
    "    c = gn.convert_to_MultiDiGraph(b)\n",
    "\n",
    "    # This is the most controversial function - removes duplicated edges. This takes care of two-lane but separate highways, BUT\n",
    "    # destroys internal loops within roads. Can be run with or without this line\n",
    "    c = gn.remove_duplicate_edges(c)\n",
    "\n",
    "    # Run this again after removing duplicated edges\n",
    "    c = gn.custom_simplify(c)\n",
    "\n",
    "    # Ensure all remaining edges are duplicated (two-way streets)\n",
    "    c = gn.add_missing_reflected_edges(c)\n",
    "    \n",
    "    # save final\n",
    "    gn.save(c, '%s_processed' % country, wpath)\n",
    "    \n",
    "    print('Edge reduction: %s to %s (%d percent)' % (G.number_of_edges(), \n",
    "                                               c.number_of_edges(), \n",
    "                                               ((G.number_of_edges() - c.number_of_edges())/G.number_of_edges()*100)))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above two cells define our two main processes - loading the graph and cleaning the graph. \n",
    "\n",
    "We go ahead and run this for Yemen below. Note that you can run multiple countries at a time if needed using this loop formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- processing for: YEM ---\n",
      "\n",
      "start: Tue Apr 30 14:29:47 2019\n",
      "\n",
      "Outputs can be found at: C:\\Users\\charl\\Documents\\GOST\\Yemen\\YEM\\Round 3\\output\n",
      "\n",
      "These two should equal: A) length of final df: 154550 | B) length of original df: 154550\n",
      "154538\n",
      "308119\n",
      "293625\n",
      "147581\n",
      "293608\n",
      "Edge reduction: 154550 to 293608 (-89 percent)\n",
      "\n",
      "end: Tue Apr 30 14:57:31 2019\n",
      "\n",
      "--- processing complete for: YEM ---\n"
     ]
    }
   ],
   "source": [
    "# set UTM zone for measuring distances (Relevant for junction collapsing)\n",
    "UTMZs = {'YEM':32638}\n",
    "\n",
    "# set the base projection\n",
    "WGS = {'init': 'epsg:4326'}\n",
    "\n",
    "# add as many countries as you have networks to be cleaned; here, we have 1\n",
    "countries = ['YEM']\n",
    "\n",
    "# set the filepath\n",
    "fpath = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\YEM\\Round 3'\n",
    "\n",
    "# work through the countries list\n",
    "for country in countries:\n",
    "    \n",
    "    print('\\n--- processing for: %s ---\\n' % country)\n",
    "    print('start: %s\\n' % time.ctime())\n",
    "    \n",
    "    # set a write path for the outputs, and make it if it doesn't already exist\n",
    "    wpath = os.path.join(fpath, r'output' )\n",
    "    if not os.path.exists(wpath):\n",
    "        os.mkdir(wpath)\n",
    "    \n",
    "    print('Outputs can be found at: %s\\n' % (wpath))\n",
    "        \n",
    "    # make a string in the format GeoPandas will accept for reprojection\n",
    "    UTM = {'init': 'epsg:%d' % UTMZs[country]}\n",
    "    \n",
    "    # read that graph in...\n",
    "    G = InitialReadIn(fpath, country)\n",
    "    \n",
    "    #...and clean that graph!!\n",
    "    G = CleanNetwork(G, wpath, country, UTM, WGS, 0.5, verbose = False)\n",
    "    print('\\nend: %s' % time.ctime())\n",
    "    print('\\n--- processing complete for: %s ---' % country)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
