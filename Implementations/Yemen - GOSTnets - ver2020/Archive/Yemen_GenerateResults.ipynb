{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peartree version: 0.6.0 \n",
      "networkx version: 2.2 \n",
      "matplotlib version: 2.2.2 \n",
      "osmnx version: 0.8.2 \n",
      "peartree version: 0.6.0 \n",
      "networkx version: 2.2 \n",
      "matplotlib version: 2.2.2 \n",
      "osmnx version: 0.8.2 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST_PublicGoods\\GOSTNets\\GOSTNets')\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST')\n",
    "import GOSTnet as gn\n",
    "import importlib\n",
    "importlib.reload(gn)\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from shapely.wkt import loads\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepth = r'C:\\Users\\charl\\Documents\\GOST\\Yemen'\n",
    "pth = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\graphtool'\n",
    "net_pth = pth\n",
    "pckle = r'conflict_adj.pickle'\n",
    "walk_speed = 4 \n",
    "WGS = {'init':'epsg:4326'}\n",
    "measure_crs = {'init':'epsg:32638'}\n",
    "date = 'January24th'\n",
    "subset = r'HeRAMS Hospitals %s' % date\n",
    "OD_name = r'outputOD_%s.csv' % date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import All-Destination OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "OD = pd.read_csv(os.path.join(pth, OD_name))\n",
    "OD = OD.rename(columns = {'Unnamed: 0':'O_ID'})\n",
    "OD = OD.set_index('O_ID')\n",
    "OD = OD.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36158, 4114)\n"
     ]
    }
   ],
   "source": [
    "OD_original = OD\n",
    "print(OD_original.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Subset to Accepted Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Latitude', 'Longitude', 'Year', 'FacilityID',\n",
      "       'Governorate', 'District', 'Facility Type', 'Functionality2016',\n",
      "       'Damaged 2016', 'Name of Health Facility', 'Name of Governor ate',\n",
      "       'Name of District', 'Facility Type2', 'Damaged2018',\n",
      "       'Functionality2018', 'Accessibility to HF', 'geometry', 'NN',\n",
      "       'NN_dist'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "229"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceptable_df = pd.read_csv(os.path.join(pth, 'HeRAMs_2016v2018_damages and functionality_cleaned_snapped.csv'))\n",
    "print(acceptable_df.columns)\n",
    "hosp_types = ['District L Rural\\r Hospital','Governorate/General\\r Hospital','Hospital','1']\n",
    "def hospcheck(x, hosp_types):\n",
    "    if x in hosp_types:\n",
    "        return 'HOS'\n",
    "    else:\n",
    "        return 'PHC'\n",
    "acceptable_df['hosp'] = acceptable_df['Facility Type2'].apply(lambda x: hospcheck(x, hosp_types))\n",
    "acceptable_df = acceptable_df.loc[acceptable_df['hosp'] == 'HOS']\n",
    "function_level = ['1','2',1,2]\n",
    "acceptable_df = acceptable_df.loc[acceptable_df['Functionality2018'].isin(function_level)]\n",
    "#service_level = ['1']\n",
    "#acceptable_df = acceptable_df.loc[acceptable_df['Comprehensive Emergency Obstetric Care (S424)'].isin(service_level)]\n",
    "len(acceptable_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceptable_df['geometry'] = acceptable_df['geometry'].apply(loads)\n",
    "acceptable_gdf = gpd.GeoDataFrame(acceptable_df, geometry = 'geometry', crs = {'init':'epsg:4326'})\n",
    "accepted_facilities = list(set(list(acceptable_df.NN)))\n",
    "accepted_facilities_str = [str(i) for i in accepted_facilities]\n",
    "OD = OD_original[accepted_facilities_str]\n",
    "acceptable_df.to_csv(os.path.join(basepth,'output_layers','%s.csv' % subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36158, 4114)\n",
      "(36158, 227)\n"
     ]
    }
   ],
   "source": [
    "print(OD_original.shape)\n",
    "print(OD.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Walk Time from Final Node to Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_df = acceptable_df[['NN','NN_dist']]\n",
    "\n",
    "dest_df = dest_df.set_index('NN')\n",
    "\n",
    "dest_df['NN_dist'] = dest_df['NN_dist'] / 1000 * 3600 / walk_speed\n",
    "\n",
    "dest_df.index = dest_df.index.map(str)\n",
    "\n",
    "d_f = OD.transpose()\n",
    "\n",
    "for i in d_f.columns:\n",
    "    dest_df[i] = d_f[i]\n",
    "    \n",
    "for i in dest_df.columns:\n",
    "    if i == 'NN_dist':\n",
    "        pass\n",
    "    else:\n",
    "        dest_df[i] = dest_df[i] + dest_df['NN_dist']\n",
    "\n",
    "dest_df = dest_df.drop('NN_dist', axis = 1)\n",
    "\n",
    "dest_df = dest_df.transpose()\n",
    "\n",
    "dest_df['min_time'] = dest_df.min(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = r'origins_1km_snapped.csv'\n",
    "grid = pd.read_csv(os.path.join(pth, grid_name))\n",
    "grid = grid.rename(columns = {'NN':'O_ID','NN_dist':'walk_to_road_net'})\n",
    "grid = grid.set_index(grid['O_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid['on_network_time'] = dest_df['min_time']\n",
    "grid['walk_to_road_net'] = grid['walk_to_road_net'] / 1000 * 3600 / walk_speed \n",
    "grid['total_time_net'] = grid['on_network_time'] + grid['walk_to_road_net']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Direct Walking Time (no driving!), Compare to Drive Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid['PLOT_TIME_SECS'] = grid['total_time_net']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid['PLOT_TIME_MINS'] = grid['PLOT_TIME_SECS'] / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Burn Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "rst_fn = os.path.join(pth,'pop18_resampled.tif')\n",
    "out_fn = os.path.join(basepth,'output_layers','%s.tif' % subset)\n",
    "\n",
    "# Update metadata\n",
    "rst = rasterio.open(rst_fn, 'r')\n",
    "meta = rst.meta.copy()\n",
    "D_type = rasterio.float64\n",
    "meta.update(compress='lzw', dtype = D_type, count = 2)\n",
    "\n",
    "with rasterio.open(out_fn, 'w', **meta) as out:\n",
    "    with rasterio.open(rst_fn, 'r') as pop:\n",
    "        \n",
    "        # this is where we create a generator of geom, value pairs to use in rasterizing\n",
    "        shapes = ((geom,value) for geom, value in zip(grid.geometry, grid.PLOT_TIME_MINS))\n",
    "\n",
    "        population = pop.read(1).astype(D_type)\n",
    "        cpy = population.copy()\n",
    "\n",
    "        travel_times = features.rasterize(shapes=shapes, fill=0, out=cpy, transform=out.transform)\n",
    "\n",
    "        out.write_band(1, population)\n",
    "        out.write_band(2, travel_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Zonal Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\Documents\\GOST\\Yemen\\output_layers\\HeRAMS Hospitals January24th.tif\n",
      "0    0.397615\n",
      "Name: frac_30, dtype: float64\n",
      "0    0.610592\n",
      "Name: frac_60, dtype: float64\n",
      "0    0.840795\n",
      "Name: frac_120, dtype: float64\n",
      "0    0.944127\n",
      "Name: frac_240, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST\\GOSTRocks')\n",
    "#from GOSTRocks.rasterMisc import *\n",
    "### MODIFIED FUNCTION BELOW!!\n",
    "\n",
    "utils = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\util_files'\n",
    "\n",
    "yemen_shp_name = os.path.join(utils, r'Yemen_bound.shp')\n",
    "yemen_shp = gpd.read_file(yemen_shp_name)\n",
    "yemen_shp = yemen_shp.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "district_shp_name = os.path.join(utils, r'Yemen_adm2.shp')\n",
    "district_shp = gpd.read_file(district_shp_name)\n",
    "district_shp = district_shp.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "inraster = out_fn\n",
    "ras = rasterio.open(inraster, mode = 'r+')\n",
    "pop = ras.read(1)\n",
    "tt_matrix = ras.read(2)\n",
    "\n",
    "resolution = 'national'\n",
    "\n",
    "if resolution == 'national':\n",
    "    target_shp = yemen_shp\n",
    "elif resolution == 'district':\n",
    "    target_shp = district_shp\n",
    "\n",
    "## First, add on the total population of the district to each district shape\n",
    "\n",
    "mask_pop = np.ma.masked_where(pop > (200000), pop).mask\n",
    "\n",
    "base_pop = zonalStats(target_shp, \n",
    "                        inraster, \n",
    "                        bandNum = 1,\n",
    "                        mask_A = mask_pop,\n",
    "                        reProj = False, \n",
    "                        minVal = 0,\n",
    "                        maxVal = np.inf, \n",
    "                        verbose = True, \n",
    "                        rastType='N')\n",
    "\n",
    "cols = ['total_pop','min','max','mean']\n",
    "\n",
    "temp_df = pd.DataFrame(base_pop, columns = cols)\n",
    "\n",
    "target_shp['total_pop'] = temp_df['total_pop']\n",
    "target_shp['total_pop'].loc[target_shp['total_pop'] == -1] = 0\n",
    "\n",
    "## Now, calculate the population within a range of time thresholds from the destination set\n",
    "for time_thresh in [30,60,120, 240]:\n",
    "    \n",
    "    mask_obj = np.ma.masked_where(tt_matrix > (time_thresh), tt_matrix).mask\n",
    "\n",
    "    raw = zonalStats(target_shp, \n",
    "                        inraster, \n",
    "                        bandNum = 1,\n",
    "                        mask_A = mask_obj,\n",
    "                        reProj = False, \n",
    "                        minVal = 0,\n",
    "                        maxVal = np.inf, \n",
    "                        verbose = True, \n",
    "                        rastType='N')\n",
    "\n",
    "    cols = ['pop_%s' % time_thresh,'min','max','mean']\n",
    "\n",
    "    temp_df = pd.DataFrame(raw, columns = cols)\n",
    "\n",
    "    target_shp['pop_%s' % time_thresh] = temp_df['pop_%s' % time_thresh]\n",
    "    target_shp['pop_%s' % time_thresh].loc[target_shp['pop_%s' % time_thresh] == -1] = 0\n",
    "    target_shp['frac_%s' % time_thresh] = (target_shp['pop_%s' % time_thresh]) / (target_shp['total_pop']).fillna(0)\n",
    "    target_shp['frac_%s' % time_thresh].replace([np.inf, -np.inf], 0)\n",
    "    target_shp['frac_%s' % time_thresh] = target_shp['frac_%s' % time_thresh].fillna(0)\n",
    "    \n",
    "# Save to file\n",
    "                  \n",
    "if resolution == 'national':\n",
    "    print(out_fn)\n",
    "    print(target_shp.frac_30.head(1))\n",
    "    print(target_shp.frac_60.head(1))\n",
    "    print(target_shp.frac_120.head(1))\n",
    "    print(target_shp.frac_240.head(1))\n",
    "else:\n",
    "    target_shp['abs_pop_iso'] = target_shp['total_pop'] - target_shp['pop_30']\n",
    "    target_shp.to_file(os.path.join(basepth, 'output_layers','%s_zonal_%s.shp' % (subset, resolution)), driver = 'ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Change Rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepth = r'C:\\Users\\charl\\Documents\\GOST\\Yemen'\n",
    "pth = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\graphtool'\n",
    "start = ['base',\n",
    "         ' 2018_November1st',\n",
    "         ' November8th',\n",
    "         ' November14th',\n",
    "         ' November25th',\n",
    "         ' December17th']\n",
    "\n",
    "end = [' 2018_November1st',\n",
    "    ' November8th',\n",
    "    ' November14th',\n",
    "    ' November25th',\n",
    "    ' December17th',\n",
    "    ' January24th']\n",
    "\n",
    "for i in range(0, len(end)):\n",
    "    st = start[i]\n",
    "    en = end[i]\n",
    "    \n",
    "    if st == 'base':\n",
    "        stn = ''\n",
    "    else:\n",
    "        stn = st\n",
    "    \n",
    "    subset = r'HeRAMS Hospitals_{}_{}'.format(st, en)\n",
    "    pre_raster = os.path.join(basepth, 'output_layers','HeRAMS Hospitals{}.tif'.format(stn))\n",
    "    post_raster = os.path.join(basepth, 'output_layers','HeRAMS Hospitals{}.tif'.format(en))\n",
    "    out_fn = os.path.join(basepth,'output_layers','%s.tif' % subset)\n",
    "\n",
    "    pre = rasterio.open(pre_raster, 'r')\n",
    "    arr_pre = pre.read(2)\n",
    "    post = rasterio.open(post_raster, 'r')\n",
    "    arr_post = post.read(2)\n",
    "    delta = arr_pre - arr_post\n",
    "\n",
    "    # Update metadata\n",
    "    rst_fn = os.path.join(pth,'pop18_resampled.tif')\n",
    "    rst = rasterio.open(rst_fn, 'r')\n",
    "    meta = rst.meta.copy()\n",
    "    D_type = rasterio.float64\n",
    "    meta.update(compress='lzw', dtype = D_type, count = 3)\n",
    "\n",
    "    with rasterio.open(out_fn, 'w', **meta) as out:\n",
    "        with rasterio.open(rst_fn, 'r') as pop:\n",
    "\n",
    "            # this is where we create a generator of geom, value pairs to use in rasterizing\n",
    "            #shapes = ((geom,value) for geom, value in zip(grid.geometry, grid.PLOT_TIME_MINS))\n",
    "\n",
    "            population = pop.read(1).astype(D_type)\n",
    "\n",
    "            out.write_band(1, population)\n",
    "            out.write_band(2, delta)\n",
    "            out.write_band(3, delta * population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zonalStats(inShp, inRaster, bandNum=1, mask_A = None, reProj = False, minVal = '', maxVal = '', verbose=False , rastType='N', unqVals=[]):\n",
    "    import sys, os, inspect, logging, json\n",
    "    import rasterio, affine\n",
    "\n",
    "    import pandas as pd\n",
    "    import geopandas as gpd\n",
    "    import numpy as np\n",
    "\n",
    "    from collections import Counter\n",
    "    from shapely.geometry import box\n",
    "    from affine import Affine\n",
    "    from rasterio import features\n",
    "    from rasterio.mask import mask\n",
    "    from rasterio.features import rasterize\n",
    "    from rasterio.warp import reproject, Resampling\n",
    "    from osgeo import gdal\n",
    "    \n",
    "    ''' Run zonal statistics against an input shapefile\n",
    "    \n",
    "    INPUT VARIABLES\n",
    "    inShp [string or geopandas object] - path to input shapefile\n",
    "    inRaster [string or rasterio object] - path to input raster\n",
    "    \n",
    "    OPTIONAL\n",
    "    bandNum [integer] - band in raster to analyze\n",
    "    reProj [boolean] -  whether to reproject data to match, if not, raise an error\n",
    "    minVal [number] - if defined, will only calculation statistics on values above this number\n",
    "    verbose [boolean] - whether to be loud with responses\n",
    "    rastType [string N or C] - N is numeric and C is categorical. Categorical returns counts of numbers\n",
    "    unqVals [array of numbers] - used in categorical zonal statistics, tabulates all these numbers, will report 0 counts\n",
    "    mask_A [numpy boolean mask] - mask the desired band using an identical shape boolean mask. Useful for doing conditional zonal stats\n",
    "    \n",
    "    RETURNS\n",
    "    array of arrays, one for each feature in inShp\n",
    "    '''   \n",
    "    if isinstance(inShp, str):\n",
    "        inVector = gpd.read_file(inShp) \n",
    "    else:\n",
    "        inVector = inShp\n",
    "    if isinstance(inRaster, str):\n",
    "        curRaster = rasterio.open(inRaster, 'r+')\n",
    "    else:\n",
    "        curRaster = inRaster\n",
    "        \n",
    "    # If mask is not none, apply mask \n",
    "    if mask_A is not None:\n",
    "        \n",
    "        curRaster.write_mask(np.invert(mask_A))\n",
    "    \n",
    "    outputData=[]\n",
    "    if inVector.crs != curRaster.crs:\n",
    "        if reProj:\n",
    "            inVector = inVector.to_crs(curRaster.crs)\n",
    "        else:\n",
    "            raise ValueError(\"Input CRS do not match\")\n",
    "    fCount = 0\n",
    "    tCount = len(inVector['geometry'])\n",
    "    #generate bounding box geometry for raster bbox\n",
    "    b = curRaster.bounds\n",
    "    rBox = box(b[0], b[1], b[2], b[3])\n",
    "    for geometry in inVector['geometry']:\n",
    "        #This test is used in case the geometry extends beyond the edge of the raster\n",
    "        #   I think it is computationally heavy, but I don't know of an easier way to do it\n",
    "        if not rBox.contains(geometry):\n",
    "            geometry = geometry.intersection(rBox)            \n",
    "        try:\n",
    "            fCount = fCount + 1\n",
    "            if fCount % 1000 == 0 and verbose:\n",
    "                tPrint(\"Processing %s of %s\" % (fCount, tCount) )\n",
    "            # get pixel coordinates of the geometry's bounding box\n",
    "            ul = curRaster.index(*geometry.bounds[0:2])\n",
    "            lr = curRaster.index(*geometry.bounds[2:4])\n",
    "            '''\n",
    "            TODO: There is a problem with the indexing - if the shape falls outside the boundaries, it errors\n",
    "                I want to change it to just grab what it can find, but my brain is wrecked and I cannot figure it out\n",
    "            print(geometry.bounds)\n",
    "            print(curRaster.shape)\n",
    "            print(lr)\n",
    "            print(ul)\n",
    "            lr = (max(lr[0], 0), min(lr[1], curRaster.shape[1]))\n",
    "            ul = (min(ul[0], curRaster.shape[0]), min(ul[1]))\n",
    "            '''\n",
    "            # read the subset of the data into a numpy array\n",
    "            window = ((float(lr[0]), float(ul[0]+1)), (float(ul[1]), float(lr[1]+1)))\n",
    "            \n",
    "            if mask is not None:\n",
    "                data = curRaster.read(bandNum, window=window, masked = True)\n",
    "            else:\n",
    "                data = curRaster.read(bandNum, window=window, masked = False)\n",
    "            \n",
    "            # create an affine transform for the subset data\n",
    "            t = curRaster.transform\n",
    "            shifted_affine = Affine(t.a, t.b, t.c+ul[1]*t.a, t.d, t.e, t.f+lr[0]*t.e)\n",
    "\n",
    "            # rasterize the geometry\n",
    "            mask = rasterize(\n",
    "                [(geometry, 0)],\n",
    "                out_shape=data.shape,\n",
    "                transform=shifted_affine,\n",
    "                fill=1,\n",
    "                all_touched=False,\n",
    "                dtype=np.uint8)\n",
    "\n",
    "            # create a masked numpy array\n",
    "            masked_data = np.ma.array(data=data, mask=mask.astype(bool))\n",
    "            if rastType == 'N':                \n",
    "                if minVal != '' or maxVal != '':\n",
    "                    if minVal != '':\n",
    "                        masked_data = np.ma.masked_where(masked_data < minVal, masked_data)\n",
    "                    if maxVal != '':\n",
    "                        masked_data = np.ma.masked_where(masked_data > maxVal, masked_data)                    \n",
    "                    if masked_data.count() > 0:                        \n",
    "                        results = [masked_data.sum(), masked_data.min(), masked_data.max(), masked_data.mean()]\n",
    "                    else :\n",
    "                        results = [-1, -1, -1, -1]                \n",
    "                else:\n",
    "                    results = [masked_data.sum(), masked_data.min(), masked_data.max(), masked_data.mean()]\n",
    "            if rastType == 'C':\n",
    "                if len(unqVals) > 0:                          \n",
    "                    xx = dict(Counter(data.flatten()))\n",
    "                    results = [xx.get(i, 0) for i in unqVals]                \n",
    "                else:\n",
    "                    results = np.unique(masked_data, return_counts=True)                    \n",
    "            outputData.append(results)\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "            outputData.append([-1, -1, -1, -1])            \n",
    "    return outputData   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Cfox2)",
   "language": "python",
   "name": "cfox2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
