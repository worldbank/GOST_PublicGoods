{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep A - Warfront Layer Generation/\n",
    "\n",
    "This script sits outside of the main process. In this script, we take the raw data given to us by the WHO in Excel format, and join it to a shapefile. The raw document was composed of a list of homogenous governorates for the North, a list of homogenous governorates for the South, and then additional tabs for governorates that are split (see Taizz, Al Jawf, etc). \n",
    "\n",
    "We aim to build this information into a shapefile which we can bring in to the main process when relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We commence by importing the usual suspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peartree version: 0.6.0 \n",
      "networkx version: 2.2 \n",
      "matplotlib version: 2.2.2 \n",
      "osmnx version: 0.8.2 \n",
      "peartree version: 0.6.0 \n",
      "networkx version: 2.2 \n",
      "matplotlib version: 2.2.2 \n",
      "osmnx version: 0.8.2 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST_PublicGoods\\GOSTNets\\GOSTNets')\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST')\n",
    "import GOSTnet as gn\n",
    "import importlib\n",
    "importlib.reload(gn)\n",
    "import geopandas as gpd\n",
    "import rasterio as rt\n",
    "from rasterio import features\n",
    "from shapely.wkt import loads\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from shapely.geometry import box, Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set paths to our utility working folder, and import the shapefile we want to join the information on to. Note, we use GADM boundaries and NOT World Bank boundaries here because the spelling of placenames is notoriously unreliable in the Yemen region. As the Excel document used the placenames taken from the GADM layer, we go with the GADM layer, rather than trying to manually match the placenames on the equivalent World Bank admin boundary shapefile (I tried this first, it is VERY painful). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util_pth = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\util_files\\gadm36_YEM_shp'\n",
    "util_fil = r'gadm36_YEM_2.shp'\n",
    "util_shp = gpd.read_file(os.path.join(util_pth, util_fil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a simple binary code - 1 for South, 0 for North. This will enable easier manipulation later. We build a dictionary for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "homogenous_status = {'Abyan':1,\n",
    "                    '`Adan':1, \n",
    "                    'Al Dali\\'':1,\n",
    "                    'Al Mahrah':1,\n",
    "                    'Hadramawt':1, \n",
    "                    'Lahij':1,\n",
    "                    'Ma\\'rib':1,\n",
    "                    'Shabwah':1, \n",
    "                     \n",
    "                    'Al Mahwit':0,\n",
    "                    'Amran':0, \n",
    "                    'Dhamar':0,\n",
    "                    'Hajjah':0,\n",
    "                    'Ibb':0,\n",
    "                    'Sa`dah':0,\n",
    "                    'San`a\\'':0,\n",
    "                    'Raymah':0,\n",
    "                    'Amanat Al Asimah':0\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick out the unique values in the NAME_1 field of the administrative boundary shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_regions = list(util_shp.NAME_1.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and check against the keys of the above dictionary to identify the non-homogenous governorates. We will then take each of those in turn and build similar dictionaries for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in homogenous_status.keys():\n",
    "    if i not in unique_regions:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taizz is one such governorates where control is split between the north and the south. So, we pick out from the shapefile all districts where NAME_1 is Ta`izz, and make a list of the unique values in NAME_2 (the sub-governorate districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Taizz_shp_districts = list(util_shp.loc[util_shp.NAME_1 == 'Ta`izz'].NAME_2.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. This information is hard-coded from the excel I was given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Taizz = {'Al  Mukha':0,\n",
    " \"Al Ma'afer\":1,\n",
    " 'Al Mawasit':0,\n",
    " 'Al Misrakh':1,\n",
    " 'Al Mudhaffar':0,\n",
    " 'Al Qahirah':1,\n",
    " \"Al Wazi'iyah\":0,\n",
    " 'As Silw':1,\n",
    " 'Ash Shamayatayn':0,\n",
    " \"At Ta'iziyah\":0,\n",
    " 'Dhubab':0,\n",
    " 'Dimnat Khadir':0,\n",
    " 'Hayfan':1,\n",
    " 'Jabal Habashy':1,\n",
    " 'Maqbanah':0,\n",
    " \"Mashra'a Wa Hadnan\":0,\n",
    " 'Mawiyah':0,\n",
    " 'Mawza':0,\n",
    " 'Sabir Al Mawadim':1,\n",
    " 'Salh':1,\n",
    " 'Sama':0,\n",
    " \"Shara'b Ar Rawnah\":0,\n",
    " \"Shara'b As Salam\":0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check to make sure that all Taizz districts have been given a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in Taizz.keys():\n",
    "    if i not in Taizz_shp_districts:\n",
    "        print(i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat this process for Al Jawf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "al_jawf_shp_districts = list(util_shp.loc[util_shp.NAME_1 == 'Al Jawf'].NAME_2.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "al_jawf = {\n",
    " 'Al Ghayl':1,\n",
    " 'Al Hazm':1,\n",
    " 'Al Humaydat':0,\n",
    " 'Al Khalq':1,\n",
    " 'Al Maslub':1,\n",
    " 'Al Matammah':0,\n",
    " 'Al Maton':0,\n",
    " 'Az Zahir':0,\n",
    " 'Bart Al Anan':0,\n",
    " \"Khabb wa ash Sha'af\":0,\n",
    " 'Kharab Al Marashi':0,\n",
    " 'Rajuzah':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in al_jawf.keys():\n",
    "    if i not in al_jawf_shp_districts:\n",
    "        print(i)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and Al Hudaydah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "al_hudaydah_shp_districts = list(util_shp.loc[util_shp.NAME_1 == 'Al Hudaydah'].NAME_2.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Al_Hudaydah = {'Ad Dahi':0,\n",
    " 'Ad Durayhimi':1,\n",
    " 'Al Garrahi':0,\n",
    " 'Al Hajjaylah':0,\n",
    " 'Al Hali':0,\n",
    " 'Al Hawak':1,\n",
    " 'Al Khawkhah':1,\n",
    " 'Al Mansuriyah':0,\n",
    " \"Al Marawi'ah\":0,\n",
    " 'Al Mighlaf':0,\n",
    " 'Al Mina':0,\n",
    " 'Al Munirah':0,\n",
    " 'Al Qanawis':0,\n",
    " 'Alluheyah':0,\n",
    " 'As Salif':0,\n",
    " 'As Sukhnah':0,\n",
    " 'At Tuhayat':1,\n",
    " 'Az Zaydiyah':0,\n",
    " 'Az Zuhrah':0,\n",
    " 'Bajil':0,\n",
    " 'Bayt Al Faqiah':1,\n",
    " 'Bura':0,\n",
    " 'Hays':1,\n",
    " \"Jabal Ra's\":0,\n",
    " 'Kamaran':0,\n",
    " 'Zabid':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in Al_Hudaydah.keys():\n",
    "    if i not in al_hudaydah_shp_districts:\n",
    "        print(i)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and Al Bayda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "al_bayda_shp_districts = list(util_shp.loc[util_shp.NAME_1 == 'Al Bayda\\''].NAME_2.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "al_bayda = {\"Al A'rsh\":0,\n",
    " 'Al Bayda':0,\n",
    " 'Al Bayda City':0,\n",
    " 'Al Malagim':0,\n",
    " 'Al Quraishyah':0,\n",
    " 'Ar Ryashyyah':0,\n",
    " 'As Sawadiyah':0,\n",
    " \"As Sawma'ah\":1,\n",
    " 'Ash Sharyah':0,\n",
    " 'At Taffah':0,\n",
    " 'Az Zahir':1,\n",
    " \"Dhi Na'im\":0,\n",
    " 'Maswarah':1,\n",
    " 'Mukayras':0,\n",
    " \"Na'man\":1,\n",
    " \"Nati'\":1,\n",
    " \"Rada'\":0,\n",
    " 'Radman Al Awad':0,\n",
    " 'Sabah':0,\n",
    " \"Wald Rabi'\":0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have assembled our binary dictionaries, we can map this 1/0 value onto ALL of the districts in the shapefile. We know by construction above that we have assigned values to every governorate or every district, so we need not worry about completeness at this stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    197\n",
       "1    136\n",
       "Name: allegiance, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Firstly, we use the map method on NAME_1 column to fill in our homogenous states, filling blanks with the word 'split'\n",
    "util_shp['allegiance'] = util_shp['NAME_1'].map(homogenous_status).fillna('split')\n",
    "\n",
    "# Now, we take locs of the GeoDataFrame and apply the govenorate specific dictionaries against the NAME_2 column \n",
    "# Where NAME_1 is a known split-loyalty state\n",
    "util_shp['allegiance'].loc[util_shp.NAME_1 == 'Ta`izz'] = util_shp['NAME_2'].map(Taizz)\n",
    "util_shp['allegiance'].loc[util_shp.NAME_1 == 'Al Jawf'] = util_shp['NAME_2'].map(al_jawf)\n",
    "util_shp['allegiance'].loc[util_shp.NAME_1 == 'Al Bayda\\''] = util_shp['NAME_2'].map(al_bayda)\n",
    "util_shp['allegiance'].loc[util_shp.NAME_1 == 'Al Hudaydah'] = util_shp['NAME_2'].map(Al_Hudaydah)\n",
    "\n",
    "# Finally, we count up the total number of 1s and 0s. \n",
    "util_shp['allegiance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now send this to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "util_shp.to_file(os.path.join(util_pth, 'conflictbounds.shp'), driver = 'ESRI Shapefile')\n",
    "\n",
    "# Although this is useful, what's even more useful is to have files that 'join up' regions of homogenous control - \n",
    "# as the boundaries between these regions are the Warfronts. We do that by using Unary Union, below. \n",
    "\n",
    "from shapely.ops import unary_union\n",
    "north = util_shp.loc[util_shp.allegiance == 0]\n",
    "south = util_shp.loc[util_shp.allegiance == 1]\n",
    "north_shp = unary_union(north.geometry)\n",
    "south_shp = unary_union(south.geometry)\n",
    "\n",
    "# We can now send to a file a 'south districts; file and a 'north districts' file. \n",
    "south_file = gpd.GeoDataFrame({'geometry':south_shp},geometry = 'geometry', crs = {'init':'epsg:4326'})\n",
    "south_file.to_file(os.path.join(util_pth,'districts_south.shp'))\n",
    "\n",
    "north_file = gpd.GeoDataFrame({'geometry':north_shp},geometry = 'geometry', crs = {'init':'epsg:4326'})\n",
    "north_file.to_file(os.path.join(util_pth,'districts_north.shp'))\n",
    "\n",
    "# finally, we can join them together into a merged districts file composed only of regions of homogenous control. \n",
    "combo = pd.concat([north_file, south_file])\n",
    "combo.to_file((os.path.join(util_pth,'merged_dists_unedited.shp')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
