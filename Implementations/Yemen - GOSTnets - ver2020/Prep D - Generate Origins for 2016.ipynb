{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep D - Generate Origins for 2016\n",
    "\n",
    "Part of the complexity of the Yemen anaylsis is that we want to compare the access to helath facilities across two different time periods - 2016 and 2018. \n",
    "\n",
    "Unfortunately, WorldPop supplied us with grids which were slightly offset for the two years. This is not good for the purposes of network analysis - as we want to the origin points to remain constant (geographically) in order to do change detection between the resultant travel time rasters. \n",
    "\n",
    "As such, it was necessary to devise a means of translating the values on the 2016 file to the geographical centroids of the 2018 file to carry out the analysis. This is what this script accomplishes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We commence per normal by importing the usual suspects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST\\GOSTRocks')\n",
    "import rasterMisc as rm\n",
    "import rasterio as rt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box, Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we import the 2018 points, and build a list of nodes composed of x,y coordinate pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origin_pth = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\origins'\n",
    "points_2018 = gpd.read_file(os.path.join(origin_pth, 'origins_1km_2018.shp'))\n",
    "points_2018['x'] = points_2018.geometry.x\n",
    "points_2018['y'] = points_2018.geometry.y\n",
    "\n",
    "list_of_nodes = {}\n",
    "for index, row in points_2018.iterrows():\n",
    "    list_of_nodes.update({index:(row['x'], row['y'])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have population for 2015, and facility availability for 2016. Rather than moan about it, we get on and use the 2015 population layer for 2016. As usual, we start by opening the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pop_2015 = rt.open(os.path.join(r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\worldpop',r'pop15_resampled.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to sample the raster for only the points that fall inside raster. So we do a quick intersection check to build a list of the nodes that definitely intersect the bounds of the raster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take bounds\n",
    "b = pop_2015.bounds\n",
    "\n",
    "# build bounding box of the raster\n",
    "datasetBoundary = box(b[0], b[1], b[2], b[3])\n",
    "\n",
    "# iterate through the nodes list\n",
    "selKeys = []\n",
    "selPts = []\n",
    "for key, pt in list_of_nodes.items():\n",
    "    \n",
    "    # Make a point, check if it lies inside the bounding box just defined\n",
    "    if Point(pt[0], pt[1]).intersects(datasetBoundary):\n",
    "        \n",
    "        # if so, add the Point and keys to the respective lists\n",
    "        selPts.append(pt)\n",
    "        selKeys.append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we go ahead and sample the 2015 raster with these points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raster_values = list(pop_2015.sample(selPts))\n",
    "raster_values = [x[0] for x in raster_values]\n",
    "\n",
    "# generate new dictionary of {node ID: raster values}\n",
    "ref = dict(zip(selKeys, raster_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before mapping the values back on to original 2018 points using the pandas map function on the ref dictionary of ID:value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the key line that translates the index field into the 2015 population value\n",
    "points_2018['2015_POP'] = points_2018.index.map(ref)\n",
    "\n",
    "# we reset this field as 'VALUE' and drop annoying fields\n",
    "points_2018['VALUE'] = points_2018['2015_POP']\n",
    "points_2018 = points_2018.drop(['x','y','2015_POP'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are ready to write out the 2015 layer as both shapefile and .csv, which we do below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "points_2018.to_file(os.path.join(r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\origins','origins_1km_2015.shp'), driver = 'ESRI Shapefile')\n",
    "points_2018.to_csv(os.path.join(r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\origins','origins_1km_2015.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
