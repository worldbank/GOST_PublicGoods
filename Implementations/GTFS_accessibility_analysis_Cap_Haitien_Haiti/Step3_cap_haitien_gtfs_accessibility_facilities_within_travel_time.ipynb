{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Cap Haitien GTFS Accessibility Analysis\n",
    "How many Economic Indicators can be reached within x amount of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reference to GOSTNets\n",
    "import sys\n",
    "sys.path.append(r'C:\\repos\\GOSTnets')\n",
    "import GOSTnets as gn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read back your graphs from step 2 from you saved pickle\n",
    "G_service0001 = nx.read_gpickle(r\"temp\\gtfs_export_cap_haitien_merged_impute_walk_v5_service0001.pickle\")\n",
    "G_service0002 = nx.read_gpickle(r\"temp\\gtfs_export_cap_haitien_merged_impute_walk_v5_service0002.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(G.edges)[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify only the largest graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compatible with NetworkX 2.4\n",
    "list_of_subgraphs = list(G_service0001.subgraph(c).copy() for c in nx.weakly_connected_components(G_service0001))\n",
    "max_graph = None\n",
    "max_edges = 0\n",
    "for i in list_of_subgraphs:\n",
    "    if i.number_of_edges() > max_edges:\n",
    "        max_edges = i.number_of_edges()\n",
    "        max_graph = i\n",
    "\n",
    "# set your graph equal to the largest sub-graph\n",
    "G_service0001 = max_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compatible with NetworkX 2.4\n",
    "list_of_subgraphs = list(G_service0002.subgraph(c).copy() for c in nx.weakly_connected_components(G_service0002))\n",
    "max_graph = None\n",
    "max_edges = 0\n",
    "for i in list_of_subgraphs:\n",
    "    if i.number_of_edges() > max_edges:\n",
    "        max_edges = i.number_of_edges()\n",
    "        max_graph = i\n",
    "\n",
    "# set your graph equal to the largest sub-graph\n",
    "G_service0002 = max_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = {'G_service0001': G_service0001, 'G_service0002': G_service0002}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print info about the largest sub-graph\n",
    "#print(nx.info(G_largest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load origins\n",
    "origins = gpd.read_file(r\"input_folder\\cap_haitien_worldpop_pts2.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load destinations\n",
    "destinations = gpd.read_file(r\"output_folder\\osm_infrastructure\\osm_shops_and_amenities.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For each destination for each type of graph do an accessibility analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-14-b93bf47d6374>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-14-b93bf47d6374>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    origins = gpd.read_file(rinput_folder\\cap_haitien_worldpop_pts2.shp\")\u001b[0m\n\u001b[1;37m                                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "for G in graphs.items():\n",
    "    # Origins remain the same for each type of accessibility\n",
    "    # insert origins\n",
    "    origins = gpd.read_file(rinput_folder\\cap_haitien_worldpop_pts2.shp\")\n",
    "    # snap the origins to the road graph\n",
    "    snapped_origins = gn.pandana_snap(G[1], origins, source_crs = 'epsg:4326', target_crs = 'epsg:32619')\n",
    "    # filter out origins with a distance more than 2km\n",
    "    snapped_origins_filtered = snapped_origins[snapped_origins.NN_dist < 2000]\n",
    "    originNodes = list(snapped_origins_filtered['NN'].unique())\n",
    "\n",
    "    # snap the destinations to the road graph\n",
    "    snapped_destinations = gn.pandana_snap(G[1], destinations, source_crs = 'epsg:4326', target_crs = 'epsg:32619')\n",
    "    destinationsNodes = list(snapped_destinations['NN'].unique())\n",
    "    # Calculate OD Matrix\n",
    "    OD_matrix = gn.calculate_OD(G[1], originNodes, destinationsNodes, fail_value=-1, weight='length')\n",
    "    \n",
    "    OD_df = pd.DataFrame(OD_matrix, columns = destinationsNodes , index = originNodes)\n",
    "    \n",
    "    # 60 minute threshold\n",
    "    threshold_in_sec = 60 * 60\n",
    "    \n",
    "    # calculate accessibility\n",
    "    accessibility_measure = OD_df[OD_df <= threshold_in_sec].count(axis=1)\n",
    "    \n",
    "    results = pd.DataFrame([originNodes, list(accessibility_measure)]).transpose()\n",
    "    colName = \"accessibility_measure\"\n",
    "    results.columns = ['NN', colName]\n",
    "    \n",
    "    output = snapped_origins_filtered.copy()\n",
    "    output = pd.merge(output, results, on=\"NN\")\n",
    "    \n",
    "    #convert travel_time_to_closest_facility to number\n",
    "    output[\"accessibility_measure\"] = pd.to_numeric(output[\"accessibility_measure\"])\n",
    "    \n",
    "    # save a shapefile...\n",
    "    destinations_gpd = gpd.GeoDataFrame(output, crs = \"epsg:4326\", geometry = 'geometry')\n",
    "    destinations_gpd.to_file(fr\"output_folder\\cap_haitien_accessibility_economic_{G[0]}.shp\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
