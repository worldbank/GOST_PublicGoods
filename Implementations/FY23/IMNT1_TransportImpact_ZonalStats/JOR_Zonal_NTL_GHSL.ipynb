{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, importlib, boto3\n",
    "import rasterio, geojson, folium, h3\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import Polygon, Point, mapping\n",
    "from botocore.config import Config\n",
    "from botocore import UNSIGNED\n",
    "\n",
    "import GOSTRocks.rasterMisc as rMisc\n",
    "\n",
    "sys.path.append(\"/home/wb411133/Code/GEE_Zonal/src\")\n",
    "from gee_tools import Catalog, ZonalStats\n",
    "import ee\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input variables\n",
    "global_ghsl_folder = '/home/public/Data/GLOBAL/GHSL/v2022/'\n",
    "data_folder = \"/home/wb411133/data/Projects/IMNT1_TransportImpact_ZonalStats\"\n",
    "viirs_folder = os.path.join(data_folder, \"VIIRS_DATA\")\n",
    "ghsl_folder = os.path.join(data_folder, \"GHSL_DATA\")\n",
    "in_pop_folder = \"/home/public/Data/COUNTRY/JOR/WorldPop\"\n",
    "global_ntl_folder = \"/home/public/Data/GLOBAL/NighttimeLights/VIIRS_ANNUAL_EOG_V21\"\n",
    "\n",
    "for cFolder in [data_folder, viirs_folder, ghsl_folder]:\n",
    "    if not os.path.exists(cFolder):\n",
    "        os.makedirs(cFolder)\n",
    "proposed_lines = os.path.join(data_folder, \"InputData\", 'JOR_proposed_ring_roads.geojson')\n",
    "amman_bound    = os.path.join(data_folder, \"InputData\", 'AMMAN_UCDB.geojson')\n",
    "in_roads = gpd.read_file(proposed_lines)\n",
    "\n",
    "# Define output files\n",
    "viirs_stats = os.path.join(data_folder, \"VIIRS_zonal.csv\")\n",
    "ghsl_stats = os.path.join(data_folder, \"GHSL_zonal.csv\")\n",
    "pop_stats = os.path.join(data_folder, \"WorldPop_zonal.csv\")\n",
    "ghsl_pop_stats = os.path.join(data_folder, \"GHSL_Pop_stats.csv\")\n",
    "ntl_pop_stats = os.path.join(data_folder, \"VIIRS_Pop_stats.csv\")\n",
    "\n",
    "# Define City\n",
    "selected_city = \"Amman, Jordan\"\n",
    "lat = 31.952949925416064\n",
    "long = 35.91888873705754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed loop: 0\n",
      "Completed loop: 1\n"
     ]
    }
   ],
   "source": [
    "bucket = 'globalnightlight'\n",
    "region = 'us-east-1'\n",
    "s3client = boto3.client('s3', region_name=region, config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "# Loop through the S3 bucket and get all the keys for files that are radiance tifs and json files\n",
    "more_results = True\n",
    "try:\n",
    "    del(token)\n",
    "except:\n",
    "    pass\n",
    "loops = 0\n",
    "good_tif = []\n",
    "while more_results:\n",
    "    print(f\"Completed loop: {loops}\")\n",
    "    if loops > 0:\n",
    "        objects = s3client.list_objects_v2(Bucket=bucket, ContinuationToken=token, Prefix='composites')\n",
    "    else:\n",
    "        objects = s3client.list_objects_v2(Bucket=bucket)\n",
    "    more_results = objects['IsTruncated']\n",
    "    if more_results:\n",
    "        token = objects['NextContinuationToken']\n",
    "    loops += 1\n",
    "    for res in objects['Contents']:\n",
    "        if res['Key'].endswith('avg_rade9.tif') and (\"slcorr\" in res['Key']):\n",
    "            good_tif.append(res)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_point = Point(long, lat)\n",
    "cur_city = gpd.GeoDataFrame(pd.DataFrame([[selected_city, city_point]], columns=['City','geometry']), geometry='geometry', crs=4326).to_crs(3857)\n",
    "cur_city['geometry'] = cur_city['geometry'].buffer(40000)\n",
    "cur_city = cur_city.to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing h3 resolution of 6, as the area is ~36km2 - https://h3geo.org/docs/core-library/restable/\n",
    "h3_grid = h3.polyfill(mapping(cur_city.unary_union), 6, geo_json_conformant=True)\n",
    "h3_shps = [Polygon(h3.h3_to_geo_boundary(h, geo_json=True)) for h in h3_grid]\n",
    "inH = pd.DataFrame(h3_shps, columns=['geometry'])\n",
    "inH['id'] = h3_grid\n",
    "inH = gpd.GeoDataFrame(inH, geometry='geometry', crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inH['areakm2'] = inH.to_crs(3857)['geometry'].apply(lambda x: x.area/1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate h3 grid around dedicated city\n",
    "m = folium.Map(location=[lat,long], zoom_start=10)\n",
    "\n",
    "for shp in h3_shps:\n",
    "    hex_shp = folium.GeoJson(mapping(shp), style_function=lambda feature: {\n",
    "    'color':'black',\n",
    "    'weight':0.5\n",
    "}) \n",
    "    hex_shp.add_to(m)\n",
    "\n",
    "amman_bound = folium.GeoJson(mapping(ammanD), style_function=lambda feature: {\n",
    "    'color':'black',\n",
    "    'weight':0.5\n",
    "})\n",
    "amman_bound.add_to(m)\n",
    "    \n",
    "# add the lines for the proposed ring roads\n",
    "control_road = folium.GeoJson(mapping(in_roads['geometry'].iloc[0]), style_function=lambda feature: {\n",
    "    'color':'red',\n",
    "    'weight':5\n",
    "})\n",
    "control_road.add_to(m)\n",
    "\n",
    "treatment_road = folium.GeoJson(mapping(in_roads['geometry'].iloc[1]), style_function=lambda feature: {\n",
    "    'color':'blue',\n",
    "    'weight':5\n",
    "})\n",
    "treatment_road.add_to(m)\n",
    "\n",
    "m\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WP 2000\n",
      "WP 2001\n",
      "WP 2002\n",
      "WP 2003\n",
      "WP 2004\n",
      "WP 2005\n",
      "WP 2006\n",
      "WP 2007\n",
      "WP 2008\n",
      "WP 2009\n",
      "WP 2010\n",
      "WP 2011\n",
      "WP 2012\n",
      "WP 2013\n",
      "WP 2014\n",
      "WP 2015\n",
      "WP 2016\n",
      "WP 2017\n",
      "WP 2018\n",
      "WP 2019\n",
      "WP 2020\n"
     ]
    }
   ],
   "source": [
    "resP = inH.copy()\n",
    "pop_files = [os.path.join(in_pop_folder, x) for x in os.listdir(in_pop_folder)]\n",
    "for pop_file in pop_files:\n",
    "    year = pop_file.split(\"_\")[-2]\n",
    "    inR = rasterio.open(pop_file)    \n",
    "    res = rMisc.zonalStats(inH, pop_file, minVal=0, reProj=True)\n",
    "    res = pd.DataFrame(res, columns=[\"SUM\",\"MIN\",\"MAX\",\"MEAN\"])\n",
    "    resP[f'WP_{year}'] = res['SUM']\n",
    "    print(f\"WP {year}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wb411133/data/Projects/IMNT1_TransportImpact_ZonalStats/WorldPop_zonal.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resP.drop(['geometry'], axis=1).to_csv(pop_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rMisc.clipRaster(rasterio.open(pop_file), inH, os.path.join(data_folder, \"wp_2020.tif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NTL zonal stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resH = inH.copy()\n",
    "for ntl_layer in good_tif:\n",
    "    ntl_file = os.path.join(\"https://globalnightlight.s3.amazonaws.com/\", ntl_layer['Key'])    \n",
    "    inNTL = rasterio.open(ntl_file)\n",
    "    filename = os.path.basename(ntl_file)\n",
    "    local_file = os.path.join(viirs_folder, filename)\n",
    "    if inH.crs != inNTL.crs:\n",
    "        inH = inH.to_crs(inNTL.crs)\n",
    "    if not os.path.exists(local_file):\n",
    "        rMisc.clipRaster(inNTL, inH, local_file)\n",
    "    date = filename.split('_')[2].split('-')[0]\n",
    "    res = rMisc.zonalStats(inH, inNTL, minVal=0)\n",
    "    res = pd.DataFrame(res, columns=[\"SUM\",\"MIN\",\"MAX\",\"MEAN\"])\n",
    "    resH[f'ntl_{date}'] = res['SUM']\n",
    "    print(date)    \n",
    "    \n",
    "pd.DataFrame(resH.drop(['geometry'], axis=1)).to_csv(viirs_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(x):\n",
    "    try:\n",
    "        return(x.split(\"_\")[1][:4])\n",
    "    except:\n",
    "        return(-1)\n",
    "\n",
    "res_annual = resH.transpose()\n",
    "res_annual['year'] = [get_year(x) for x in list(res_annual.index)]\n",
    "#res_annual = (res_annual.drop(['geometry','id','AMMAN','TREAT','CONTROL','CAT']).groupby('year').mean()).transpose()\n",
    "#res_annual['CAT'] = resH['CAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(x):\n",
    "    try:\n",
    "        return(x.mean())\n",
    "    except:\n",
    "        return(-1)\n",
    "all_res = {}\n",
    "for res_group in list(res_annual.drop(['geometry','id','AMMAN','TREAT','CONTROL','CAT']).groupby('year')):\n",
    "    print(res_group[0])\n",
    "    year = f'ntl_{res_group[0]}'\n",
    "    res = res_group[1].apply(get_mean, axis=0)\n",
    "    all_res[year] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_annual = pd.DataFrame(all_res).drop('year')\n",
    "res_annual['CAT'] = inH['CAT']\n",
    "res_annual['geometry'] = inH['geometry']\n",
    "res_annual = gpd.GeoDataFrame(res_annual, geometry='geometry', crs=4326)\n",
    "res_annual.to_file(viirs_stats.replace(\".csv\", \".json\"), driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resH.to_file(viirs_stats.replace(\".csv\", \".json\"), driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_ghsl_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GHSL stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in ghsl folder\n",
    "ghsl_files = [os.path.join(global_ghsl_folder, x) for x in os.listdir(global_ghsl_folder) if x.endswith(\".tif\")]\n",
    "resG = inH.copy()\n",
    "for ghsl_file in ghsl_files:    \n",
    "    date = os.path.basename(ghsl_file).split(\"_\")[3]\n",
    "    inR = rasterio.open(ghsl_file)\n",
    "    if inH.crs != inR.crs:\n",
    "        inH = inH.to_crs(inR.crs)\n",
    "    local_file = os.path.join(ghsl_folder, os.path.basename(ghsl_file))\n",
    "    if not os.path.exists(local_file):\n",
    "        rMisc.clipRaster(inR, inH, local_file)\n",
    "    res = rMisc.zonalStats(inH, inR, minVal=0)\n",
    "    res = pd.DataFrame(res, columns=[\"SUM\",\"MIN\",\"MAX\",\"MEAN\"])\n",
    "    resG[f'ghsl_{date}'] = res['SUM']\n",
    "    print(date)  \n",
    "pd.DataFrame(resG.drop(['geometry'], axis=1)).to_csv(ghsl_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resG.to_file(ghsl_stats.replace(\".csv\", \".json\"), driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine GHSL layers to create map of date created\n",
    "ghsl_files = os.listdir(ghsl_folder)\n",
    "thresh = 1000\n",
    "all_res = []\n",
    "try:\n",
    "    del final\n",
    "except:\n",
    "    pass\n",
    "for ghsl_file in ghsl_files:\n",
    "    date = ghsl_file.split(\"_\")[3][1:5]    \n",
    "    inR = rasterio.open(os.path.join(ghsl_folder, ghsl_file))\n",
    "    inD = inR.read()    \n",
    "    curD = (inD > thresh) * int(date)\n",
    "    curD[inD == inR.meta['nodata']] = 0\n",
    "    #print(int(date))\n",
    "    all_res.append(curD)\n",
    "    try:\n",
    "        final[final < int(date)] = curD[final < int(date)]\n",
    "        print(date)\n",
    "    except:\n",
    "        final = curD\n",
    "   \n",
    "meta = inR.meta.copy()\n",
    "meta.update(count=1)\n",
    "\n",
    "stackedRes = np.vstack(all_res)\n",
    "output = np.amin(stackedRes, axis=0, where=stackedRes>0, initial=meta['nodata'])\n",
    "\n",
    "with rasterio.open(os.path.join(data_folder, f\"ghsl_binary_t{thresh}.tif\"), 'w', **meta) as outR:\n",
    "    outR.write_band(1, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate trend stats\n",
    "Combine the luminosity and built area data with population, and then summarize within three comparable areas:\n",
    "\n",
    "1. Entire Amman area\n",
    "2. Treatment road\n",
    "3. Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Identify hexagonal bins for each catergories\n",
    "ammanD = gpd.read_file(amman_bound)\n",
    "inH = inH.to_crs(ammanD.crs)\n",
    "\n",
    "amman_hex = inH.loc[inH.intersects(ammanD.unary_union)]\n",
    "treat_hex = inH.loc[inH.intersects(in_roads['geometry'].iloc[1])]\n",
    "control_hex = inH.loc[inH.intersects(in_roads['geometry'].iloc[0])]\n",
    "\n",
    "# Generate codes for the hex groups\n",
    "inH['AMMAN'] = 0\n",
    "inH.loc[inH['id'].isin(amman_hex['id']),'AMMAN'] = 1\n",
    "\n",
    "inH['TREAT'] = 0\n",
    "inH.loc[inH['id'].isin(treat_hex['id']),'TREAT'] = 1\n",
    "\n",
    "inH['CONTROL'] = 0\n",
    "inH.loc[inH['id'].isin(control_hex['id']),'CONTROL'] = 1\n",
    "\n",
    "inH['CAT'] = ''\n",
    "inH.loc[inH['AMMAN'] == 1,'CAT'] = 'Amman'\n",
    "inH.loc[inH['CONTROL'] == 1,'CAT'] = 'Control'\n",
    "inH.loc[inH['TREAT'] == 1,'CAT'] = 'Treatment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate h3 grid around dedicated city\n",
    "m = folium.Map(location=[lat,long], zoom_start=11)\n",
    "\n",
    "amman_hex = amman_hex.to_crs(4326)\n",
    "amman_shp = folium.GeoJson(mapping(amman_hex.unary_union), style_function=lambda feature: {\n",
    "    'color':'blue',\n",
    "    'weight':0.5\n",
    "}) \n",
    "amman_shp.add_to(m)\n",
    "m\n",
    "\n",
    "treat_hex = treat_hex.to_crs(4326)\n",
    "treat_shp = folium.GeoJson(mapping(treat_hex.unary_union), style_function=lambda feature: {\n",
    "    'color':'orange',\n",
    "    'weight':0.5\n",
    "}) \n",
    "treat_shp.add_to(m)\n",
    "m\n",
    "\n",
    "control_hex = control_hex.to_crs(4326)\n",
    "control_shp = folium.GeoJson(mapping(control_hex.unary_union), style_function=lambda feature: {\n",
    "    'color':'green',\n",
    "    'weight':0.5\n",
    "}) \n",
    "control_shp.add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotG.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resG['CAT'] = inH['CAT']\n",
    "plotG = pd.DataFrame(resG.groupby('CAT').sum())\n",
    "plotG = pd.DataFrame(plotG.drop(['ghsl_P2030LIN', 'ghsl_P2025LIN', \"AMMAN\",\"TREAT\",\"CONTROL\"], axis=1))\n",
    "plotG = plotG.drop(\"\")\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "\n",
    "plt.plot(plotG.transpose()/10000000, label=list(plotG.index))\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel(\"Meters sq of built area (10,000,000s)\")\n",
    "plt.xlabel(\"Global Human Settlement Layer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotG.transpose().plot.bar(stacked=False, ylabel=\"Meters sq of built area (10,000,000s)\", xlabel=\"Year built (Global Human Settlement Layer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resP['CAT'] = inH['CAT']\n",
    "plotG = pd.DataFrame(resP.groupby('CAT').sum())\n",
    "plotG = plotG.drop(\"\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "\n",
    "plt.plot(plotG.transpose()/1000000, label=list(plotG.index))\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel(\"WorldPop Population (1,000,000s)\")\n",
    "plt.xlabel(\"WorldPop\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#resH['CAT'] = inH['CAT']\n",
    "plotG = pd.DataFrame(np.log10(res_annual.groupby('CAT').sum()))\n",
    "plotG = plotG.drop([''])\n",
    "#plotG = plotG.drop(['AMMAN','TREAT','CONTROL'], axis=1)\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.plot(plotG.transpose(), label=list(plotG.index))\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel(\"log(Nighttime Lights Brightness)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate per capita maps of NTL and GHSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntlD = res_annual.copy()\n",
    "for col in ntlD.columns:\n",
    "    if col.startswith('ntl'):\n",
    "        year = col.split(\"_\")[-1]\n",
    "        print(year)\n",
    "        try:\n",
    "            curP = np.log10(resP.loc[:,[year in x for x in resP.columns]].iloc[:,0])\n",
    "            curN = np.log10(ntlD.loc[:,col].values)\n",
    "            ntlD[col] = [x[1]/x[0] for x in zip(curP, curN)]\n",
    "        except:\n",
    "            ntlD.drop([col], axis=1, inplace=True)\n",
    "\n",
    "            \n",
    "plotG = pd.DataFrame(ntlD.groupby('CAT').sum())\n",
    "plotG = plotG.drop(\"\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.plot(plotG.transpose(), label=list(plotG.index))\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel(\"log(Nighttime Lights Brightness) per log(person)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotG.to_csv(ntl_pop_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ntlG = resG.drop(['geometry','AMMAN','TREAT','CONTROL'], axis=1).copy()\n",
    "for col in ntlG.columns:\n",
    "    if col.startswith('ghsl'):\n",
    "        year = col[-4:]\n",
    "        try:\n",
    "            curP = resP.loc[:,[year in x for x in resP.columns]].iloc[:,0]\n",
    "            curN = ntlG.loc[:,col].values\n",
    "            ntlG[col] = [x[1]/x[0] for x in zip(curP, curN)]    \n",
    "        except:\n",
    "            ntlG.drop([col], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotG = pd.DataFrame(ntlG.groupby('CAT').sum())\n",
    "plotG = plotG.drop(\"\")\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.plot(plotG.transpose(), label=list(plotG.index))\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel(\"Built area per person\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotG.transpose().plot.bar(stacked=False, ylabel=\"Built area per capita (m2/person)\", xlabel=\"Year built (Global Human Settlement Layer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Earth Engine",
   "language": "python",
   "name": "ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
