{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard library import, change path to GOSTnets path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peartree version: 0.6.1 \n",
      "networkx version: 2.3 \n",
      "matplotlib version: 3.0.3 \n",
      "osmnx version: 0.9 \n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST_PublicGoods\\GOSTNets\\GOSTNets')\n",
    "import GOSTnet as gn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destination Prep\n",
    "Here we seek to remove rows in the destination files which don't have valid Latitude / Longitude coordinate pairs, and standardize column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define path variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = r'C:\\Users\\charl\\Documents\\GOST\\SierraLeone\\Destinations'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import schools dataset, remove rows which don't have both a valid Latitude and Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\Anaconda3\\envs\\Cfox2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (10,15,34,82,521) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(pth, \"schools.csv\"))\n",
    "df = df.loc[(df.LATITUDE.isna() == False) & (df.LONGITUDE.isna() == False)]\n",
    "df.to_csv(os.path.join(pth, \"schools.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import health center dataset, remove rows which don't have both a valid Latitude and Longitude, rename columns to be consistent with schools dataset\n",
    "\n",
    "N.B. commented out, as it won't work if run more than once - columns will cease to exist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(pth, \"health_centers.csv\"), encoding = 'utf-8')\n",
    "#df = df.loc[(df.Lat.isna() == False) & (df.Long.isna() == False)]\n",
    "#df = df.rename({'Lat':'LATITUDE','Long':'LONGITUDE'}, axis = 1)\n",
    "df.to_csv(os.path.join(pth, \"health_centers.csv\"), encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Largest Graph\n",
    "\n",
    "Here, we generate shapefiles of the connected network and those roads which are disconnected. Though not necessary for the analysis, this is a useful process to go through to:\n",
    "1.) visually appraise the quality of the OSM network\n",
    "2.) identify large subgraphs that need to be manually connected to the main network\n",
    "3.) support network improvement activities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Processed Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_pth = r'C:\\Users\\charl\\Documents\\GOST\\SierraLeone\\RoadNet'\n",
    "G = nx.read_gpickle(os.path.join(net_pth, 'SLE_processed.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a unique value to every edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0\n",
    "for u, v, data in G.edges(data = True):\n",
    "    data['unique_id'] = q\n",
    "    q+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify largest subgraph by making a list of all subgraphs, iterating through them, and setting a variable to the maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_graphs = list(nx.strongly_connected_component_subgraphs(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edges = 0\n",
    "for q in range(0, len(list_of_graphs)):\n",
    "        g = list_of_graphs[q]\n",
    "        if g.number_of_edges() > max_edges:\n",
    "            max_edges = g.number_of_edges()\n",
    "            t = q\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the results of this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest graphs is the graph in position 0, and has 139617 edges\n"
     ]
    }
   ],
   "source": [
    "print(\"The largest graphs is the graph in position %s, and has %s edges\" % (t, max_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define largest graph as its own object, save down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_G = list_of_graphs[t]\n",
    "gn.save(largest_G, 'largest_G', r'C:\\Users\\charl\\Documents\\GOST\\SierraLeone\\RoadNet')\n",
    "edge_gdf_largest_G = gn.edge_gdf_from_graph(largest_G)\n",
    "\n",
    "# Turn into shapefile\n",
    "edge_gdf_largest_G = edge_gdf_largest_G.drop('geometry', axis = 1)\n",
    "edge_gdf_largest_G['Wkt'] = edge_gdf_largest_G['Wkt'].apply(lambda x: gn.unbundle_geometry(x))\n",
    "edge_gdf_largest_G = edge_gdf_largest_G.set_geometry('Wkt')\n",
    "edge_gdf_largest_G.to_file(os.path.join(r'C:\\Users\\charl\\Documents\\GOST\\SierraLeone\\RoadNet','LargestG.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a shapefile of all the edges that aren't in the main graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_gdf = gn.edge_gdf_from_graph(G)\n",
    "\n",
    "edges_in_largest_G = list(edge_gdf_largest_G.unique_id)\n",
    "\n",
    "edges_NOT_in_largest_G = edge_gdf.loc[~edge_gdf.unique_id.isin(edges_in_largest_G)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_NOT_in_largest_G = edges_NOT_in_largest_G.drop('geometry', axis = 1)\n",
    "edges_NOT_in_largest_G['Wkt'] = edges_NOT_in_largest_G['Wkt'].apply(lambda x: gn.unbundle_geometry(x))\n",
    "edges_NOT_in_largest_G = edges_NOT_in_largest_G.set_geometry('Wkt')\n",
    "edges_NOT_in_largest_G.to_file(os.path.join(r'C:\\Users\\charl\\Documents\\GOST\\SierraLeone\\RoadNet','DisconnectedRoads.shp'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Cfox2)",
   "language": "python",
   "name": "cfox2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
