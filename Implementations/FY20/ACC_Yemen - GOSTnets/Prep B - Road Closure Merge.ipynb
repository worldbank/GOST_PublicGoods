{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep B - Road Closure Merge\n",
    "\n",
    "It is well known that conflict leads to road damage and closure - with various factions setting up road blocks, and munitions damaging road surfaces, sometimes in major ways. \n",
    "\n",
    "We received from the UN Logistics Cluster (via Dr. Kent Garber, World Bank) the latest road closure information for Yemen, as well as 4 file versions for previous time periods. However, this information is limited to only the largest grade roads in the area (main roads, paved) whereas our own network is derived from Open Street Map which has been purposefully improved over the region. As such, we want to spatially join the information from this road shapefile over to our own network. This is what this script accomplishes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the usual suspects. If you have installed GOSTnets via conda, you will not need to append to the system path as we have done below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peartree version: 0.6.1 \n",
      "networkx version: 2.3 \n",
      "matplotlib version: 3.0.3 \n",
      "osmnx version: 0.9 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST_PublicGoods\\GOSTNets\\GOSTNets')\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST')\n",
    "import GOSTnet as gn\n",
    "import importlib\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from shapely.wkt import loads\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Road Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up net_graph as the pickled network object. We are using the Salted network with time attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bp = r'C:\\Users\\charl\\Documents\\GOST\\Yemen'\n",
    "net_graph = nx.read_gpickle(os.path.join(bp, 'YEM', 'Round 3', 'G_salty_time.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we add a new attribute - ID - for each edge, and then generate a GeoDataFrame from the graph's edges using GOSTnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 1\n",
    "for u, v, data in net_graph.edges(data = True):\n",
    "    data['ID'] = counter\n",
    "    counter+=1\n",
    "net_graph_edge_gdf = gn.edge_gdf_from_graph(net_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match on Conflict information to Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we set up for a large loop, where we iteratively read in and spatially match on the information from each shapefile on to our main graph object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of the files and their dates to iterate through\n",
    "settings = [\n",
    "{'date':'November1st',\n",
    "'f_name':'Access_20181101.shp'},\n",
    "{'date':'November8th',\n",
    "'f_name':'Access_20181108.shp'},\n",
    "{'date':'November14th',\n",
    "  'f_name':r'Access_20181114.shp'}, \n",
    "{'date':'November25th',\n",
    "'f_name':'Access_20181125.shp'},\n",
    "{'date':'December17th',\n",
    "'f_name':'Access_20181217.shp'},\n",
    "{'date':'January24th',\n",
    "'f_name':r'Access_20190124.shp'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the main loop. Pay attention to in-line commentary to see how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up a spatial index using the GeoPandas .sindex method\n",
    "smol = net_graph_edge_gdf\n",
    "spatial_index = smol.sindex\n",
    "\n",
    "# iterate through our settings list....\n",
    "for setting in settings:\n",
    "    \n",
    "    # Extract from the setting dictionary the filename and the date it relates to\n",
    "    f_name = setting['f_name']\n",
    "    date = setting['date']\n",
    "\n",
    "    # read in the UN logistics cluster shapefile for that date using f_name\n",
    "    conflict = gpd.read_file(os.path.join(r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\Conflicts\\Road Networks (UN Logistics Cluster)',f_name))\n",
    "    \n",
    "    # pick out only the roads where their status is either restricted or closed. The rest of the roads are in full working operation\n",
    "    conflict = conflict.loc[conflict.status.isin(['Restricted','Closed'])]\n",
    "    \n",
    "    # Reproject the conflict-affected roads to UTM zone \n",
    "    conflict = conflict.to_crs({'init':'epsg:32638'})\n",
    "    \n",
    "    # Buffer these roads by 50 meters\n",
    "    conflict['buffered'] = conflict.buffer(50)\n",
    "    \n",
    "    # reset the GeoDataFrame's geometry attribute to the buffered road geometry\n",
    "    conflict = conflict.set_geometry('buffered')\n",
    "    \n",
    "    # reset the projection to WGS 84\n",
    "    conflict = conflict.to_crs({'init':'epsg:4326'})\n",
    "    \n",
    "    # split out the restricted and the closed roads into their only GeoDataFrames\n",
    "    conflict_restricted = conflict.copy()\n",
    "    conflict_restricted = conflict_restricted.loc[conflict_restricted.status.isin(['Restricted'])]\n",
    "    conflict_closed = conflict.copy()\n",
    "    conflict_closed = conflict_closed.loc[conflict_closed.status.isin(['Closed'])]\n",
    "    \n",
    "    # now, we iterate through each closed road, and use the spatial index to quickly identify \n",
    "    # intersecting graph edges with the buffered closed roads. This may capture a few more roads that strictly necessary, but \n",
    "    # that is a price we are willing to pay, and probably reflects the 'on the ground' situation (remember no edge is longer than 2km anyway)\n",
    "    close = []\n",
    "    for index, row in conflict_closed.iterrows():\n",
    "        polygon = row.buffered\n",
    "        possible_matches_index = list(spatial_index.intersection((polygon.bounds)))\n",
    "        possible_matches = smol.iloc[possible_matches_index]\n",
    "        precise_matches = possible_matches[possible_matches.intersects(polygon)]\n",
    "        i = list(precise_matches.ID)\n",
    "        if len(i) !=0:\n",
    "            close.append(i)\n",
    "    close = [item for sublist in close for item in sublist]\n",
    "    \n",
    "    # we perform the same operation now on restricted roads\n",
    "    restrict = []\n",
    "    for index, row in conflict_restricted.iterrows():\n",
    "        polygon = row.buffered\n",
    "        possible_matches_index = list(spatial_index.intersection((polygon.bounds)))\n",
    "        possible_matches = smol.iloc[possible_matches_index]\n",
    "        precise_matches = possible_matches[possible_matches.intersects(polygon)]\n",
    "        i = list(precise_matches.ID)\n",
    "        if len(i) !=0:\n",
    "            restrict.append(i)\n",
    "    restrict = [item for sublist in restrict for item in sublist]\n",
    "    \n",
    "    # Closed roads are a 'higher order' problem that restricted roads. As such, should the buffer nature \n",
    "    # of the process have assigned a road both to the closed AND restricted buckets, we remove it from the restricted bucket. \n",
    "    # this shouldn't happen too often, but is entirely possible where a closed road meets a restricted road. \n",
    "    for i in restrict:\n",
    "        if i in close:\n",
    "            restrict.remove(i)\n",
    "    \n",
    "    # now, we iterate through the edges, and check to see whether their IDs crop up in the list items 'close' and 'restrict' - \n",
    "    # and if so, we adjust their time accordingly. \n",
    "    for u, v, data in net_graph.edges(data = True):\n",
    "        \n",
    "        # if a road is on the restricted list, we double the travel time. \n",
    "        if data['ID'] in restrict:\n",
    "            data['time_%s' % date] = data['time'] * 2\n",
    "            data['MOD_%s' % date] = 'restricted'\n",
    "            \n",
    "        # if a road is closed, we make the travel time very, very large. \n",
    "        elif data['ID'] in close:\n",
    "            data['time_%s' % date] = 99999999\n",
    "            data['MOD_%s' % date] = 'closed'\n",
    "            \n",
    "        # otherwise, we pass\n",
    "        else:\n",
    "            data['time_%s' % date] = data['time']\n",
    "            data['MOD_%s' % date] = 'normal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the resulting graph down as 'conflict adjusted'. Note, we did not edit the 'time' property, but set a NEW property for the travel time as of the date of the conflict info - so the original time can still be accessed from the conflcit adjusted Graph object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gn.save(net_graph, 'G_salty_time_conflict_adj', os.path.join(bp, 'YEM', 'Round 3'), nodes = False, edges = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snap on "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we also snap on our facility file and origin files to the conflcit adjusted graph. \n",
    "\n",
    "Although we did not change any nodes, its always nice to be sure you are working with the latest and greatest file version :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5042\n",
      "4411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\Documents\\GitHub\\GOST_PublicGoods\\GOSTNets\\GOSTNets\\GOSTnet.py:1620: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  G_tree = spatial.KDTree(node_gdf[['x','y']].as_matrix())\n",
      "C:\\Users\\charl\\Documents\\GitHub\\GOST_PublicGoods\\GOSTNets\\GOSTNets\\GOSTnet.py:1622: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  distances, indices = G_tree.query(in_df[['x','y']].as_matrix())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed: 12 seconds\n"
     ]
    }
   ],
   "source": [
    "dfiles = ['HeRAMS 2018 April.csv']\n",
    "\n",
    "dpath = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\facility_files'\n",
    "wpath = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\graphtool'\n",
    "\n",
    "for dfile in dfiles:\n",
    "    # Read in\n",
    "    dest_df = pd.read_csv(os.path.join(os.path.join(dpath, dfile)), encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    # Ensure coordinates are floats\n",
    "    dest_df.Longitude = dest_df.Longitude.astype(float)\n",
    "    dest_df.Latitude = dest_df.Latitude.astype(float)\n",
    "    \n",
    "    # Drop entries with no coordinates    \n",
    "    dest_df2 = dest_df.copy()\n",
    "    print(len(dest_df2))\n",
    "    dest_df2 = dest_df2.loc[(dest_df2.Longitude != 0)]\n",
    "    dest_df2 = dest_df2.loc[(dest_df2.Longitude != None)]\n",
    "    dest_df2 = dest_df2.loc[(dest_df2.Longitude <= 60)]\n",
    "    dest_df2 = dest_df2.loc[(dest_df2.Longitude >= 35)]\n",
    "    dest_df2 = dest_df2.loc[(dest_df2.Latitude <= 30)]\n",
    "    dest_df2 = dest_df2.loc[(dest_df2.Latitude >= 5)]\n",
    "    print(len(dest_df2))\n",
    "    dest_df = dest_df2\n",
    "    \n",
    "    # Generate Geometries\n",
    "    dest_df['geometry'] = list(zip(dest_df.Longitude, dest_df.Latitude))\n",
    "    dest_df['geometry'] = dest_df['geometry'].apply(Point)\n",
    "    dest_df = gpd.GeoDataFrame(dest_df, geometry = 'geometry', crs = {'init':'espg:4326'})\n",
    "    \n",
    "    # Perform snap\n",
    "    time.ctime()\n",
    "    start = time.time()\n",
    "    df = gn.pandana_snap(net_graph, dest_df, 'epsg:4326','epsg:32638', add_dist_to_node_col = True)\n",
    "    \n",
    "    # Save to file\n",
    "    df.to_csv(os.path.join(wpath, dfile.replace('.csv', '_snapped.csv')))\n",
    "    df.to_csv(os.path.join(dpath, dfile.replace('.csv', '_snapped.csv')))\n",
    "\n",
    "    print('time elapsed: %d seconds' % (time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning snap\n",
      "Time elapsed: 166 seconds\n"
     ]
    }
   ],
   "source": [
    "ofile = r'origins_1km.csv'\n",
    "ofiles = [ofile] \n",
    "opath = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\origins'\n",
    "for ofile in ofiles:\n",
    "    \n",
    "    # Read in\n",
    "    dest_df = pd.read_csv(os.path.join(os.path.join(opath, ofile)), encoding = \"ISO-8859-1\")\n",
    "    dest_df['geometry'] = dest_df['geometry'].apply(loads)\n",
    "    dest_df = gpd.GeoDataFrame(dest_df, geometry = 'geometry', crs = {'init':'espg:4326'})\n",
    "    \n",
    "    # Perform snap\n",
    "    print('Beginning snap')\n",
    "    \n",
    "    time.ctime()\n",
    "    start = time.time()\n",
    "    df = gn.pandana_snap(net_graph, dest_df, 'epsg:4326','epsg:32638', add_dist_to_node_col = True)\n",
    "    \n",
    "    # Save to file\n",
    "    df.to_csv(os.path.join(wpath, ofile.replace('.csv', '_snapped.csv')))\n",
    "    df.to_csv(os.path.join(opath, ofile.replace('.csv', '_snapped.csv')))\n",
    "\n",
    "    print('Time elapsed: %d seconds' % (time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
