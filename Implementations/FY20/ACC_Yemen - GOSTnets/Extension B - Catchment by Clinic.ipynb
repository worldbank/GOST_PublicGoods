{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension B - Catchment by Clinic\n",
    "\n",
    "This is the final analysis that has been done for the Yemen project. It aims to identify the number of people that can access a clinic within a given time frame, and also the number of unique users - the people who can ONLY access a given healthcare facility within the time frame, and no subsitute clinic.\n",
    "\n",
    "This process is very closely modelled on Step 4 - Generate Results. Read that notebook first to get a feel for what is going on. It breaks from this process at the point labelled 'BREAK' - annotations will begin from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "sys.path.append(r'/home/public/GOST_PublicGoods/GOSTNets/GOSTNets')\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST')\n",
    "import GOSTnet as gn\n",
    "import importlib\n",
    "import geopandas as gpd\n",
    "import rasterio as rt\n",
    "from rasterio import features\n",
    "from shapely.wkt import loads\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from shapely.geometry import box, Point, Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "walking = 1 # set to 1 for walking\n",
    "conflict = 1 # set to 1 to prevent people from crossing warfronts\n",
    "zonal_stats = 1 # set to 1 to produce summary zonal stats layer\n",
    "facility_type = 'HOS'   # Options: 'HOS' or 'PHC' or 'ALL'\n",
    "year = 2018   # default = 2018\n",
    "service_index = 0 # Set to 0 for all services / access to hospitals\n",
    "\n",
    "services = ['ALL',\n",
    "            'Antenatal',\n",
    "            'BEmONC',\n",
    "            'CEmONC',\n",
    "            'Under_5',\n",
    "            'Emergency_Surgery',\n",
    "            'Immunizations',\n",
    "            'Malnutrition',\n",
    "            'Int_Outreach']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import All-Destination OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "basepth = r'/home/wb493355/data/yemen/Round 3'\n",
    "pth = os.path.join(basepth, 'graphtool')\n",
    "util_path = os.path.join(basepth, 'util_files')\n",
    "srtm_pth = os.path.join(basepth, 'SRTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files will have name:  walking_24th_HERAMS_HOS_ALL_ConflictAdj_2018_YEHNP_only\n",
      "network:  walk_graph.pickle\n",
      "OD Matrix:  OD_normal_walking_2018.csv\n",
      "Conflict setting:  ConflictAdj\n"
     ]
    }
   ],
   "source": [
    "if conflict == 1: \n",
    "    conflict_tag = 'ConflictAdj'\n",
    "    appendor = 'Jan24th'\n",
    "else:\n",
    "    conflict_tag = 'NoConflict'\n",
    "    appendor = 'normal'\n",
    "    \n",
    "if walking == 1:\n",
    "    type_tag = 'walking'\n",
    "    net_name = r'walk_graph.pickle'\n",
    "    appendor = 'normal'\n",
    "else:\n",
    "    type_tag = 'driving'\n",
    "    net_name = r'G_salty_time_conflict_adj.pickle'\n",
    "\n",
    "YEHNP = 1\n",
    "\n",
    "OD_pth = pth\n",
    "net_pth = pth\n",
    "\n",
    "OD_name = r'OD_%s_%s_%s.csv' % (appendor, type_tag, year)\n",
    "\n",
    "WGS = {'init':'epsg:4326'}\n",
    "measure_crs = {'init':'epsg:32638'}\n",
    "\n",
    "subset = r'%s_24th_HERAMS_%s_%s_%s_%s' % (type_tag, facility_type, services[service_index], conflict_tag, year)\n",
    "    \n",
    "if YEHNP == 1:\n",
    "    subset = subset+'_YEHNP_only'\n",
    "elif YEHNP == -1:\n",
    "    subset = subset+'_Excl_YEHNP'\n",
    "        \n",
    "print(\"Output files will have name: \", subset)\n",
    "print(\"network: \",net_name)\n",
    "print(\"OD Matrix: \",OD_name)\n",
    "print(\"Conflict setting: \",conflict_tag)\n",
    "                                            \n",
    "offroad_speed = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OD = pd.read_csv(os.path.join(OD_pth, OD_name))\n",
    "OD = OD.rename(columns = {'Unnamed: 0':'O_ID'})\n",
    "OD = OD.set_index('O_ID')\n",
    "OD = OD.replace([np.inf, -np.inf], np.nan)\n",
    "OD_original = OD.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Subset to Accepted Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "acceptable_df = pd.read_csv(os.path.join(OD_pth, 'HeRAMS 2018 April_snapped.csv'))\n",
    "\n",
    "# Adjust for facility type\n",
    "if facility_type == 'HOS':\n",
    "    acceptable_df = acceptable_df.loc[acceptable_df['Health Facility Type Coded'].isin(['1',1])]\n",
    "elif facility_type == 'PHC':\n",
    "    acceptable_df = acceptable_df.loc[acceptable_df['Health Facility Type Coded'].isin([2,'2',3,'3'])]\n",
    "elif facility_type == 'ALL':\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('unacceptable facility_type entry!')\n",
    "\n",
    "# Adjust for facility type\n",
    "if YEHNP == 1 and facility_type == 'HOS':\n",
    "    acceptable_df = acceptable_df.loc[(acceptable_df['YEHNP_Hospitals'] == 1)]\n",
    "elif YEHNP == 1 and facility_type == 'PHC':\n",
    "    acceptable_df = acceptable_df.loc[(acceptable_df['YEHNP_PHCs'] == 1)]\n",
    "elif YEHNP == -1 and facility_type == 'HOS':\n",
    "    acceptable_df = acceptable_df.loc[(acceptable_df['YEHNP_Hospitals'] != 1)]\n",
    "elif YEHNP == -1 and facility_type == 'PHC':\n",
    "    acceptable_df = acceptable_df.loc[(acceptable_df['YEHNP_PHCs'] != 1)]\n",
    "\n",
    "# Adjust for functionality in a given year\n",
    "acceptable_df = acceptable_df.loc[acceptable_df['Functioning %s' % year].isin(['1','2',1,2])]\n",
    "\n",
    "# Adjust for availability of service\n",
    "\n",
    "SERVICE_DICT = {'Antenatal_2018':'ANC 2018',\n",
    "               'Antenatal_2016':'Antenatal Care (P422) 2016',\n",
    "               'BEmONC_2018':'Basic emergency obstetric care 2018',\n",
    "               'BEmONC_2016':'Basic Emergency Obsteteric Care (P424) 2016',\n",
    "               'CEmONC_2018':'Comprehensive emergency obstetric care 2018',\n",
    "               'CEmONC_2016':'Comprehensive Emergency Obstetric Care (S424) 2016',\n",
    "               'Under_5_2018':'Under 5 clinics 2018',\n",
    "               'Under_5_2016':'Under-5 clinic services (P23) 2016',\n",
    "               'Emergency_Surgery_2018':'Emergency and elective surgery 2018',\n",
    "               'Emergency_Surgery_2016':'Emergency and Elective Surgery (S14) 2016',\n",
    "               'Immunizations_2018':'EPI 2018',\n",
    "               'Immunizations_2016':'EPI (P21a) 2016',\n",
    "               'Malnutrition_2018':'Malnutrition services 2018',\n",
    "               'Malnutrition_2016':'Malnutrition services (P25) 2016',\n",
    "               'Int_Outreach_2018':'Integrated outreach (IMCI+EPI+ANC+Nutrition_Services) 2018',\n",
    "               'Int_Outreach_2016':'Integrated Outreach (P22) 2016'}\n",
    "\n",
    "if service_index == 0:\n",
    "    pass\n",
    "else:\n",
    "    acceptable_df = acceptable_df.loc[acceptable_df[SERVICE_DICT['%s_%s' % (services[service_index],year)]].isin(['1',1])]\n",
    "print(len(acceptable_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36624, 3824)\n",
      "(36624, 64)\n"
     ]
    }
   ],
   "source": [
    "acceptable_df['geometry'] = acceptable_df['geometry'].apply(loads)\n",
    "acceptable_gdf = gpd.GeoDataFrame(acceptable_df, geometry = 'geometry', crs = {'init':'epsg:4326'})\n",
    "accepted_facilities = list(set(list(acceptable_df.NN)))\n",
    "accepted_facilities_str = [str(i) for i in accepted_facilities]\n",
    "OD = OD_original[accepted_facilities_str]\n",
    "acceptable_df.to_csv(os.path.join(basepth,'output_layers','Round 3','%s.csv' % subset))\n",
    "print(OD_original.shape)\n",
    "print(OD.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to add elevation to a point GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_elevation(df, x, y, srtm_pth):\n",
    "    # walk all tiles, find path\n",
    "    \n",
    "    tiles = []\n",
    "    for root, folder, files in os.walk(os.path.join(srtm_pth,'high_res')):\n",
    "        for f in files:\n",
    "            if f[-3:] == 'hgt':\n",
    "                tiles.append(f[:-4])\n",
    "\n",
    "    # load dictionary of tiles\n",
    "    arrs = {}\n",
    "    for t in tiles:\n",
    "        arrs[t] = rt.open(os.path.join(srtm_pth, 'high_res', '{}.hgt'.format(t), '{}.hgt'.format(t)), 'r')\n",
    "\n",
    "    # assign a code\n",
    "    uniques = []\n",
    "    df['code'] = 'placeholder'\n",
    "    def tile_code(z):\n",
    "        E = str(z[x])[:2]\n",
    "        N = str(z[y])[:2]\n",
    "        return 'N{}E0{}'.format(N, E)\n",
    "    df['code'] = df.apply(lambda z: tile_code(z), axis = 1)\n",
    "    unique_codes = list(set(df['code'].unique()))\n",
    "    \n",
    "    z = {}\n",
    "    # Match on High Precision Elevation\n",
    "    property_name = 'elevation'\n",
    "    for code in unique_codes:\n",
    "        \n",
    "        df2 = df.copy()\n",
    "        df2 = df2.loc[df2['code'] == code]\n",
    "        dataset = arrs[code]\n",
    "        b = dataset.bounds\n",
    "        datasetBoundary = box(b[0], b[1], b[2], b[3])\n",
    "        selKeys = []\n",
    "        selPts = []\n",
    "        for index, row in df2.iterrows():\n",
    "            if Point(row[x], row[y]).intersects(datasetBoundary):\n",
    "                selPts.append((row[x],row[y]))\n",
    "                selKeys.append(index)\n",
    "        raster_values = list(dataset.sample(selPts))\n",
    "        raster_values = [x[0] for x in raster_values]\n",
    "\n",
    "        # generate new dictionary of {node ID: raster values}\n",
    "        z.update(zip(selKeys, raster_values))\n",
    "        \n",
    "    elev_df = pd.DataFrame.from_dict(z, orient='index')\n",
    "    elev_df.columns = ['elevation']\n",
    "    \n",
    "    missing = elev_df.copy()\n",
    "    missing = missing.loc[missing.elevation < 0]\n",
    "    if len(missing) > 0:\n",
    "        missing_df = df.copy()\n",
    "        missing_df = missing_df.loc[missing.index]\n",
    "        low_res_tifpath = os.path.join(srtm_pth, 'clipped', 'clipped_e20N40.tif')\n",
    "        dataset = rt.open(low_res_tifpath, 'r')\n",
    "        b = dataset.bounds\n",
    "        datasetBoundary = box(b[0], b[1], b[2], b[3])\n",
    "        selKeys = []\n",
    "        selPts = []\n",
    "        for index, row in missing_df.iterrows():\n",
    "            if Point(row[x], row[y]).intersects(datasetBoundary):\n",
    "                selPts.append((row[x],row[y]))\n",
    "                selKeys.append(index)\n",
    "        raster_values = list(dataset.sample(selPts))\n",
    "        raster_values = [x[0] for x in raster_values]\n",
    "        z.update(zip(selKeys, raster_values))\n",
    "\n",
    "        elev_df = pd.DataFrame.from_dict(z, orient='index')\n",
    "        elev_df.columns = ['elevation']\n",
    "    df['point_elev'] = elev_df['elevation']\n",
    "    df = df.drop('code', axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to convert distances to walk times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_walktimes(df, start = 'point_elev', end = 'node_elev', dist = 'NN_dist', max_walkspeed = 6, min_speed = 0.1):\n",
    "    # Tobler's hiking function: https://en.wikipedia.org/wiki/Tobler%27s_hiking_function\n",
    "    def speed(incline_ratio, max_speed):\n",
    "        walkspeed = max_speed * np.exp(-3.5 * abs(incline_ratio + 0.05)) \n",
    "        return walkspeed\n",
    "\n",
    "    speeds = {}\n",
    "    times = {}\n",
    "\n",
    "    for index, data in df.iterrows():\n",
    "        if data[dist] > 0:\n",
    "            delta_elevation = data[end] - data[start]\n",
    "            incline_ratio = delta_elevation / data[dist]\n",
    "            speed_kmph = speed(incline_ratio = incline_ratio, max_speed = max_walkspeed)\n",
    "            speed_kmph = max(speed_kmph, min_speed)\n",
    "            speeds[index] = (speed_kmph)\n",
    "            times[index] = (data[dist] / 1000 * 3600 / speed_kmph)\n",
    "\n",
    "    speed_df = pd.DataFrame.from_dict(speeds, orient = 'index')\n",
    "    time_df = pd.DataFrame.from_dict(times, orient = 'index')\n",
    "\n",
    "    df['walkspeed'] = speed_df[0]\n",
    "    df['walk_time'] = time_df[0]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add elevation for destination nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wb493355/.conda/envs/templateA/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/wb493355/.conda/envs/templateA/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/wb493355/.conda/envs/templateA/lib/python3.7/site-packages/ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "dest_df = acceptable_df[['NN','NN_dist','Latitude','Longitude']]\n",
    "dest_df = add_elevation(dest_df, 'Longitude','Latitude', srtm_pth).set_index('NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add elevation from graph nodes (reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = nx.read_gpickle(os.path.join(OD_pth, net_name))\n",
    "G_node_df = gn.node_gdf_from_graph(G)\n",
    "G_node_df = add_elevation(G_node_df, 'x', 'y', srtm_pth)\n",
    "match_node_elevs = G_node_df[['node_ID','point_elev']].set_index('node_ID')\n",
    "match_node_elevs.loc[match_node_elevs.point_elev < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match on node elevations for dest_df; calculate travel times to nearest node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dest_df['node_elev'] = match_node_elevs['point_elev']\n",
    "dest_df = generate_walktimes(dest_df, start = 'node_elev', end = 'point_elev', dist = 'NN_dist', max_walkspeed = offroad_speed)\n",
    "dest_df = dest_df.sort_values(by = 'walk_time', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Walk Time to all travel times in OD matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dest_df = dest_df[['walk_time']]\n",
    "dest_df.index = dest_df.index.map(str)\n",
    "\n",
    "d_f = OD.transpose()\n",
    "\n",
    "for i in d_f.columns:\n",
    "    dest_df[i] = d_f[i]\n",
    "    \n",
    "for i in dest_df.columns:\n",
    "    if i == 'walk_time':\n",
    "        pass\n",
    "    else:\n",
    "        dest_df[i] = dest_df[i] + dest_df['walk_time']\n",
    "\n",
    "dest_df = dest_df.drop('walk_time', axis = 1)\n",
    "\n",
    "dest_df = dest_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Shapefile Describing Regions of Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if conflict == 1:\n",
    "    conflict_file = r'merged_dists_%s.shp' % year\n",
    "elif conflict == 0:\n",
    "    conflict_file = r'NoConflict.shp'\n",
    "merged_dists = gpd.read_file(os.path.join(util_path, conflict_file))\n",
    "if merged_dists.crs != {'init':'epsg:4326'}:\n",
    "    merged_dists = merged_dists.to_crs({'init':'epsg:4326'})\n",
    "merged_dists = merged_dists.loc[merged_dists.geometry.type == 'Polygon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor in lines of Control - Import Areas of Control Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intersect points with merged districts shapefile, identify relationship\n",
    "\n",
    "def AggressiveSpatialIntersect(points, polygons):\n",
    "    import osmnx as ox\n",
    "    spatial_index = points.sindex\n",
    "    container = {}\n",
    "    cut_geoms = []\n",
    "    for index, row in polygons.iterrows():\n",
    "        polygon = row.geometry\n",
    "        if polygon.area > 0.5:\n",
    "            geometry_cut = ox.quadrat_cut_geometry(polygon, quadrat_width=0.5)\n",
    "            cut_geoms.append(geometry_cut)\n",
    "            print('cutting geometry %s into %s pieces' % (index, len(geometry_cut)))\n",
    "            index_list = []\n",
    "            for P in geometry_cut:\n",
    "                possible_matches_index = list(spatial_index.intersection(P.bounds))\n",
    "                possible_matches = points.iloc[possible_matches_index]\n",
    "                precise_matches = possible_matches[possible_matches.intersects(P)]\n",
    "                if len(precise_matches) > 0:\n",
    "                    index_list.append(precise_matches.index)\n",
    "                flat_list = [item for sublist in index_list for item in sublist]\n",
    "                container[index] = list(set(flat_list))\n",
    "        else:\n",
    "            possible_matches_index = list(spatial_index.intersection(polygon.bounds))\n",
    "            possible_matches = points.iloc[possible_matches_index]\n",
    "            precise_matches = possible_matches[possible_matches.intersects(polygon)]\n",
    "            if len(precise_matches) > 0:\n",
    "                container[index] = list(precise_matches.index)\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph_node_gdf = gn.node_gdf_from_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting geometry 56 into 121 pieces\n",
      "cutting geometry 59 into 47 pieces\n",
      "cutting geometry 78 into 236 pieces\n",
      "cutting geometry 79 into 16 pieces\n",
      "**bag of possible node snapping locations has been successfully generated**\n"
     ]
    }
   ],
   "source": [
    "gdf = graph_node_gdf.copy()\n",
    "gdf = gdf.set_index('node_ID')\n",
    "possible_snap_nodes = AggressiveSpatialIntersect(graph_node_gdf, merged_dists)\n",
    "print('**bag of possible node snapping locations has been successfully generated**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Match on network time from origin node (time travelling along network + walking to destination)\n",
    "if year == 2018:\n",
    "    year_raster = 2018\n",
    "elif year == 2016:\n",
    "    year_raster = 2015\n",
    "grid_name = r'origins_1km_%s_snapped.csv' % year_raster\n",
    "\n",
    "grid = pd.read_csv(os.path.join(OD_pth, grid_name))\n",
    "grid = grid.rename({'Unnamed: 0':'PointID'}, axis = 1)\n",
    "grid['geometry'] = grid['geometry'].apply(loads)\n",
    "grid_gdf = gpd.GeoDataFrame(grid, crs = WGS, geometry = 'geometry')\n",
    "grid_gdf = grid_gdf.set_index('PointID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust Nearest Node snapping for War"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting geometry 56 into 121 pieces\n",
      "cutting geometry 59 into 47 pieces\n",
      "cutting geometry 78 into 236 pieces\n",
      "cutting geometry 79 into 16 pieces\n",
      "bag of possible origins locations has been successfully generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/public/GOST_PublicGoods/GOSTNets/GOSTNets/GOSTnet.py:1699: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  G_tree = spatial.KDTree(target_gdf[['x','y']].as_matrix())\n",
      "/home/public/GOST_PublicGoods/GOSTNets/GOSTNets/GOSTnet.py:1701: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  distances, indices = G_tree.query(source_gdf[['x','y']].as_matrix())\n"
     ]
    }
   ],
   "source": [
    "origin_container = AggressiveSpatialIntersect(grid_gdf, merged_dists)\n",
    "print('bag of possible origins locations has been successfully generated')\n",
    "\n",
    "bundle = []\n",
    "for key in origin_container.keys():\n",
    "    origins = origin_container[key]\n",
    "    possible_nodes = graph_node_gdf.loc[possible_snap_nodes[key]]\n",
    "    origin_subset = grid_gdf.loc[origins]\n",
    "    origin_subset_snapped = gn.pandana_snap_points(origin_subset, \n",
    "                                possible_nodes, \n",
    "                                source_crs = 'epsg:4326', \n",
    "                                target_crs = 'epsg:32638', \n",
    "                                add_dist_to_node_col = True)\n",
    "    bundle.append(origin_subset_snapped)\n",
    "\n",
    "grid_gdf_adjusted = pd.concat(bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_gdf = grid_gdf_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add origin node distance to network - walking time\n",
    "grid = grid_gdf\n",
    "grid = add_elevation(grid, 'Longitude','Latitude', srtm_pth)\n",
    "grid = grid.reset_index()\n",
    "grid['O_ID'] = grid['NN']\n",
    "grid = grid.set_index('NN')\n",
    "grid['node_elev'] = match_node_elevs['point_elev']\n",
    "grid = grid.set_index('PointID')\n",
    "grid = generate_walktimes(grid, start = 'point_elev', end = 'node_elev', dist = 'NN_dist', max_walkspeed = offroad_speed)\n",
    "grid = grid.rename({'node_elev':'nr_node_on_net_elev', \n",
    "                    'walkspeed':'walkspeed_to_net', \n",
    "                    'walk_time':'walk_time_to_net',\n",
    "                   'NN_dist':'NN_dist_to_net',\n",
    "                   'O_ID':'NN',\n",
    "                   'Unnamed: 0.1':'PointID'}, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust acceptable destinations for each node for the war"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting geometry 56 into 121 pieces\n",
      "cutting geometry 59 into 47 pieces\n",
      "cutting geometry 78 into 236 pieces\n",
      "cutting geometry 79 into 16 pieces\n",
      "cutting geometry 56 into 121 pieces\n",
      "cutting geometry 59 into 47 pieces\n",
      "cutting geometry 78 into 236 pieces\n",
      "cutting geometry 79 into 16 pieces\n"
     ]
    }
   ],
   "source": [
    "gdf = graph_node_gdf.copy()\n",
    "gdf['node_ID'] = gdf['node_ID'].astype('str')\n",
    "gdf = gdf.loc[gdf.node_ID.isin(list(dest_df.columns))]\n",
    "gdf = gdf.set_index('node_ID')\n",
    "\n",
    "dest_container = AggressiveSpatialIntersect(gdf, merged_dists)\n",
    "\n",
    "gdf = graph_node_gdf.copy()\n",
    "gdf = gdf.loc[gdf.node_ID.isin(list(dest_df.index))]\n",
    "gdf = gdf.set_index('node_ID')\n",
    "\n",
    "origin_snap_container = AggressiveSpatialIntersect(gdf, merged_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BREAK\n",
    "\n",
    "From this point the script diverges from Step 4 - Generate Results. \n",
    "\n",
    "In this cell, we DO NOT use a min function to work out the closest destination to each origin cell. Instead, we merge on to the grid the travel time to ALL relevant destinations in the same polygon of homogeneous control that is accessible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "region: 56\n",
      "number of origin nodes in this reigon: 20249\n",
      "number of destination nodes in this reigon: 34\n",
      "How many destination facilities in this region? 34\n",
      "How many origin grid cells in this region? 145348\n",
      "\n",
      "region: 59\n",
      "number of origin nodes in this reigon: 1058\n",
      "number of destination nodes in this reigon: 1\n",
      "How many destination facilities in this region? 1\n",
      "How many origin grid cells in this region? 4371\n",
      "\n",
      "region: 70\n",
      "number of origin nodes in this reigon: 328\n",
      "number of destination nodes in this reigon: 2\n",
      "How many destination facilities in this region? 2\n",
      "How many origin grid cells in this region? 1172\n",
      "\n",
      "region: 78\n",
      "number of origin nodes in this reigon: 14015\n",
      "number of destination nodes in this reigon: 25\n",
      "How many destination facilities in this region? 25\n",
      "How many origin grid cells in this region? 393576\n",
      "\n",
      "region: 79\n",
      "number of origin nodes in this reigon: 974\n",
      "number of destination nodes in this reigon: 2\n",
      "How many destination facilities in this region? 2\n",
      "How many origin grid cells in this region? 4628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wb493355/.conda/envs/templateA/lib/python3.7/site-packages/ipykernel_launcher.py:32: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "bundle = []\n",
    "\n",
    "for key in origin_snap_container.keys():\n",
    "    \n",
    "    # print which polygon we are looking at\n",
    "    print('\\nregion:',key)\n",
    "    \n",
    "    # identify bundle of origin, dest nodes inside region\n",
    "    origins = origin_snap_container[key]\n",
    "    print('number of origin nodes in this reigon:',len(origins))\n",
    "    destinations = dest_container[key]\n",
    "    print('number of destination nodes in this reigon:',len(destinations))\n",
    "    \n",
    "    # get part of OD that is relevant\n",
    "    relevant_dests = dest_df.copy()\n",
    "    relevant_dests = relevant_dests[destinations].loc[origins]\n",
    "    print('How many destination facilities in this region?',len(relevant_dests.columns))\n",
    "    \n",
    "    # get part of grid that is relevant\n",
    "    relevant_grid = grid.copy()\n",
    "    relevant_grid = relevant_grid.loc[origin_container[key]]\n",
    "    print('How many origin grid cells in this region?',len(relevant_grid))\n",
    "    \n",
    "    # match on dest-df\n",
    "    relevant_grid = relevant_grid.set_index('NN')\n",
    "    for i in relevant_dests.columns:\n",
    "        relevant_grid[i] = relevant_dests[i]\n",
    "    \n",
    "    # append to bundle for reconstruction\n",
    "    bundle.append(relevant_grid)\n",
    "    \n",
    "combo_grid = pd.concat(bundle)\n",
    "combo_grid['PointID_copy'] = combo_grid['PointID']\n",
    "combo_grid = combo_grid.set_index('PointID')\n",
    "print(len(combo_grid[dest_df.columns].loc[241487].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we add the walk time to the network to the on-network time. This is the best way of representing the 'drive time' to each destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wb493355/.conda/envs/templateA/lib/python3.7/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "combo_grid2 = combo_grid.copy()\n",
    "\n",
    "# add on walk time\n",
    "for i in dest_df.columns:\n",
    "    combo_grid2[i].loc[combo_grid2[i].isna() == False] = combo_grid2[i].loc[combo_grid2[i].isna() == False] + combo_grid2['walk_time_to_net'].loc[combo_grid2[i].isna() == False]\n",
    "\n",
    "    \n",
    "combo_grid2 = combo_grid2.drop(['NN_dist_to_net','walk_time_to_net','walkspeed_to_net'], axis = 1)\n",
    "grid = combo_grid2\n",
    "\n",
    "print(len(combo_grid2[dest_df.columns].loc[241487].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Direct Walking Time (not using road network), vs. network Time\n",
    "\n",
    "The output of this block was not factored in, in the end. The problem was that, identifying the closest facility to the origin point is not useful when you are trying to retain the access time to ALL facilities in the same homogenous region. Ergo, we do not use this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting geometry 56 into 121 pieces\n",
      "cutting geometry 59 into 47 pieces\n",
      "cutting geometry 78 into 236 pieces\n",
      "cutting geometry 79 into 16 pieces\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "bundle = []\n",
    "\n",
    "W = graph_node_gdf.copy()\n",
    "W['node_ID'] = W['node_ID'].astype(str)\n",
    "W = W.set_index('node_ID')\n",
    "\n",
    "locations_gdf = gpd.GeoDataFrame(acceptable_df, geometry = 'geometry', crs = {'init':'epsg:4326'})\n",
    "locations_container = AggressiveSpatialIntersect(locations_gdf, merged_dists)\n",
    "\n",
    "for key in origin_container.keys():\n",
    "    origins = origin_container[key]\n",
    "    origin_subset = grid.copy()\n",
    "    origin_subset = origin_subset.loc[origins]\n",
    "    locations = locations_gdf.loc[locations_container[key]]\n",
    "    if len(locations) < 1:\n",
    "        origin_subset['NN'] = None\n",
    "        origin_subset['NN_dist'] = None\n",
    "        bundle.append(origin_subset)\n",
    "    else:\n",
    "        origin_subset_snapped = gn.pandana_snap_points(origin_subset, \n",
    "                                locations, \n",
    "                                source_crs = 'epsg:4326', \n",
    "                                target_crs = 'epsg:32638', \n",
    "                                add_dist_to_node_col = True)\n",
    "        bundle.append(origin_subset_snapped)\n",
    "\n",
    "grid_gdf_adjusted = pd.concat(bundle)\n",
    "grid = grid_gdf_adjusted\n",
    "print(len(grid[dest_df.columns].loc[241487].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate summary by Destination\n",
    "\n",
    "Here, for each time threshold, we return a binary version of the OD-matrix if the destination facility has a travel time beneath the threshold time, and sum for each facility. We also identify instances of where there is only one valid facility for a given origin - this will happen when the sum of a row is equal to the only value in the row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ag1 = grid.fillna(99999999999).copy()\n",
    "\n",
    "uniques, totals, test_frames_A, test_frames_B = {}, {}, {}, {}\n",
    "\n",
    "for thresh in [30, 60, 120, 240]:\n",
    "        \n",
    "    ag2 = ag1.copy()\n",
    "    \n",
    "    def convert(x, thresh):\n",
    "        if 0 < x < (thresh * 60):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # identify pop under thresh\n",
    "    for i in Dest_IDs:\n",
    "        ag2[i] = ag2[i].fillna(-1)\n",
    "        ag2[i] = ag2[i].apply(lambda x: convert(x, thresh))\n",
    "    \n",
    "    # add Valid column. counts up number of cells beneath travel time threshold. \n",
    "    ag2['VALID'] = ag2[Dest_IDs].sum(axis = 1)\n",
    "    \n",
    "    test_frames_A[thresh] = ag2.copy()\n",
    "    \n",
    "    # multiply through by population value\n",
    "    for i in Dest_IDs:\n",
    "        ag2[i] = ag2[i] * ag2['VALUE']\n",
    "        \n",
    "    # generate total of pop that can access a destination in under thresh mins\n",
    "    ag2['total'] = ag2[Dest_IDs].sum(axis = 1)\n",
    "    \n",
    "    test_frames_B[thresh] = ag2.copy()\n",
    "    \n",
    "    # compare to total, zero out values where less than total (i.e. not unique)\n",
    "    res_uniques, res_totals = [], []\n",
    "    \n",
    "    for i in Dest_IDs:\n",
    "        ag3 = ag2.copy()\n",
    "        res_uniques.append(ag3[i].loc[ag3['VALID'] == 1].sum())\n",
    "        res_totals.append(ag3[i].loc[ag3['VALID'] > 0].sum())\n",
    "                 \n",
    "    uniques[thresh] = res_uniques\n",
    "    totals[thresh] = res_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate the results DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame({'catchment_30':totals[30],\n",
    "                      'catchment_60':totals[60],\n",
    "                      'catchment_120':totals[120],\n",
    "                      'catchment_240':totals[240],\n",
    "                      'unique_30': uniques[30], \n",
    "                      'unique_60': uniques[60],\n",
    "                      'unique_120': uniques[120],\n",
    "                      'unique_240': uniques[240],\n",
    "                      'NN':Dest_IDs},\n",
    "                    index = Dest_IDs)\n",
    "\n",
    "# Generate 'fraction of catchment that is uniquely served by this facility' statistics. \n",
    "res_df['pct_unique_30'] = res_df['unique_30'] / res_df['catchment_30']\n",
    "res_df['pct_unique_60'] = res_df['unique_60'] / res_df['catchment_60']\n",
    "res_df['pct_unique_120'] = res_df['unique_120'] / res_df['catchment_120']\n",
    "res_df['pct_unique_240'] = res_df['unique_240'] / res_df['catchment_240']\n",
    "\n",
    "acceptable_df_res = acceptable_df.copy()\n",
    "acceptable_df_res['NN'] = acceptable_df_res['NN'].astype('str')\n",
    "acceptable_df_res = acceptable_df_res.set_index('NN')\n",
    "acceptable_df_res = acceptable_df_res.merge(res_df, on = 'NN')\n",
    "acceptable_df_res = acceptable_df_res.sort_values(by = 'pct_unique_30', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize it here to make sure it is what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>FID</th>\n",
       "      <th>Functionality</th>\n",
       "      <th>YEHNP_PHCs</th>\n",
       "      <th>YEHNP_Hospitals</th>\n",
       "      <th>Name of_Health_Facility</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Name of Governorate</th>\n",
       "      <th>...</th>\n",
       "      <th>catchment_120</th>\n",
       "      <th>catchment_240</th>\n",
       "      <th>unique_30</th>\n",
       "      <th>unique_60</th>\n",
       "      <th>unique_120</th>\n",
       "      <th>unique_240</th>\n",
       "      <th>pct_unique_30</th>\n",
       "      <th>pct_unique_60</th>\n",
       "      <th>pct_unique_120</th>\n",
       "      <th>pct_unique_240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31142</td>\n",
       "      <td>39</td>\n",
       "      <td>1102001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yarim .H</td>\n",
       "      <td>14.304533</td>\n",
       "      <td>44.370000</td>\n",
       "      <td>Ibb</td>\n",
       "      <td>...</td>\n",
       "      <td>106671.0</td>\n",
       "      <td>218656.0</td>\n",
       "      <td>44244.0</td>\n",
       "      <td>77271.0</td>\n",
       "      <td>106671.0</td>\n",
       "      <td>206411.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14344</td>\n",
       "      <td>227</td>\n",
       "      <td>1111011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Aladin H</td>\n",
       "      <td>13.965600</td>\n",
       "      <td>44.008767</td>\n",
       "      <td>Ibb</td>\n",
       "      <td>...</td>\n",
       "      <td>42751.0</td>\n",
       "      <td>138371.0</td>\n",
       "      <td>5098.0</td>\n",
       "      <td>12578.0</td>\n",
       "      <td>42751.0</td>\n",
       "      <td>132366.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.956602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>119219</td>\n",
       "      <td>2540</td>\n",
       "      <td>1924006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hajar Aljoul rural H (Al Faqeed Al Shadli H)</td>\n",
       "      <td>14.460983</td>\n",
       "      <td>48.279683</td>\n",
       "      <td>Hadramout</td>\n",
       "      <td>...</td>\n",
       "      <td>4263.0</td>\n",
       "      <td>9560.0</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>2678.0</td>\n",
       "      <td>4263.0</td>\n",
       "      <td>9560.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>55109</td>\n",
       "      <td>2749</td>\n",
       "      <td>2005004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26September rural H</td>\n",
       "      <td>14.491833</td>\n",
       "      <td>44.016667</td>\n",
       "      <td>Dhamar</td>\n",
       "      <td>...</td>\n",
       "      <td>33511.0</td>\n",
       "      <td>126731.0</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>9390.0</td>\n",
       "      <td>33511.0</td>\n",
       "      <td>126731.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>27210</td>\n",
       "      <td>2869</td>\n",
       "      <td>2008017</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dhamar public H</td>\n",
       "      <td>14.553317</td>\n",
       "      <td>44.391533</td>\n",
       "      <td>Dhamar</td>\n",
       "      <td>...</td>\n",
       "      <td>257069.0</td>\n",
       "      <td>360203.0</td>\n",
       "      <td>89579.0</td>\n",
       "      <td>219683.0</td>\n",
       "      <td>257069.0</td>\n",
       "      <td>358011.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>51916</td>\n",
       "      <td>3034</td>\n",
       "      <td>2107001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Al Shaheed Al Defaiaah Hospital</td>\n",
       "      <td>14.808703</td>\n",
       "      <td>45.719971</td>\n",
       "      <td>Shabwah</td>\n",
       "      <td>...</td>\n",
       "      <td>29990.0</td>\n",
       "      <td>57195.0</td>\n",
       "      <td>12100.0</td>\n",
       "      <td>19264.0</td>\n",
       "      <td>29990.0</td>\n",
       "      <td>57195.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>78261</td>\n",
       "      <td>3127</td>\n",
       "      <td>2113011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ataq general Hospital</td>\n",
       "      <td>14.539150</td>\n",
       "      <td>46.830867</td>\n",
       "      <td>Shabwah</td>\n",
       "      <td>...</td>\n",
       "      <td>21445.0</td>\n",
       "      <td>38469.0</td>\n",
       "      <td>7594.0</td>\n",
       "      <td>17307.0</td>\n",
       "      <td>21445.0</td>\n",
       "      <td>38469.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>104045</td>\n",
       "      <td>3171</td>\n",
       "      <td>2116008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Azzan Hospital</td>\n",
       "      <td>14.329533</td>\n",
       "      <td>47.448367</td>\n",
       "      <td>Shabwah</td>\n",
       "      <td>...</td>\n",
       "      <td>16992.0</td>\n",
       "      <td>44241.0</td>\n",
       "      <td>4639.0</td>\n",
       "      <td>7390.0</td>\n",
       "      <td>16992.0</td>\n",
       "      <td>44241.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>79326</td>\n",
       "      <td>3347</td>\n",
       "      <td>2214008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Kitaf Health Center</td>\n",
       "      <td>17.034533</td>\n",
       "      <td>44.108400</td>\n",
       "      <td>Sa'adah</td>\n",
       "      <td>...</td>\n",
       "      <td>4296.0</td>\n",
       "      <td>12847.0</td>\n",
       "      <td>1348.0</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>4296.0</td>\n",
       "      <td>12847.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>82462</td>\n",
       "      <td>3361</td>\n",
       "      <td>2215001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Al Jumhoori Hospital</td>\n",
       "      <td>16.940883</td>\n",
       "      <td>43.768117</td>\n",
       "      <td>Sa'adah</td>\n",
       "      <td>...</td>\n",
       "      <td>121733.0</td>\n",
       "      <td>267776.0</td>\n",
       "      <td>36836.0</td>\n",
       "      <td>63296.0</td>\n",
       "      <td>121733.0</td>\n",
       "      <td>267776.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>56526</td>\n",
       "      <td>3488</td>\n",
       "      <td>2307014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sep matnah 26</td>\n",
       "      <td>15.252064</td>\n",
       "      <td>44.026962</td>\n",
       "      <td>Sana'a</td>\n",
       "      <td>...</td>\n",
       "      <td>15757.0</td>\n",
       "      <td>59495.0</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>3723.0</td>\n",
       "      <td>15757.0</td>\n",
       "      <td>51928.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.872813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>79804</td>\n",
       "      <td>3781</td>\n",
       "      <td>2507002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Radfan Public H</td>\n",
       "      <td>13.526683</td>\n",
       "      <td>44.852483</td>\n",
       "      <td>Lahj</td>\n",
       "      <td>...</td>\n",
       "      <td>20019.0</td>\n",
       "      <td>47441.0</td>\n",
       "      <td>5080.0</td>\n",
       "      <td>11769.0</td>\n",
       "      <td>20019.0</td>\n",
       "      <td>45148.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3803</td>\n",
       "      <td>3856</td>\n",
       "      <td>2511004</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tour Albaha H</td>\n",
       "      <td>13.177733</td>\n",
       "      <td>44.304683</td>\n",
       "      <td>Lahj</td>\n",
       "      <td>...</td>\n",
       "      <td>32867.0</td>\n",
       "      <td>93488.0</td>\n",
       "      <td>2377.0</td>\n",
       "      <td>12796.0</td>\n",
       "      <td>32867.0</td>\n",
       "      <td>93488.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>89985</td>\n",
       "      <td>3927</td>\n",
       "      <td>2514003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ibn Khaldon H - Chest disease</td>\n",
       "      <td>13.050317</td>\n",
       "      <td>44.883967</td>\n",
       "      <td>Lahj</td>\n",
       "      <td>...</td>\n",
       "      <td>88846.0</td>\n",
       "      <td>179495.0</td>\n",
       "      <td>20873.0</td>\n",
       "      <td>59755.0</td>\n",
       "      <td>88846.0</td>\n",
       "      <td>106971.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.595955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>85283</td>\n",
       "      <td>3992</td>\n",
       "      <td>2607005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26 september general hospital</td>\n",
       "      <td>15.025267</td>\n",
       "      <td>45.309900</td>\n",
       "      <td>Marib</td>\n",
       "      <td>...</td>\n",
       "      <td>12551.0</td>\n",
       "      <td>21708.0</td>\n",
       "      <td>2124.0</td>\n",
       "      <td>6972.0</td>\n",
       "      <td>12551.0</td>\n",
       "      <td>21708.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>92622</td>\n",
       "      <td>4222</td>\n",
       "      <td>2707001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alkhamis H</td>\n",
       "      <td>15.185717</td>\n",
       "      <td>43.512350</td>\n",
       "      <td>Al Mahwit</td>\n",
       "      <td>...</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>10359.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>10359.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>29731</td>\n",
       "      <td>4254</td>\n",
       "      <td>2708008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Aljoumhwri H  General</td>\n",
       "      <td>15.465383</td>\n",
       "      <td>43.555733</td>\n",
       "      <td>Al Mahwit</td>\n",
       "      <td>...</td>\n",
       "      <td>52428.0</td>\n",
       "      <td>135836.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>25368.0</td>\n",
       "      <td>52428.0</td>\n",
       "      <td>135836.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>31713</td>\n",
       "      <td>4303</td>\n",
       "      <td>2804009</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alghidha H</td>\n",
       "      <td>16.211767</td>\n",
       "      <td>52.190667</td>\n",
       "      <td>Al-Mahra</td>\n",
       "      <td>...</td>\n",
       "      <td>33320.0</td>\n",
       "      <td>33320.0</td>\n",
       "      <td>27417.0</td>\n",
       "      <td>31449.0</td>\n",
       "      <td>33320.0</td>\n",
       "      <td>33320.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>61573</td>\n",
       "      <td>4337</td>\n",
       "      <td>2808002</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Qshin Rural H</td>\n",
       "      <td>15.416400</td>\n",
       "      <td>51.665033</td>\n",
       "      <td>Al-Mahra</td>\n",
       "      <td>...</td>\n",
       "      <td>15579.0</td>\n",
       "      <td>17480.0</td>\n",
       "      <td>4124.0</td>\n",
       "      <td>5471.0</td>\n",
       "      <td>15579.0</td>\n",
       "      <td>17480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>117139</td>\n",
       "      <td>4533</td>\n",
       "      <td>2914001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>As Sawd Rural Hospital</td>\n",
       "      <td>15.775850</td>\n",
       "      <td>43.817150</td>\n",
       "      <td>Amran</td>\n",
       "      <td>...</td>\n",
       "      <td>16344.0</td>\n",
       "      <td>65098.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>4316.0</td>\n",
       "      <td>16344.0</td>\n",
       "      <td>50638.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56655</td>\n",
       "      <td>4561</td>\n",
       "      <td>2915022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Amran General Hospital</td>\n",
       "      <td>15.660450</td>\n",
       "      <td>43.948300</td>\n",
       "      <td>Amran</td>\n",
       "      <td>...</td>\n",
       "      <td>124282.0</td>\n",
       "      <td>217336.0</td>\n",
       "      <td>48075.0</td>\n",
       "      <td>94001.0</td>\n",
       "      <td>124282.0</td>\n",
       "      <td>124168.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>69130</td>\n",
       "      <td>4578</td>\n",
       "      <td>2917001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thula Rural H</td>\n",
       "      <td>15.577400</td>\n",
       "      <td>43.904300</td>\n",
       "      <td>Amran</td>\n",
       "      <td>...</td>\n",
       "      <td>24539.0</td>\n",
       "      <td>135461.0</td>\n",
       "      <td>2532.0</td>\n",
       "      <td>4410.0</td>\n",
       "      <td>24539.0</td>\n",
       "      <td>56753.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.418962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>81098</td>\n",
       "      <td>4689</td>\n",
       "      <td>3003003</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alslam H</td>\n",
       "      <td>13.855433</td>\n",
       "      <td>44.701450</td>\n",
       "      <td>Al Dhale'e</td>\n",
       "      <td>...</td>\n",
       "      <td>63416.0</td>\n",
       "      <td>168546.0</td>\n",
       "      <td>6936.0</td>\n",
       "      <td>20655.0</td>\n",
       "      <td>63416.0</td>\n",
       "      <td>64435.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.382299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>91044</td>\n",
       "      <td>4716</td>\n",
       "      <td>3004002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Althlathah Alshuhdaa H</td>\n",
       "      <td>13.837150</td>\n",
       "      <td>44.865533</td>\n",
       "      <td>Al Dhale'e</td>\n",
       "      <td>...</td>\n",
       "      <td>25055.0</td>\n",
       "      <td>72644.0</td>\n",
       "      <td>5888.0</td>\n",
       "      <td>11476.0</td>\n",
       "      <td>25055.0</td>\n",
       "      <td>59027.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.812552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>13365</td>\n",
       "      <td>4776</td>\n",
       "      <td>3006017</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alnassr H</td>\n",
       "      <td>13.703817</td>\n",
       "      <td>44.735617</td>\n",
       "      <td>Al Dhale'e</td>\n",
       "      <td>...</td>\n",
       "      <td>69125.0</td>\n",
       "      <td>213831.0</td>\n",
       "      <td>19047.0</td>\n",
       "      <td>39820.0</td>\n",
       "      <td>69125.0</td>\n",
       "      <td>108542.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.507606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>38210</td>\n",
       "      <td>4859</td>\n",
       "      <td>3101009</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Almithaq H</td>\n",
       "      <td>14.793583</td>\n",
       "      <td>43.600567</td>\n",
       "      <td>Raymah</td>\n",
       "      <td>...</td>\n",
       "      <td>9525.0</td>\n",
       "      <td>29751.0</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>4813.0</td>\n",
       "      <td>9525.0</td>\n",
       "      <td>27443.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.922423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>92241</td>\n",
       "      <td>4879</td>\n",
       "      <td>3102014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Althulaia H</td>\n",
       "      <td>14.711100</td>\n",
       "      <td>43.608000</td>\n",
       "      <td>Raymah</td>\n",
       "      <td>...</td>\n",
       "      <td>16335.0</td>\n",
       "      <td>54816.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>6417.0</td>\n",
       "      <td>16335.0</td>\n",
       "      <td>52508.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>24807</td>\n",
       "      <td>2381</td>\n",
       "      <td>1913019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alraida Alsharkia Districts H (Under construct...</td>\n",
       "      <td>15.034383</td>\n",
       "      <td>50.465883</td>\n",
       "      <td>Hadramout</td>\n",
       "      <td>...</td>\n",
       "      <td>24119.0</td>\n",
       "      <td>35428.0</td>\n",
       "      <td>7545.0</td>\n",
       "      <td>16449.0</td>\n",
       "      <td>24119.0</td>\n",
       "      <td>35428.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>89609</td>\n",
       "      <td>2347</td>\n",
       "      <td>1911016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tarim H</td>\n",
       "      <td>16.052133</td>\n",
       "      <td>49.004267</td>\n",
       "      <td>Hadramout</td>\n",
       "      <td>...</td>\n",
       "      <td>106178.0</td>\n",
       "      <td>144941.0</td>\n",
       "      <td>39730.0</td>\n",
       "      <td>78766.0</td>\n",
       "      <td>106178.0</td>\n",
       "      <td>136029.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>82400</td>\n",
       "      <td>2322</td>\n",
       "      <td>1910021</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sayo'on Public Hospital</td>\n",
       "      <td>15.936200</td>\n",
       "      <td>48.790683</td>\n",
       "      <td>Hadramout</td>\n",
       "      <td>...</td>\n",
       "      <td>119344.0</td>\n",
       "      <td>189989.0</td>\n",
       "      <td>39295.0</td>\n",
       "      <td>95397.0</td>\n",
       "      <td>119344.0</td>\n",
       "      <td>181077.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NN  Unnamed: 0      FID  Functionality  YEHNP_PHCs  YEHNP_Hospitals  \\\n",
       "0    31142          39  1102001            1.0         NaN              1.0   \n",
       "1    14344         227  1111011            1.0         NaN              1.0   \n",
       "32  119219        2540  1924006            1.0         NaN              1.0   \n",
       "34   55109        2749  2005004            1.0         NaN              1.0   \n",
       "35   27210        2869  2008017            1.0         NaN              1.0   \n",
       "36   51916        3034  2107001            1.0         NaN              1.0   \n",
       "37   78261        3127  2113011            1.0         NaN              1.0   \n",
       "38  104045        3171  2116008            1.0         NaN              1.0   \n",
       "39   79326        3347  2214008            1.0         NaN              1.0   \n",
       "40   82462        3361  2215001            1.0         NaN              1.0   \n",
       "42   56526        3488  2307014            1.0         NaN              1.0   \n",
       "47   79804        3781  2507002            1.0         NaN              1.0   \n",
       "48    3803        3856  2511004            2.0         NaN              1.0   \n",
       "49   89985        3927  2514003            1.0         NaN              1.0   \n",
       "50   85283        3992  2607005            1.0         NaN              1.0   \n",
       "51   92622        4222  2707001            2.0         NaN              1.0   \n",
       "52   29731        4254  2708008            1.0         NaN              1.0   \n",
       "53   31713        4303  2804009            2.0         NaN              1.0   \n",
       "54   61573        4337  2808002            2.0         NaN              1.0   \n",
       "55  117139        4533  2914001            1.0         NaN              1.0   \n",
       "56   56655        4561  2915022            1.0         NaN              1.0   \n",
       "57   69130        4578  2917001            2.0         NaN              1.0   \n",
       "58   81098        4689  3003003            2.0         NaN              1.0   \n",
       "59   91044        4716  3004002            1.0         NaN              1.0   \n",
       "60   13365        4776  3006017            2.0         NaN              1.0   \n",
       "61   38210        4859  3101009            2.0         NaN              1.0   \n",
       "62   92241        4879  3102014            1.0         NaN              1.0   \n",
       "31   24807        2381  1913019            3.0         NaN              1.0   \n",
       "30   89609        2347  1911016            1.0         NaN              1.0   \n",
       "29   82400        2322  1910021            1.0         NaN              1.0   \n",
       "\n",
       "                              Name of_Health_Facility   Latitude  Longitude  \\\n",
       "0                                            Yarim .H  14.304533  44.370000   \n",
       "1                                            Aladin H  13.965600  44.008767   \n",
       "32       Hajar Aljoul rural H (Al Faqeed Al Shadli H)  14.460983  48.279683   \n",
       "34                                26September rural H  14.491833  44.016667   \n",
       "35                                    Dhamar public H  14.553317  44.391533   \n",
       "36                    Al Shaheed Al Defaiaah Hospital  14.808703  45.719971   \n",
       "37                              Ataq general Hospital  14.539150  46.830867   \n",
       "38                                     Azzan Hospital  14.329533  47.448367   \n",
       "39                                Kitaf Health Center  17.034533  44.108400   \n",
       "40                               Al Jumhoori Hospital  16.940883  43.768117   \n",
       "42                                      sep matnah 26  15.252064  44.026962   \n",
       "47                                    Radfan Public H  13.526683  44.852483   \n",
       "48                                      Tour Albaha H  13.177733  44.304683   \n",
       "49                      Ibn Khaldon H - Chest disease  13.050317  44.883967   \n",
       "50                      26 september general hospital  15.025267  45.309900   \n",
       "51                                         Alkhamis H  15.185717  43.512350   \n",
       "52                              Aljoumhwri H  General  15.465383  43.555733   \n",
       "53                                         Alghidha H  16.211767  52.190667   \n",
       "54                                      Qshin Rural H  15.416400  51.665033   \n",
       "55                             As Sawd Rural Hospital  15.775850  43.817150   \n",
       "56                             Amran General Hospital  15.660450  43.948300   \n",
       "57                                      Thula Rural H  15.577400  43.904300   \n",
       "58                                           Alslam H  13.855433  44.701450   \n",
       "59                             Althlathah Alshuhdaa H  13.837150  44.865533   \n",
       "60                                          Alnassr H  13.703817  44.735617   \n",
       "61                                         Almithaq H  14.793583  43.600567   \n",
       "62                                        Althulaia H  14.711100  43.608000   \n",
       "31  Alraida Alsharkia Districts H (Under construct...  15.034383  50.465883   \n",
       "30                                            Tarim H  16.052133  49.004267   \n",
       "29                            Sayo'on Public Hospital  15.936200  48.790683   \n",
       "\n",
       "   Name of Governorate  ... catchment_120 catchment_240  unique_30 unique_60  \\\n",
       "0                  Ibb  ...      106671.0      218656.0    44244.0   77271.0   \n",
       "1                  Ibb  ...       42751.0      138371.0     5098.0   12578.0   \n",
       "32           Hadramout  ...        4263.0        9560.0     1321.0    2678.0   \n",
       "34              Dhamar  ...       33511.0      126731.0     3139.0    9390.0   \n",
       "35              Dhamar  ...      257069.0      360203.0    89579.0  219683.0   \n",
       "36             Shabwah  ...       29990.0       57195.0    12100.0   19264.0   \n",
       "37             Shabwah  ...       21445.0       38469.0     7594.0   17307.0   \n",
       "38             Shabwah  ...       16992.0       44241.0     4639.0    7390.0   \n",
       "39             Sa'adah  ...        4296.0       12847.0     1348.0    2648.0   \n",
       "40             Sa'adah  ...      121733.0      267776.0    36836.0   63296.0   \n",
       "42              Sana'a  ...       15757.0       59495.0     1908.0    3723.0   \n",
       "47                Lahj  ...       20019.0       47441.0     5080.0   11769.0   \n",
       "48                Lahj  ...       32867.0       93488.0     2377.0   12796.0   \n",
       "49                Lahj  ...       88846.0      179495.0    20873.0   59755.0   \n",
       "50               Marib  ...       12551.0       21708.0     2124.0    6972.0   \n",
       "51           Al Mahwit  ...        1766.0       10359.0      568.0    1147.0   \n",
       "52           Al Mahwit  ...       52428.0      135836.0      146.0   25368.0   \n",
       "53            Al-Mahra  ...       33320.0       33320.0    27417.0   31449.0   \n",
       "54            Al-Mahra  ...       15579.0       17480.0     4124.0    5471.0   \n",
       "55               Amran  ...       16344.0       65098.0      390.0    4316.0   \n",
       "56               Amran  ...      124282.0      217336.0    48075.0   94001.0   \n",
       "57               Amran  ...       24539.0      135461.0     2532.0    4410.0   \n",
       "58          Al Dhale'e  ...       63416.0      168546.0     6936.0   20655.0   \n",
       "59          Al Dhale'e  ...       25055.0       72644.0     5888.0   11476.0   \n",
       "60          Al Dhale'e  ...       69125.0      213831.0    19047.0   39820.0   \n",
       "61              Raymah  ...        9525.0       29751.0     1798.0    4813.0   \n",
       "62              Raymah  ...       16335.0       54816.0     1164.0    6417.0   \n",
       "31           Hadramout  ...       24119.0       35428.0     7545.0   16449.0   \n",
       "30           Hadramout  ...      106178.0      144941.0    39730.0   78766.0   \n",
       "29           Hadramout  ...      119344.0      189989.0    39295.0   95397.0   \n",
       "\n",
       "   unique_120 unique_240  pct_unique_30  pct_unique_60  pct_unique_120  \\\n",
       "0    106671.0   206411.0            1.0            1.0             1.0   \n",
       "1     42751.0   132366.0            1.0            1.0             1.0   \n",
       "32     4263.0     9560.0            1.0            1.0             1.0   \n",
       "34    33511.0   126731.0            1.0            1.0             1.0   \n",
       "35   257069.0   358011.0            1.0            1.0             1.0   \n",
       "36    29990.0    57195.0            1.0            1.0             1.0   \n",
       "37    21445.0    38469.0            1.0            1.0             1.0   \n",
       "38    16992.0    44241.0            1.0            1.0             1.0   \n",
       "39     4296.0    12847.0            1.0            1.0             1.0   \n",
       "40   121733.0   267776.0            1.0            1.0             1.0   \n",
       "42    15757.0    51928.0            1.0            1.0             1.0   \n",
       "47    20019.0    45148.0            1.0            1.0             1.0   \n",
       "48    32867.0    93488.0            1.0            1.0             1.0   \n",
       "49    88846.0   106971.0            1.0            1.0             1.0   \n",
       "50    12551.0    21708.0            1.0            1.0             1.0   \n",
       "51     1766.0    10359.0            1.0            1.0             1.0   \n",
       "52    52428.0   135836.0            1.0            1.0             1.0   \n",
       "53    33320.0    33320.0            1.0            1.0             1.0   \n",
       "54    15579.0    17480.0            1.0            1.0             1.0   \n",
       "55    16344.0    50638.0            1.0            1.0             1.0   \n",
       "56   124282.0   124168.0            1.0            1.0             1.0   \n",
       "57    24539.0    56753.0            1.0            1.0             1.0   \n",
       "58    63416.0    64435.0            1.0            1.0             1.0   \n",
       "59    25055.0    59027.0            1.0            1.0             1.0   \n",
       "60    69125.0   108542.0            1.0            1.0             1.0   \n",
       "61     9525.0    27443.0            1.0            1.0             1.0   \n",
       "62    16335.0    52508.0            1.0            1.0             1.0   \n",
       "31    24119.0    35428.0            1.0            1.0             1.0   \n",
       "30   106178.0   136029.0            1.0            1.0             1.0   \n",
       "29   119344.0   181077.0            1.0            1.0             1.0   \n",
       "\n",
       "    pct_unique_240  \n",
       "0         0.943999  \n",
       "1         0.956602  \n",
       "32        1.000000  \n",
       "34        1.000000  \n",
       "35        0.993915  \n",
       "36        1.000000  \n",
       "37        1.000000  \n",
       "38        1.000000  \n",
       "39        1.000000  \n",
       "40        1.000000  \n",
       "42        0.872813  \n",
       "47        0.951666  \n",
       "48        1.000000  \n",
       "49        0.595955  \n",
       "50        1.000000  \n",
       "51        1.000000  \n",
       "52        1.000000  \n",
       "53        1.000000  \n",
       "54        1.000000  \n",
       "55        0.777873  \n",
       "56        0.571318  \n",
       "57        0.418962  \n",
       "58        0.382299  \n",
       "59        0.812552  \n",
       "60        0.507606  \n",
       "61        0.922423  \n",
       "62        0.957896  \n",
       "31        1.000000  \n",
       "30        0.938513  \n",
       "29        0.953092  \n",
       "\n",
       "[30 rows x 135 columns]"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = ['catchment_30','catchment_60','catchment_120','unique_30','unique_60','unique_120','pct_unique_30','pct_unique_60','pct_unique_120']\n",
    "acceptable_df_res.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and we save our output down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outi = os.path.join(basepth, 'output_layers', 'catchment')\n",
    "acceptable_df_res.to_csv(os.path.join(outi, subset+'_catchment.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
