{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single AOI GBDX Imagery Search\n",
    "\n",
    "The purpose of the script is to search the GBDX satelite imagery back catalog for imagery of a single area of interest (AOI) polygon. It assumes that you have a gbdx.config file set up correctly in your user environment on a machine running MS Windows. See Benjamin Stewart on setting up a gbdx.config file. \n",
    "\n",
    "More broadly, you will need to have an email and password combination stored in that file that is associated with the World Bank's GBDX account. Please see Keith Garrett (Senior Geographer, GOST) about this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library installation and script setup\n",
    "This builds the environment to carry out the rest of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run one time only - install pip and unusual Libraries\n",
    "import pip\n",
    "import pandas as pd\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import box\n",
    "from shapely.geometry import MultiPolygon\n",
    "import time\n",
    "import json\n",
    "import geopandas as gpd\n",
    "\n",
    "# The following lines are GBDX - specific, and require a python environment with gbdxtools installed\n",
    "from gbdxtools import Interface\n",
    "from gbdxtools.task import env\n",
    "from gbdxtools import CatalogImage\n",
    "gbdx = Interface()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define AOI and bounding box of AOI from shapefile\n",
    "The user needs to have their Area of Interest (\"AOI\") defined as a one-polygon shapefile. This step should be performed before running the next cell. \n",
    "\n",
    "We also provide support for a single point via a buffer method (see first control-flow measure). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determine if input is single point or shapefile\n",
    "input_type = 'shapefile'\n",
    "\n",
    "if input_type == 'point':\n",
    "    \n",
    "    # Create shapely Point instance from coordinates. Put your lat, long coordinates below\n",
    "    point = Point((92.1443285, 21.2705219))\n",
    "    \n",
    "    # Make a square box around it using shapely's buffer method. Again, select your buffer size of interest as well. \n",
    "    point = point.buffer(0.002, cap_style = 3)\n",
    "    AOI = point\n",
    "    \n",
    "elif input_type == 'shapefile': \n",
    "    \n",
    "    # Attach the name of uploaded file to the fname variable. If it is not 'shapefile.shp', change the name accordingly. \n",
    "    fname = 'shapefile.shp' \n",
    "\n",
    "    # Create Area of Interest (AOI) object as a geopandas object; reproject to WGS84 if not already in WGS 84\n",
    "    AOI = gpd.read_file(fname)\n",
    "    \n",
    "    crs_WGS84 = {'init' :'epsg:4326'}\n",
    "    if AOI.crs != crs_WGS84:\n",
    "        AOI = AOI.to_crs(crs_WGS84)\n",
    "\n",
    "    # Redefine AOI as the first WKT object in the DataFrame (valid for 1-polygon AOIs only)\n",
    "    AOI = AOI['geometry'].loc[0]\n",
    "\n",
    "else: \n",
    "    print('** WARNING: Failure to determine adequate input data type **')\n",
    "    AOI = ''\n",
    "    \n",
    "# Create bboxx - the square shaped box which will always contain the AOI.\n",
    "bboxx = []\n",
    "for coord in range(0,len(AOI.bounds)): \n",
    "    bboxx.append(AOI.bounds[coord])\n",
    "\n",
    "# Print to screen - AOI and bboxx\n",
    "print 'AOI: || ', AOI, '\\n\\nbboxx: || ', bboxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Initial Vector Search: AOI Vector Against Image Catalog for All Potential Images\n",
    "Given the calculations conducted in the previous step, this cell queries the DigitalGlobe image database based on the vector footprint of the AOI defined above, and returns a list of catalog IDs which at least partially cover the AOI. As default, it returns up to 1000 images, with a cloud cover less than 25%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define search function. Returns up to 1000 images where cloud cover smaller than 25%\n",
    "def search_unordered(bbox, _type, count=1000, cloud_cover=25):\n",
    "    aoi = AOI.wkt\n",
    "    query = \"item_type:{} AND item_type:DigitalGlobeAcquisition\".format(_type)\n",
    "    query += \" AND attributes.cloudCover_int:<{}\".format(cloud_cover)\n",
    "    return gbdx.vectors.query(aoi, query, count=count)\n",
    "\n",
    "# Run search on Area of Interest (AOI). Passes in AOI in Well Known Text format (wkt)\n",
    "records = search_unordered(AOI.wkt, 'DigitalGlobeAcquisition')\n",
    "\n",
    "# Create list object of all catalog IDs returned in search\n",
    "ids = [r['properties']['attributes']['catalogID'] for r in records]\n",
    "\n",
    "# Print length of list of catalogi IDs (number of unique images)\n",
    "print 'Unique images found: %s' % len(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate CSV of images that match criteria\n",
    "At this point, we generate a .csv file with the key metadata about the image which will be used for further processing later. This is the definitive database for the given AOI. No filtering yet takes place.\n",
    "\n",
    "Key calculated statistics include: the area where the scene and the AOI don't overlap (AA), the corresponding overlap with the image (BB), the fraction of the AOI covered (frac), and the binary flag for whether the image is yet in IDAHO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Define Counters\n",
    "l = 0    # number of non-IDAHO images\n",
    "scenes = [] # list containing metadata dictionaries of all scenes in our AOI \n",
    "\n",
    "# Toggle for printing images to screen\n",
    "download_thumbnails = 0\n",
    "\n",
    "# Loop catalog IDs\n",
    "for i in ids:\n",
    "    \n",
    "    # Fetch metadata dictionary for each catalog ID in ids list\n",
    "    r = gbdx.catalog.get(i)\n",
    "    \n",
    "    # Check location of ID - is it in IDAHO? Returns 'not_delivered' in the event it is not on IDAHO\n",
    "    location = gbdx.catalog.get_data_location(i)\n",
    "    \n",
    "    # Defines IDAHO variable as binary 1 / 0 depending on whether it is in IDAHO already or not\n",
    "    if location == 'not_delivered':\n",
    "        l = l + 1\n",
    "        idaho = 0\n",
    "    else:\n",
    "        idaho = 1\n",
    "    \n",
    "        # Download image if image in IDAHO and toggle on\n",
    "        if download_thumbnails == 1:\n",
    "            image = CatalogImage(i, band_type=\"MS\", bbox=bboxx)\n",
    "            image.plot(w=10, h=10)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # Print statement to consol for key image variables\n",
    "    print 'ID: %s, Timestamp: %s, Cloud Cover: %s, Image bands: %s, IDAHO: %s' % (i,r['properties']['timestamp'],r['properties']['cloudCover'],r['properties']['imageBands'],idaho)\n",
    "    \n",
    "    # Calculate the percentage overlap with our AOI for each scene\n",
    "    # load as a Shapely object the wkt representation of the scene footprint\n",
    "    footprint = r['properties']['footprintWkt']\n",
    "    shapely_footprint = shapely.wkt.loads(footprint)\n",
    "    \n",
    "    # Calculate the object that represents the difference between the AOI and the scene footprint \n",
    "    AA = AOI.difference(shapely_footprint)\n",
    "    \n",
    "    # Define frac as the fraction, between 0 and 1, of the AOI that the scene covers\n",
    "    frac = 1 - (AA.area / AOI.area)\n",
    "    \n",
    "    # Create BB - the proxy for the useful area. IF scene entirely contains AOI, then BB = AOI, else it is the intersection \n",
    "    # of the scene footprint and the AOI\n",
    "    BB = AOI \n",
    "    if frac < 1:\n",
    "        BB = AOI - AA\n",
    "    #shapely_footprint.intersection(AOI)\n",
    "    # Similarly, AA, the difference area between AOI and the scene, can be set to null if the scene contains 100% of the AOI \n",
    "    if frac == 1:\n",
    "        AA = \"\"\n",
    "        \n",
    "    # Append key metadata to list obejct 'scenes' for the current scene, as a dictionary. This then moves into the pandas dataframe.\n",
    "    # Several objects here are from DigitalGlobe's metadata dictionary (anything with an r start)\n",
    "    scenes.append({\n",
    "        'ID':i, \n",
    "        'TimeStamp':r['properties']['timestamp'],\n",
    "        'CloudCover':r['properties']['cloudCover'],\n",
    "        'ImageBands':r['properties']['imageBands'],\n",
    "        'On_IDAHO':idaho,\n",
    "        'browseURL': r['properties']['browseURL'],\n",
    "        'Overlap_%': frac * 100,\n",
    "        'PanResolution': r['properties']['panResolution'],\n",
    "        'MultiResolution': r['properties']['multiResolution'],\n",
    "        'OffNadirAngle': r['properties']['offNadirAngle'],\n",
    "        'Sensor':r['properties']['sensorPlatformName'],\n",
    "        'Full_scene_WKT':r['properties']['footprintWkt'],\n",
    "        'missing_area_WKT':AA,\n",
    "        'useful_area_WKT':BB\n",
    "        })\n",
    "    \n",
    "# Summary Statistics - show totals for images, both in IDAHO and currenlty unavailable images. \n",
    "print 'Number of catalog IDs not available in IDAHO: %s' % l\n",
    "print 'Number of catalog IDs available in IDAHO: %s' % (len(ids) - l)\n",
    "\n",
    "# Define column order for dataframe of search results\n",
    "cols = ['ID','Sensor','ImageBands','TimeStamp','CloudCover','Overlap_%','PanResolution','MultiResolution','OffNadirAngle','On_IDAHO','browseURL','Full_scene_WKT','useful_area_WKT','missing_area_WKT']\n",
    "\n",
    "#Generate pandas dataframe from results\n",
    "out = pd.DataFrame(scenes,columns = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Categorical Search: Remove Disqualified Images\n",
    "At this point, we have a pandas DataFrame object that includes some basic info about the imagery available over the AOI (up to 1000 rows - one for each image that intersects (note: not necessarily contains) the AOI. \n",
    "\n",
    "Next, we performs pandas' .loc operations to cut out scenes which don't meet the criteria specified by the 'cutoff' series of variables. Define these in-script in the '# Define categorical search parameters' section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define categorical search parameters\n",
    "cutoff_cloud_cover = 2   # images with CC over this threshold discarded\n",
    "cutoff_overlap = 0     # images with AOI overlap below this threshold discarded. [N.b.: keep small if AOI large.]\n",
    "cutoff_date_upper = '1-Jan-19'  # images newer than this date discarded\n",
    "cutoff_date_lower = '1-Jan-07'  # images older than this date discarded\\\n",
    "cutoff_nadir = 30 # Images at nadir angles greater than threshold discarded\n",
    "cutoff_pan_res = 1 # Images below this resolution discarded\n",
    "accepted_bands = ['PAN_MS1','PAN_MS1_MS2'] #  Images with any other band entry discarded\n",
    "\n",
    "# Convert Timestamp field to pandas DateTime object\n",
    "out['TS'] = out['TimeStamp'].apply(lambda x: pd.Timestamp(x))\n",
    "\n",
    "# Add separate date and time columns for easy interpretation\n",
    "string = out['TimeStamp'].str.split('T')\n",
    "out['Date'] = string.str.get(0)\n",
    "out['Time'] = string.str.get(1)\n",
    "\n",
    "# Categorical Search: remove disqualified images. Copy of dataframe taken, renamed to 'out_1stcut'.\n",
    "out_1stcut = out.loc[(out['CloudCover'] <= cutoff_cloud_cover) & \n",
    "                     (out['Overlap_%'] >= cutoff_overlap) & \n",
    "                     (out['TS'] > pd.Timestamp(cutoff_date_lower, tz = 0)) & \n",
    "                     (out['TS'] < pd.Timestamp(cutoff_date_upper, tz = 0)) &\n",
    "                     (out['ImageBands'].isin(accepted_bands)) & \n",
    "                     (out['OffNadirAngle'] <= cutoff_nadir) & \n",
    "                     (out['PanResolution'] <= cutoff_pan_res)\n",
    "                    ]\n",
    "\n",
    "# Print to consol remaining images after categorical search undertaken\n",
    "print '\\nNumber of results remaining: %s' % len(out_1stcut.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Image Quality Ranking\n",
    "For the remaining images that met minimum quality thresholds, we go on to rank them, best to worst. This is done on a points-based system. \n",
    "\n",
    "Images accrue points for: \n",
    "- every % of cloud cover (1 point)\n",
    "- every % of missed overlap with the AOI (1 point)\n",
    "- every week away from the optimal date (1 point)\n",
    "- every degree away from nadir (1 point)\n",
    "- every cm of resolution worse than the optimal resolution \n",
    "\n",
    "User preferences are defined in the 'pref_weights' dictionary. \n",
    "Ensure all weights sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define continuous image ranking preferences\n",
    "optimal_date =  '1-Jan-19' # Optimal date (enter as dd-mmm-yy)\n",
    "optimal_pan_res = 0.4 # Optimal pan resolution, metres\n",
    "optimal_nadir = 0 # optimal image angle. 0 = vertical\n",
    "\n",
    "# Define continuous image ranking preference weights. Must sum to 1.\n",
    "# If user cares more about scenes being current, up the 'date' weighting at expense of other categories, for example.\n",
    "pref_weights = {\n",
    "    'cloud_cover': 0.5,\n",
    "    'overlap':0.5,\n",
    "    'date': 0.0,\n",
    "    'nadir': 0.0,\n",
    "    'resolution': 0.0\n",
    "    }\n",
    "\n",
    "# Apply ranking method over all non-disqualified search results for each field\n",
    "optimal_date = pd.to_datetime(optimal_date, utc = True)\n",
    "\n",
    "# each 1% of cloud cover = 1 point\n",
    "out_1stcut['points_CC'] = (out_1stcut['CloudCover'])  \n",
    "\n",
    "# each 1% of overlap missed = 1 point\n",
    "out_1stcut['points_Overlap'] = (100 - out_1stcut['Overlap_%'])  \n",
    "\n",
    "# each week away from the optimal date = 1 point \n",
    "out_1stcut['points_Date'] = ((abs(out_1stcut['TS'] - optimal_date)).view('int64') / 60 / 60 / 24 / 1E9) / 7 \n",
    "\n",
    "# each degree off nadir = 1 point\n",
    "out_1stcut['points_Nadir'] = abs(out_1stcut['OffNadirAngle'] - optimal_nadir) \n",
    "\n",
    "# each cm of resolution worse than the optimal resolution = 1 point\n",
    "out_1stcut['points_Res'] = (out_1stcut['PanResolution'] - optimal_pan_res).apply(lambda x: max(x,0)) * 100 \n",
    "\n",
    "# Define ranking algorithm - weight point components defined above by the preference weighting dictionary\n",
    "def Ranker(out_1stcut, pref_weights):\n",
    "    a = out_1stcut['points_CC'] * pref_weights['cloud_cover']\n",
    "    b = out_1stcut['points_Overlap'] * pref_weights['overlap']\n",
    "    c = out_1stcut['points_Date'] * pref_weights['date'] \n",
    "    d = out_1stcut['points_Nadir'] * pref_weights['nadir']\n",
    "    e = out_1stcut['points_Res'] * pref_weights['resolution']\n",
    "    \n",
    "    # Score is linear addition of the number of 'points' the scene wins as defined above. More points = worse fit to criteria\n",
    "    rank = a + b + c + d + e\n",
    "    return rank\n",
    "\n",
    "# Add new column - Rank Result - with the total number of points accrued by the scene \n",
    "out_1stcut['RankResult'] = Ranker(out_1stcut,pref_weights)\n",
    "\n",
    "# Add a Preference order column - Pref_Order - based on Rank Result, sorted ascending (best scene first)\n",
    "out_1stcut = out_1stcut.sort_values(by = 'RankResult', axis = 0, ascending = True)\n",
    "out_1stcut = out_1stcut.reset_index()\n",
    "out_1stcut['Pref_order'] = out_1stcut.index + 1\n",
    "out_1stcut = out_1stcut.drop(['index'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output image results .csv\n",
    "Before construction of the scene mosaic, output a .csv with the details of selected and ranked scenes, named 'Scene_List.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose which columns to keep from out_1stcut, and in which order\n",
    "cols = ['ID','Sensor','ImageBands','Date','Time','CloudCover','Overlap_%','PanResolution','MultiResolution','OffNadirAngle','On_IDAHO','Pref_order','RankResult','points_CC','points_Overlap','points_Date','points_Nadir','points_Res','browseURL','Full_scene_WKT','useful_area_WKT','missing_area_WKT']\n",
    "out_1stcut = out_1stcut[cols]\n",
    "\n",
    "# Add a column containing the area of interest polygon for reference\n",
    "out_1stcut['AOI_WKT'] = AOI\n",
    "\n",
    "# send to file at the outpath_path\n",
    "output_path = r'C:\\Users\\charl\\Documents\\GOST\\GBDX\\Padma'\n",
    "out_1stcut.to_csv(os.path.join(output_path,'Scene_List.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build composite shape from useful area WKT\n",
    "\n",
    "This block takes the AOI and subtracts from it, in rank-preferred order, the useable scene area for each catalog ID. \n",
    "\n",
    "This results in a diminishing 'AOI remaining' area, which the loop seeks to fill, with images of ever decreasing ranks. \n",
    "\n",
    "The idea is to make a mosaic of imagery covering the AOI, using best quality imagery first as defined above via our ranking system. Note that, for example, adjustments to the pref_weights dictionary will have an effect on the resultant mosaic!\n",
    "\n",
    "A new column in the dataframe is created - 'used_area_wkt' - which is the geometry of the image which should be requested if trying to make a mosaic of these catalog IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new copy of the dataframe to work on\n",
    "finaldf = out_1stcut\n",
    "\n",
    "# Add column for used scene region area, expressed as .wkt\n",
    "finaldf['used_scene_region_WKT'] = 0\n",
    "finaldf['used_area'] = 0\n",
    "\n",
    "# Set initial value of AOI_remaining to the full AOI under consideration\n",
    "AOI_remaining = AOI\n",
    "\n",
    "# Create two lists - \n",
    "# 'usedareas' for the areas of scenes used in the final product, and \n",
    "# 'AOI_rems' to record sequential reduction in remaining AOI that needs to be filled\n",
    "usedareas = []\n",
    "AOI_rems = []\n",
    "\n",
    "# Set up loop for each image in dataframe of ranked images\n",
    "for s in finaldf.index:\n",
    "    print 'calculating for %s' % s\n",
    "    \n",
    "    # pick up the WKT of the useful area as the useful_scene_region variable\n",
    "    useful_scene_region = finaldf['useful_area_WKT'].loc[s]\n",
    "    \n",
    "    # Set up try loop - to catch if there is no intersection of AOI_remaining and useful_scene_region\n",
    "    try: \n",
    "        \n",
    "        # define 'used_scene_region' as the useable bit of the image that overlaps the AOI\n",
    "        used_scene_region = AOI_remaining.intersection(useful_scene_region)\n",
    "        \n",
    "        # calculate the area of that region\n",
    "        used_area = used_scene_region.area\n",
    "        \n",
    "        # Check to see if this is a geometry collection. This shapely type is for 'jumbles' of outputs (e.g. Polygons + Lines)\n",
    "        # This can be created if the intersection process decides that it also wants a 1-pixel strip from the bottom of the image\n",
    "        # as well as the main chunk. This won't translate back to a shapefile, so we drop non-Polygon objects iteratively. \n",
    "        if used_scene_region.type == 'GeometryCollection':\n",
    "            xlist = []\n",
    "            \n",
    "            # Iterate through all objects in the geometry collection\n",
    "            for y in used_scene_region.geoms:\n",
    "                \n",
    "                # Add polygons to a fresh list\n",
    "                if y.type == 'Polygon':\n",
    "                    xlist.append(y)\n",
    "                    \n",
    "            # Convert that list to a multipolygon object\n",
    "            used_scene_region = MultiPolygon(xlist)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # Append the used bit of the image to the usedareas list. \n",
    "        usedareas.append(used_scene_region)\n",
    "        \n",
    "        # Add two new columns to the dataframe - the used scene geometry in wkt, and the area of the used scene\n",
    "        finaldf['used_scene_region_WKT'].loc[s] = used_scene_region\n",
    "        finaldf['used_area'].loc[s] = used_area\n",
    "        \n",
    "        # Redefine the area of the AOI that needs to be filled by the next, lower-rank image\n",
    "        AOI_remaining = AOI_remaining.difference(used_scene_region)\n",
    "        \n",
    "        # Add this to the AOI_rems list for troubelshooting and verification\n",
    "        AOI_rems.append(AOI_remaining)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output and Summary\n",
    "End of the process - print how much of the AOI was eventually covered with these settings, and send the .csv to file as 'Final_Scene_List'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop from the scene list any scene where the area used is less than 1% of the AOI\n",
    "finaldf = finaldf.loc[finaldf['used_area'] > (AOI.area / 100)]\n",
    "\n",
    "# Print summary statistics to consol\n",
    "print 'Remaining images: %s' % len(finaldf.index)\n",
    "print 'Proportion of AOI covered: %d percent' % (finaldf['used_area'].sum() / AOI.area * 100)\n",
    "print 'Remaining area:'\n",
    "AOI_remaining\n",
    "\n",
    "# Send final .csv to file\n",
    "finaldf.to_csv('Final_Scene_List_Konna.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagery Ordering\n",
    "\n",
    "In this section, we order the imagery we want to use in our project from GBDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for demonstration purposes, we make a dataframe with just the first 20 images in it\n",
    "o = out_1stcut.copy()\n",
    "o = o.sort_values(by = 'Overlap_%', ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creat a list of imagery IDs we wish to acquire\n",
    "order_list = list(o.ID)\n",
    "\n",
    "# creat a list object to keep track of the order receipts\n",
    "order_receipts = []\n",
    "print 'Number of images to be ordered: %d' % len(order_list)\n",
    "\n",
    "# As this may cost the Bank, it is important users understand that executing this cell has a dollar cost. \n",
    "# Write in the consent variable below: 'I agree to ordering these image IDs to IDAHO'\n",
    "consent = \n",
    "\n",
    "# if the user consents to this action, \n",
    "if consent == 'I agree to ordering these image IDs to IDAHO':\n",
    "    \n",
    "    # for each imagery ID in the order_list\n",
    "    for x in order_list:\n",
    "        try:\n",
    "            # order the image using gbdx.ordering.order, and add the receipt to the list of receipts\n",
    "            order_id = gbdx.ordering.order(x)\n",
    "            order_receipts.append(order_id)\n",
    "        except:\n",
    "            # should this process fail, add an error message to receipt list. \n",
    "            order_receipts.append('error!')\n",
    "else: \n",
    "    print 'please write out your consent in the consent variable above'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using this block, we can print out the status of our requests\n",
    "for receipt in order_receipts[:20]:\n",
    "    try:\n",
    "        print(gbdx.ordering.status(receipt))\n",
    "    except:\n",
    "        print('error!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagery chip download\n",
    "Here, we use GOST's GBDX tools library to automate the download of each image in the output dataframe. \n",
    "We call the images down using the 'ID' field (catalog ID of image). \n",
    "Be sure to append to sys.path the path to the GOST_GBDX Github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import gbdx tools, GOST_GBDX lib, append to sys.path\n",
    "import sys, os\n",
    "sys.path.insert(0, r\"C:\\Users\\charl\\Documents\\GitHub\\GOST_GBDX\")\n",
    "from GOST_GBDx_Tools import gbdxTasks\n",
    "from GOST_GBDx_Tools import gbdxURL_misc\n",
    "from gbdxtools import CatalogImage\n",
    "\n",
    "# gbdx is the object created when instantiating a GBDX interface session - see start of script. \n",
    "# it is effectively a credentializing device\n",
    "curTasks = gbdxTasks.GOSTTasks(gbdx)\n",
    "gbdxUrl = gbdxURL_misc.gbdxURL(gbdx)\n",
    "\n",
    "# path to the location where downloaded .tifs will be stored\n",
    "curFolder=r'C:\\Users\\charl\\Documents\\GOST\\GBDX\\Padma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(curFolder, topdown=False):\n",
    "    pass\n",
    "\n",
    "i = 0\n",
    "output = o\n",
    "for i in range(0, len(output)):\n",
    "    \n",
    "        cWKT = output.AOI_WKT.iloc[i]\n",
    "        catID = output.ID.iloc[i]\n",
    "        curFile = 'img_%s.tif' % (catID)\n",
    "         \n",
    "        a = os.path.join(curFolder, curFile)\n",
    "        \n",
    "        # here, we skip a row in the output df if its .tif file already exists in the output location\n",
    "        if curFile in files:\n",
    "            print('file already exists, skipping download: %s' % curFile)\n",
    "            pass\n",
    "        # here we use the GOST library to actually download the cat ID, to the extent of the cWKT - the bounding box. \n",
    "        else:\n",
    "            print('downloading: %s' % curFile)\n",
    "            curTasks.downloadImage(catID, a, boundingBox=cWKT.bounds, imgChipSize = 100000)"
   ]
  }
 ],
 "metadata": {
  "hub": {
   "id": "5a54f830cee1f025f139c6a8",
   "published": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
