{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Snap CXB OD Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the final step of calculating the base OD matrices which underlie all GOSTNets-derived accessibility analysis. It's also the slowest step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os, sys, time, importlib\n",
    "\n",
    "# add to your system path the location of the LoadOSM.py and GOSTnet.py scripts\n",
    "# sys.path.append(\"../../../GOSTnets/GOSTnets\")\n",
    "\n",
    "import GOSTnets as gn\n",
    "import importlib\n",
    "# import Network_Clean as gnClean\n",
    "importlib.reload(gn)\n",
    "\n",
    "import networkx as nx\n",
    "import osmnx\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import ipyparallel as ipp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pth = r'inputs\\\\dests'\n",
    "geo_pth = r'../../../GEO'\n",
    "fin_pth = 'final'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_pckle = r'final_current_G.pickle'\n",
    "upgr_all = r'final_upgrade_all_G.pickle'\n",
    "upgr_nosouth = r'final_upgrade_nosouth_G.pickle'\n",
    "upgr_noferry = r'final_upgrade_noferry_G.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_current = nx.read_gpickle(os.path.join(fin_pth, fin_pckle))\n",
    "G_upgr_all = nx.read_gpickle(os.path.join(fin_pth, upgr_all))\n",
    "G_upgr_nosouth = nx.read_gpickle(os.path.join(fin_pth, upgr_nosouth))\n",
    "G_upgr_noferry = nx.read_gpickle(os.path.join(fin_pth, upgr_noferry))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_name = r'hrsl_2018_cxb_pts_snapped.csv'\n",
    "grid_name = r'growth_center_origins_snapped.csv'\n",
    "origins = pd.read_csv(os.path.join(fin_pth,grid_name))\n",
    "grid = origins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxb_fil = r'cxb_ctr.shp'\n",
    "chitt_fil = r'chittagong.shp'\n",
    "health_fil = r'hc_merge_200324_4326.shp'\n",
    "primary_fil = r'schools/school_category_primary.gpkg'\n",
    "secondary_fil = r'schools/school_category_secondary.gpkg'\n",
    "tertiary_fil = r'schools/school_category_tertiary.gpkg'\n",
    "matar_fil = r'martarbari.shp'\n",
    "mkts_fil = r'mkts_merge_4326.shp'\n",
    "gc_fil = r'cxb_lged_gc_moved_4326.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dests = {\"CXB\" : cxb_fil, \"Chittagong\" : chitt_fil, \"Health\" : health_fil, \\\n",
    "         \"Primary_education\" : primary_fil, \"Secondary_education\" : secondary_fil, \"Tertiary_education\" : tertiary_fil, \\\n",
    "         \"Martarbari\" : matar_fil, \"All_markets\" : mkts_fil, \"Growth_centers\" : gc_fil}\n",
    "\n",
    "# note you can use smaller / larger dest dictionaries as needed\n",
    "# This is helpful for going back and re-running only certain destinations, or adding in new ones.\n",
    "\n",
    "# dests = {\"CXB\" : cxb_fil}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scenarios (for looping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dict here allows us to match a label to a pickle\n",
    "\n",
    "scenarios = {'current' : [G_current,'_current_snapped.csv'],\\\n",
    "             'upgrade_all' : [G_upgr_all,'_ua_snapped.csv'],\\\n",
    "             'upgrade_nosouth' : [G_upgr_nosouth,'_uns_snapped.csv'],\\\n",
    "             'upgrade_noferry' : [G_upgr_noferry,'_unf_snapped.csv']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_speed = 4.5\n",
    "WGS = {'epsg':'4326'}\n",
    "measure_crs = {'epsg':'32646'}\n",
    "# date = 'May2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dests = {\"All_markets\" : mkts_fil, \"Growth_centers\" : gc_fil}\n",
    "# cur = {'current' : [G_current,'_current_snapped.csv']}\n",
    "\n",
    "# for scen, values in cur.items():\n",
    "# #     namestr(values, globals())\n",
    "#     od_routine(values[0],scen,values[1])\n",
    "\n",
    "# for scen, values in cur.items():\n",
    "#     add_walking_time(scen,values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for u, v, data in G_upgr_all.edges(data=True):\n",
    "#     if data['osm_id'] == '244861071':\n",
    "#         print(data['infra_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for u, v, data in G_upgr_nosouth.edges(data=True):\n",
    "#     if data['osm_id'] == '244861071':\n",
    "#         print(data['infra_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions that will generate OD matrices, and then generate direct walking times from origins to destinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit of functions is they allow us to loop the analysis over the dictionary items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are big, messy, and adapted from old GOSTNets code. Though functional, the code could likely be streamlined as it's tricky to troubleshoot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def od_routine(G_input,scenario='',snap_ending='_snapped.csv'):\n",
    "    \n",
    "    origins_pop_nodes = list(set(origins.NN)) # consolidates by shared nodes. \n",
    "    \n",
    "    for dest_type, fpth in dests.items():\n",
    "\n",
    "        snapfile = dest_type + snap_ending\n",
    "\n",
    "        print(dest_type)\n",
    "\n",
    "        dest = pd.read_csv(os.path.join(fin_pth,snapfile))\n",
    "        dest_nodes = list(set(dest.NN))\n",
    "\n",
    "        print(len(list(set(dest.NN))))\n",
    "\n",
    "        od_time = gn.calculate_OD(G_input, origins=origins_pop_nodes, \n",
    "                              destinations=dest_nodes, fail_value=99999999, weight='time')\n",
    "\n",
    "        od_time_df = pd.DataFrame(od_time, index=origins_pop_nodes, columns=dest_nodes)\n",
    "\n",
    "        print(od_time_df.shape)\n",
    "\n",
    "        # Add walking time (from origin to NN) for each OD\n",
    "\n",
    "        # origins_join = origins_pop_snapped.merge(od_time_df, how='left', on='NN')\n",
    "        origins['NN_dist_seconds'] = ((origins.NN_dist / 1000) / walk_speed) * 60 * 60\n",
    "        origins_join = origins.join(od_time_df, on='NN', rsuffix=\"dist_\")\n",
    "\n",
    "    #     print(origins_join.head())\n",
    "\n",
    "        origins_join.columns[6:len(origins_join.columns)]\n",
    "\n",
    "        origins_join.to_csv(os.path.join(fin_pth,'origins_walktime_{}_NN_{}.csv'.format(scenario,dest_type)))\n",
    "        od_time_df.to_csv(os.path.join(fin_pth,'OD_matrix_{}_NN_{}.csv'.format(scenario,dest_type)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_walking_time(scenario='',snap_ending='_snapped.csv'):\n",
    "    # Main method\n",
    "    \n",
    "    print(scenario)\n",
    "\n",
    "    for dest_type, fpth in dests.items():\n",
    "\n",
    "        snapfile = dest_type + snap_ending\n",
    "\n",
    "        print(dest_type)\n",
    "\n",
    "        OD_name = r'OD_matrix_{}_NN_{}.csv'.format(scenario,dest_type)\n",
    "\n",
    "        OD = pd.read_csv(os.path.join(fin_pth, OD_name))\n",
    "        # OD = od_time_df\n",
    "\n",
    "        OD = OD.rename(columns = {'Unnamed: 0':'O_ID'})\n",
    "        OD = OD.set_index('O_ID')\n",
    "        OD = OD.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    #     # Filtering by only desired destination in an all-destination OD matrix.\n",
    "    #     # Skipping for now\n",
    "\n",
    "        od_dest_df = pd.read_csv(os.path.join(fin_pth,snapfile))\n",
    "        od_dest_df['geometry'] = od_dest_df['geometry'].apply(loads)\n",
    "#         od_dest_gdf = gpd.GeoDataFrame(od_dest_df, crs = {'init':'epsg:4326'}, geometry = 'geometry')\n",
    "\n",
    "    #     accepted_facilities = list(set(list(acceptable_df.NN)))\n",
    "    #     accepted_facilities_str = [str(i) for i in accepted_facilities]\n",
    "\n",
    "    #     print(accepted_facilities)\n",
    "    #     print(accepted_facilities_str)\n",
    "    #     # OD = OD_original[accepted_facilities_str] # not necessary, already done\n",
    "    #     # acceptable_df.to_csv(os.path.join(basepth,'Output','%s.csv' % subset))\n",
    "\n",
    "        # Computing walk time from network to destination\n",
    "\n",
    "        dest = pd.read_csv(os.path.join(fin_pth,snapfile))\n",
    "\n",
    "        dest_df = dest[['NN','NN_dist']]\n",
    "        dest_df = dest_df.set_index('NN')\n",
    "\n",
    "        dest_df['NN_dist'] = dest_df['NN_dist'] / 1000 * 3600 / walk_speed\n",
    "        dest_df.index = dest_df.index.map(str)\n",
    "\n",
    "        d_f = OD.transpose()\n",
    "\n",
    "        for i in d_f.columns:\n",
    "            dest_df[i] = d_f[i]\n",
    "\n",
    "        for i in dest_df.columns:\n",
    "            if i == 'NN_dist':\n",
    "                pass\n",
    "            else:\n",
    "                dest_df[i] = dest_df[i] + dest_df['NN_dist']\n",
    "                \n",
    "        dest_df = dest_df.drop('NN_dist', axis = 1)\n",
    "        dest_df = dest_df.transpose()\n",
    "        dest_df['min_time'] = dest_df.min(axis = 1)\n",
    "\n",
    "#         dest_df['geometry'] = dest_df['geometry'].apply(loads)\n",
    "        dest_gdf = gpd.GeoDataFrame(od_dest_df, geometry = 'geometry', crs = {'init':'epsg:4326'})\n",
    "\n",
    "        # Add walk time from origin to network\n",
    "\n",
    "        grid = pd.read_csv(os.path.join(fin_pth, grid_name))\n",
    "        grid = grid.rename(columns = {'NN':'O_ID','NN_dist':'walk_to_road_net'})\n",
    "        grid = grid.set_index(grid['O_ID'])\n",
    "\n",
    "        grid['on_network_time'] = dest_df['min_time']\n",
    "        grid['walk_to_road_net'] = grid['walk_to_road_net'] / 1000 * 3600 / walk_speed \n",
    "        grid['total_time_net'] = grid['on_network_time'] + grid['walk_to_road_net']\n",
    "\n",
    "#         print(grid.head())\n",
    "\n",
    "        grid['geometry'] = grid['geometry'].apply(loads)\n",
    "        o_2_d = gpd.GeoDataFrame(grid, crs = {'init':'epsg:4326'}, geometry = 'geometry')\n",
    "\n",
    "            # Snapping!\n",
    "\n",
    "        print('start of snapping: %s\\n' % time.ctime())\n",
    "        o_2_d = gn.pandana_snap_points(o_2_d, \n",
    "                                   dest_gdf, # eventually just use dest_gdf\n",
    "                                   source_crs='epsg:4326',\n",
    "                                   target_crs='epsg:32646',\n",
    "                                   add_dist_to_node_col = True)\n",
    "        print('\\nend of snapping: %s' % time.ctime())\n",
    "        print('\\n--- processing complete')\n",
    "\n",
    "            # Recalculating the resulting walking times into seconds and minutes.\n",
    "            # Make sure that if walking is faster than on-network travel, it prefers walking\n",
    "\n",
    "        o_2_d['walk_time_direct'] = o_2_d['idx_dist'] / 1000 * 3600 / walk_speed\n",
    "\n",
    "        grid['walk_time_direct'] = o_2_d['walk_time_direct']\n",
    "\n",
    "        # grid['PLOT_TIME_SECS'] = grid[['total_time_net']].min(axis = 1)\n",
    "        # grid['PLOT_TIME_SECS'] = grid[['walk_to_road_net','total_time_net']].min(axis = 1)\n",
    "\n",
    "            # The city locations / port location don't have walk_time_direct values so we use if/else logic to work around them.\n",
    "\n",
    "        if 'walk_time_direct' in grid.columns:\n",
    "            grid['PLOT_TIME_SECS'] = grid[['walk_time_direct','total_time_net']].min(axis = 1)\n",
    "        else:\n",
    "            grid['PLOT_TIME_SECS'] = grid[['total_time_net']]\n",
    "\n",
    "        grid['PLOT_TIME_MINS'] = grid['PLOT_TIME_SECS'] / 60\n",
    "\n",
    "        if 'walk_time_direct' in grid.columns:\n",
    "            def choice(x):\n",
    "                if x.walk_time_direct < x.total_time_net:\n",
    "                    return 'walk'\n",
    "                else:\n",
    "                    return 'net'\n",
    "\n",
    "            grid['choice'] = grid.apply(lambda x: choice(x), axis = 1)\n",
    "            grid['choice'].value_counts()\n",
    "\n",
    "#         print(grid.head())\n",
    "\n",
    "        # Export\n",
    "\n",
    "        grid.to_csv(os.path.join(fin_pth,'final_cxb_{}_od_grid_{}.csv'.format(scenario,dest_type)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load origins and destinations, get unique origin nodes, run OD, export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the OD routine function on all destinations for the 3 different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CXB\n",
      "1\n",
      "(34, 1)\n",
      "CXB\n",
      "1\n",
      "(34, 1)\n",
      "CXB\n",
      "1\n",
      "(34, 1)\n",
      "CXB\n",
      "1\n",
      "(34, 1)\n"
     ]
    }
   ],
   "source": [
    "for scen, values in scenarios.items():\n",
    "    od_routine(values[0],scen,values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import completed OD matrix, calcualte walking times from origins to the destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current\n",
      "CXB\n",
      "start of snapping: Fri Jun 12 14:54:38 2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wb467985\\.conda\\envs\\geo\\lib\\site-packages\\pyproj\\crs\\crs.py:55: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "end of snapping: Fri Jun 12 14:54:39 2020\n",
      "\n",
      "--- processing complete\n",
      "upgrade_all\n",
      "CXB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wb467985\\.conda\\envs\\geo\\lib\\site-packages\\pyproj\\crs\\crs.py:55: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of snapping: Fri Jun 12 14:54:39 2020\n",
      "\n",
      "\n",
      "end of snapping: Fri Jun 12 14:54:39 2020\n",
      "\n",
      "--- processing complete\n",
      "upgrade_nosouth\n",
      "CXB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wb467985\\.conda\\envs\\geo\\lib\\site-packages\\pyproj\\crs\\crs.py:55: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of snapping: Fri Jun 12 14:54:39 2020\n",
      "\n",
      "\n",
      "end of snapping: Fri Jun 12 14:54:40 2020\n",
      "\n",
      "--- processing complete\n",
      "upgrade_noferry\n",
      "CXB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wb467985\\.conda\\envs\\geo\\lib\\site-packages\\pyproj\\crs\\crs.py:55: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of snapping: Fri Jun 12 14:54:40 2020\n",
      "\n",
      "\n",
      "end of snapping: Fri Jun 12 14:54:40 2020\n",
      "\n",
      "--- processing complete\n"
     ]
    }
   ],
   "source": [
    "for scen, values in scenarios.items():\n",
    "    add_walking_time(scen,values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have completed OD matrices for everything"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
