{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://wiki.worldbank.org/display/GEOS/MEX_AGEBS_Zonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, importlib\n",
    "import rasterio, ee, geojson\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import skimage.graph as graph\n",
    "\n",
    "from shapely.geometry import box\n",
    "\n",
    "sys.path.append(\"../../../../gostrocks/src\")\n",
    "import GOSTRocks.rasterMisc as rMisc\n",
    "from GOSTRocks.misc import tPrint\n",
    "\n",
    "sys.path.append(\"../../../../GEE_Zonal/src\")\n",
    "import gee_tools as gee\n",
    "\n",
    "sys.path.append(\"../../../../GOST_Urban/\")\n",
    "from src import UrbanRaster\n",
    "\n",
    "sys.path.append(\"../../../../GOSTNets_Raster/src\")\n",
    "import GOSTNets_Raster.market_access as ma\n",
    "\n",
    "ee.Initialize()\n",
    "cat = gee.Catalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inpput Data\n",
    "in_folder = \"/home/wb411133/data/Country/MEX\"\n",
    "zonal_out_folder = os.path.join(in_folder, \"ZONAL_OUTPUTS\")\n",
    "raster_folder = os.path.join(in_folder, \"GIS_DATA\")\n",
    "ndvi_folder = os.path.join(zonal_out_folder, \"NDVI\")\n",
    "chirps_folder = os.path.join(zonal_out_folder, \"CHIRPS\")\n",
    "\n",
    "for tFolder in [zonal_out_folder, raster_folder, ndvi_folder, chirps_folder]:\n",
    "    if not os.path.exists(tFolder):\n",
    "        os.makedirs(tFolder)\n",
    "    \n",
    "agebs_folder = os.path.join(in_folder, 'AGEB', 'AGEBS')\n",
    "agebs_files = [os.path.join(agebs_folder, x) for x in os.listdir(agebs_folder) if x.endswith(\".shp\")]\n",
    "\n",
    "pop_file = \"/home/public/Data/GLOBAL/Population/WorldPop_PPP_2020/ppp_2020_1km_Aggregated.tif\"\n",
    "ghsl_file = '/home/public/Data/GLOBAL/URBAN/GHS/GHS_SMOD/GHS_SMOD_POP2015_GLOBE_R2019A_54009_1K_V2_0.tif'\n",
    "global_access_map = '/home/public/Data/GLOBAL/INFRA/FRICTION_2020/2020_motorized_friction_surface.geotiff'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output data\n",
    "master_agebs = f\"{agebs_folder}.shp\"\n",
    "cur_file = master_agebs\n",
    "\n",
    "out_ghsl = os.path.join(zonal_out_folder, f'{os.path.basename(cur_file)[:-4]}_GHSL.csv')\n",
    "out_pop_summaries = os.path.join(zonal_out_folder, f'{os.path.basename(cur_file)[:-4]}_Pop2020.csv')\n",
    "ndvi_zonal = os.path.join(zonal_out_folder, f'{os.path.basename(cur_file)[:-4]}_NDVI_monthly.csv')\n",
    "ntl_zonal_csv = os.path.join(zonal_out_folder, f'{os.path.basename(cur_file)[:-4]}_ntl_zonal_res.csv') \n",
    "urban_pop = os.path.join(zonal_out_folder, f'{os.path.basename(cur_file)[:-4]}_UrbanPop2020.csv')\n",
    "hd_pop = os.path.join(zonal_out_folder, f'{os.path.basename(cur_file)[:-4]}_HD_UrbanPop2020.csv')\n",
    "urban_access_res = os.path.join(zonal_out_folder, f'{os.path.basename(cur_file)[:-4]}_urban_market_access.csv')\n",
    "hd_urban_access_res = os.path.join(zonal_out_folder, f'{os.path.basename(cur_file)[:-4]}_hd_urban_market_access.csv')\n",
    "\n",
    "local_pop         = os.path.join(raster_folder, f'{os.path.basename(cur_file)[:-4]}_WorldPop.tif')\n",
    "local_urban       = os.path.join(raster_folder, f'{os.path.basename(cur_file)[:-4]}_Urban.tif')\n",
    "local_urban_pop   = os.path.join(raster_folder, f'{os.path.basename(cur_file)[:-4]}_UrbanPop.tif')\n",
    "local_urban_hd    = os.path.join(raster_folder, f'{os.path.basename(cur_file)[:-4]}_HDUrban.tif')\n",
    "local_urban_hdpop = os.path.join(raster_folder, f'{os.path.basename(cur_file)[:-4]}_HDUrbanPop.tif')\n",
    "local_access_map  = os.path.join(raster_folder, f'{os.path.basename(cur_file)[:-4]}_friction_surface.tif')\n",
    "urban_extents_file = os.path.join(raster_folder, f'{os.path.basename(cur_file)[:-4]}_UrbanExtents.shp')\n",
    "hd_urban_extents_file = os.path.join(raster_folder, f'{os.path.basename(cur_file)[:-4]}_HD_UrbanExtents.shp')\n",
    "urban_access = os.path.join(raster_folder, f'{os.path.basename(cur_file)[:-4]}_access_to_urban.tif')\n",
    "hd_urban_access = os.path.join(raster_folder, f'{os.path.basename(cur_file)[:-4]}_access_to_hd_urban.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine agebs into a single dataset\n",
    "if not os.path.exists(master_agebs):\n",
    "    try: \n",
    "        del final\n",
    "    except:\n",
    "        pass\n",
    "    for agebs_file in agebs_files:\n",
    "        inD = gpd.read_file(agebs_file)\n",
    "        try:\n",
    "            final = final.append(inD)\n",
    "            final.reset_index()\n",
    "        except:\n",
    "            final = inD\n",
    "\n",
    "    final.to_file(master_agebs)\n",
    "    inD = final    \n",
    "else:\n",
    "    inD = gpd.read_file(master_agebs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the input shapefile into a GEE collection\n",
    "def gpd_to_gee(inD, id_col):\n",
    "    ''' Create a google earth engine feature collection from a geopandas object\n",
    "    INPUT\n",
    "        inD [geopandas dataframe]\n",
    "        id_col [string] - column name used to ID the features\n",
    "    '''\n",
    "    all_polys = []\n",
    "    bad_idx = []\n",
    "    for idx, row in inD.iterrows():\n",
    "        try:\n",
    "            shpJSON = geojson.Feature(geometry=row['geometry'], properties={\"ID\":row[id_col]})\n",
    "            try:\n",
    "                ee_poly = ee.Geometry.Polygon(shpJSON['geometry']['coordinates'])\n",
    "            except:\n",
    "                ee_poly = ee.Geometry.MultiPolygon(shpJSON['geometry']['coordinates'])\n",
    "            all_polys.append(ee_poly)\n",
    "        except:\n",
    "            print(idx)            \n",
    "            bad_idx.append(idx)\n",
    "    cur_ee = ee.featurecollection.FeatureCollection(all_polys)\n",
    "    return(cur_ee)\n",
    "\n",
    "def get_zonal_res(res):\n",
    "    ''' create a data frame from the results of GEE zonal results (res.getInfo())\n",
    "    '''\n",
    "    all_res = []\n",
    "    for feat in res['features']:\n",
    "        all_res.append(feat['properties'])\n",
    "    return(pd.DataFrame(all_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDVI - Vegetation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cat.search_tags(\"ndvi\")\n",
    "results = results.search_title(\"Landsat\")\n",
    "results = results.search_title(\"32-day\")\n",
    "\n",
    "landsat_collection = results.datasets.iloc[0,0]\n",
    "lc_id = landsat_collection[landsat_collection.find(\"/\")+1:landsat_collection.find(\"/\")+5]\n",
    "stat = 'MAX'\n",
    "\n",
    "results.datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(gee)\n",
    "step_count = 250\n",
    "steps = list(range(step_count, inD.shape[0], step_count))\n",
    "steps.append(inD.shape[0])\n",
    "#steps = list(range(step_count, 1000, step_count))\n",
    "start_idx = 0\n",
    "try:\n",
    "    del brokenD\n",
    "except:\n",
    "    pass\n",
    "for end_idx in steps:\n",
    "    curD = inD.iloc[start_idx:end_idx,]\n",
    "    out_file = os.path.join(ndvi_folder, f'MASTER_LIST_NDVI_{start_idx}_{end_idx}.csv')\n",
    "    if not os.path.exists(out_file):\n",
    "        try:\n",
    "            tPrint(os.path.basename(out_file))\n",
    "            cur_ee = gpd_to_gee(curD, 'CVEGEO')\n",
    "            # Run analysis on just the L8 data\n",
    "            zs = gee.ZonalStats(collection_id = landsat_collection,\n",
    "                            target_features = cur_ee,\n",
    "                            statistic_type = \"all\",\n",
    "                            output_name=f\"{lc_id}_ndvi_{stat}\",\n",
    "                            scale=1000,\n",
    "                            min_threshold=0.1,\n",
    "                            water_mask=True,                                    \n",
    "                            tile_scale = 16\n",
    "                           )\n",
    "            zonal_res = zs.runZonalStats()\n",
    "            res = zonal_res.getInfo()\n",
    "            pd_res = get_zonal_res(res)\n",
    "            pd_res[\"CVEGEO\"] = curD[\"CVEGEO\"].values\n",
    "            pd_res.to_csv(out_file)                        \n",
    "        except:\n",
    "            try:\n",
    "                brokenD = brokenD.append(curD)\n",
    "            except:\n",
    "                brokenD = curD\n",
    "            tPrint(f'***ERROR{os.path.basename(out_file)}')\n",
    "            pass\n",
    "    start_idx = end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brokenD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(gee)\n",
    "step_count = 100\n",
    "steps = list(range(step_count, brokenD.shape[0], step_count))\n",
    "steps.append(inD.shape[0])\n",
    "start_idx = 0\n",
    "try:\n",
    "    del stillBrokenD\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for end_idx in steps:\n",
    "    curD = brokenD.iloc[start_idx:end_idx,]\n",
    "    out_file = os.path.join(ndvi_folder, f'MASTER_LIST_NDVI_BROKEN_{start_idx}_{end_idx}.csv')\n",
    "    if not os.path.exists(out_file):\n",
    "        try:\n",
    "            tPrint(os.path.basename(out_file))\n",
    "            cur_ee = gpd_to_gee(curD, 'CVEGEO')\n",
    "            # Run analysis on just the L8 data\n",
    "            zs = gee.ZonalStats(collection_id = landsat_collection,\n",
    "                            target_features = cur_ee,\n",
    "                            statistic_type = \"all\",\n",
    "                            output_name=f\"{lc_id}_ndvi_{stat}\",\n",
    "                            scale=1000,\n",
    "                            min_threshold=0.1,\n",
    "                            water_mask=True,                                    \n",
    "                            tile_scale = 16\n",
    "                           )\n",
    "            zonal_res = zs.runZonalStats()\n",
    "            res = zonal_res.getInfo()\n",
    "            pd_res = get_zonal_res(res)\n",
    "            pd_res[\"CVEGEO\"] = curD[\"CVEGEO\"].values\n",
    "            pd_res.to_csv(out_file)                        \n",
    "        except:\n",
    "            try:\n",
    "                stillBrokenD = stillBrokenD.append(curD)\n",
    "            except:\n",
    "                stillBrokenD = curD\n",
    "            tPrint(f'***ERROR{os.path.basename(out_file)}')\n",
    "            pass\n",
    "    start_idx = end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.exists(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del final\n",
    "except:\n",
    "    pass\n",
    "for ndvi_file in os.listdir(ndvi_folder):\n",
    "    curN = pd.read_csv(os.path.join(ndvi_folder, ndvi_file), index_col=0)\n",
    "    bad_id_cnt = curN['CVEGEO'].fillna(-1).value_counts().iloc[0]\n",
    "    if bad_id_cnt > 1:\n",
    "        start_idx = int(ndvi_file.split(\"_\")[-2])\n",
    "        end_idx = int(ndvi_file.split(\"_\")[-1].replace(\".csv\", \"\"))\n",
    "        curD = inD.iloc[start_idx:end_idx,]\n",
    "        good_ids = curD['CVEGEO'].values\n",
    "        curN['CVEGEO'] = good_ids\n",
    "    tPrint(f\"{ndvi_file}: {bad_id_cnt}\")\n",
    "    try:\n",
    "        final = final.append(curN)\n",
    "    except:\n",
    "        final = curN        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(ndvi_zonal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHIRPS - Weather "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cat.search_tags(\"weather\")\n",
    "results = results.search_title(\"CHIRPS\")\n",
    "\n",
    "chirps_collection = results.datasets.iloc[1,0]\n",
    "stat = 'MAX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:51:23\tMASTER_LIST_CHIRPS_100_200.csv\n",
      "09:51:25\tMASTER_LIST_CHIRPS_200_300.csv\n",
      "09:51:28\tMASTER_LIST_CHIRPS_300_400.csv\n",
      "09:51:31\tMASTER_LIST_CHIRPS_400_500.csv\n",
      "09:51:39\tMASTER_LIST_CHIRPS_500_600.csv\n",
      "09:51:48\tMASTER_LIST_CHIRPS_600_700.csv\n",
      "09:51:58\tMASTER_LIST_CHIRPS_700_800.csv\n",
      "09:52:03\tMASTER_LIST_CHIRPS_800_900.csv\n",
      "09:52:07\tMASTER_LIST_CHIRPS_900_1000.csv\n",
      "09:52:09\tMASTER_LIST_CHIRPS_1000_1100.csv\n",
      "09:52:12\tMASTER_LIST_CHIRPS_1100_1200.csv\n",
      "09:52:15\tMASTER_LIST_CHIRPS_1200_1300.csv\n",
      "09:52:17\tMASTER_LIST_CHIRPS_1300_1400.csv\n",
      "09:52:20\tMASTER_LIST_CHIRPS_1400_1500.csv\n",
      "09:52:22\tMASTER_LIST_CHIRPS_1500_1600.csv\n",
      "09:52:25\tMASTER_LIST_CHIRPS_1600_1700.csv\n",
      "09:52:27\tMASTER_LIST_CHIRPS_1700_1800.csv\n",
      "09:52:31\tMASTER_LIST_CHIRPS_1800_1900.csv\n",
      "09:52:34\tMASTER_LIST_CHIRPS_1900_2000.csv\n",
      "09:52:38\tMASTER_LIST_CHIRPS_2000_2100.csv\n",
      "09:52:41\tMASTER_LIST_CHIRPS_2100_2200.csv\n",
      "09:52:44\tMASTER_LIST_CHIRPS_2200_2300.csv\n",
      "09:52:47\tMASTER_LIST_CHIRPS_2300_2400.csv\n",
      "09:52:50\tMASTER_LIST_CHIRPS_2400_2500.csv\n",
      "09:53:01\tMASTER_LIST_CHIRPS_2500_2600.csv\n",
      "09:53:12\tMASTER_LIST_CHIRPS_2600_2700.csv\n",
      "09:53:15\tMASTER_LIST_CHIRPS_2700_2800.csv\n",
      "09:53:17\tMASTER_LIST_CHIRPS_2800_2900.csv\n",
      "09:53:20\tMASTER_LIST_CHIRPS_2900_3000.csv\n",
      "09:53:23\tMASTER_LIST_CHIRPS_3000_3100.csv\n",
      "09:53:25\tMASTER_LIST_CHIRPS_3100_3200.csv\n",
      "09:53:28\tMASTER_LIST_CHIRPS_3200_3300.csv\n",
      "09:53:31\tMASTER_LIST_CHIRPS_3300_3400.csv\n",
      "09:53:34\tMASTER_LIST_CHIRPS_3400_3500.csv\n",
      "09:53:40\tMASTER_LIST_CHIRPS_3500_3600.csv\n",
      "09:53:48\tMASTER_LIST_CHIRPS_3600_3700.csv\n",
      "09:53:53\tMASTER_LIST_CHIRPS_3700_3800.csv\n",
      "09:53:56\tMASTER_LIST_CHIRPS_3800_3900.csv\n",
      "09:53:59\tMASTER_LIST_CHIRPS_3900_4000.csv\n",
      "09:54:02\tMASTER_LIST_CHIRPS_4000_4100.csv\n",
      "09:54:07\tMASTER_LIST_CHIRPS_4100_4200.csv\n",
      "09:54:11\tMASTER_LIST_CHIRPS_4200_4300.csv\n",
      "09:54:16\tMASTER_LIST_CHIRPS_4300_4400.csv\n",
      "09:54:21\tMASTER_LIST_CHIRPS_4400_4500.csv\n",
      "09:54:25\tMASTER_LIST_CHIRPS_4500_4600.csv\n",
      "09:54:28\tMASTER_LIST_CHIRPS_4600_4700.csv\n",
      "09:54:35\tMASTER_LIST_CHIRPS_4700_4800.csv\n",
      "09:54:41\tMASTER_LIST_CHIRPS_4800_4900.csv\n",
      "09:54:45\tMASTER_LIST_CHIRPS_4900_5000.csv\n",
      "09:54:51\tMASTER_LIST_CHIRPS_5000_5100.csv\n",
      "09:54:56\tMASTER_LIST_CHIRPS_5100_5200.csv\n",
      "09:55:01\tMASTER_LIST_CHIRPS_5200_5300.csv\n",
      "09:55:06\tMASTER_LIST_CHIRPS_5300_5400.csv\n",
      "09:55:10\tMASTER_LIST_CHIRPS_5400_5500.csv\n",
      "09:55:15\tMASTER_LIST_CHIRPS_5500_5600.csv\n",
      "09:55:19\tMASTER_LIST_CHIRPS_5600_5700.csv\n",
      "09:55:25\tMASTER_LIST_CHIRPS_5700_5800.csv\n",
      "09:55:30\tMASTER_LIST_CHIRPS_5800_5900.csv\n",
      "09:55:35\tMASTER_LIST_CHIRPS_5900_6000.csv\n",
      "09:55:40\tMASTER_LIST_CHIRPS_6000_6100.csv\n",
      "09:55:43\tMASTER_LIST_CHIRPS_6100_6200.csv\n",
      "09:55:45\tMASTER_LIST_CHIRPS_6200_6300.csv\n",
      "09:55:49\tMASTER_LIST_CHIRPS_6300_6400.csv\n",
      "09:55:51\tMASTER_LIST_CHIRPS_6400_6500.csv\n",
      "09:55:54\tMASTER_LIST_CHIRPS_6500_6600.csv\n",
      "09:55:57\tMASTER_LIST_CHIRPS_6600_6700.csv\n",
      "09:56:00\tMASTER_LIST_CHIRPS_6700_6800.csv\n",
      "09:56:02\tMASTER_LIST_CHIRPS_6800_6900.csv\n",
      "09:56:05\tMASTER_LIST_CHIRPS_6900_7000.csv\n",
      "09:56:09\tMASTER_LIST_CHIRPS_7000_7100.csv\n",
      "09:56:11\tMASTER_LIST_CHIRPS_7100_7200.csv\n",
      "09:56:14\tMASTER_LIST_CHIRPS_7200_7300.csv\n",
      "09:56:17\tMASTER_LIST_CHIRPS_7300_7400.csv\n",
      "09:56:19\tMASTER_LIST_CHIRPS_7400_7500.csv\n",
      "09:56:23\tMASTER_LIST_CHIRPS_7500_7600.csv\n",
      "09:56:25\tMASTER_LIST_CHIRPS_7600_7700.csv\n",
      "09:56:28\tMASTER_LIST_CHIRPS_7700_7800.csv\n",
      "09:56:32\tMASTER_LIST_CHIRPS_7800_7900.csv\n",
      "09:56:34\tMASTER_LIST_CHIRPS_7900_8000.csv\n",
      "09:56:37\tMASTER_LIST_CHIRPS_8000_8100.csv\n",
      "09:56:40\tMASTER_LIST_CHIRPS_8100_8200.csv\n",
      "09:56:43\tMASTER_LIST_CHIRPS_8200_8300.csv\n",
      "09:56:46\tMASTER_LIST_CHIRPS_8300_8400.csv\n",
      "09:56:50\tMASTER_LIST_CHIRPS_8400_8500.csv\n",
      "09:56:52\tMASTER_LIST_CHIRPS_8500_8600.csv\n",
      "09:56:55\tMASTER_LIST_CHIRPS_8600_8700.csv\n",
      "09:56:58\tMASTER_LIST_CHIRPS_8700_8800.csv\n",
      "09:57:02\tMASTER_LIST_CHIRPS_8800_8900.csv\n",
      "09:57:08\tMASTER_LIST_CHIRPS_8900_9000.csv\n",
      "09:57:16\tMASTER_LIST_CHIRPS_9000_9100.csv\n",
      "09:57:25\tMASTER_LIST_CHIRPS_9100_9200.csv\n",
      "09:57:34\tMASTER_LIST_CHIRPS_9200_9300.csv\n",
      "09:57:44\tMASTER_LIST_CHIRPS_9300_9400.csv\n",
      "09:57:53\tMASTER_LIST_CHIRPS_9400_9500.csv\n",
      "09:58:02\tMASTER_LIST_CHIRPS_9500_9600.csv\n",
      "09:58:11\tMASTER_LIST_CHIRPS_9600_9700.csv\n",
      "09:58:16\tMASTER_LIST_CHIRPS_9700_9800.csv\n",
      "09:58:20\tMASTER_LIST_CHIRPS_9800_9900.csv\n",
      "09:58:23\tMASTER_LIST_CHIRPS_9900_10000.csv\n",
      "09:58:27\tMASTER_LIST_CHIRPS_10000_10100.csv\n",
      "09:58:30\tMASTER_LIST_CHIRPS_10100_10200.csv\n",
      "09:58:33\tMASTER_LIST_CHIRPS_10200_10300.csv\n",
      "09:58:37\tMASTER_LIST_CHIRPS_10300_10400.csv\n",
      "09:58:40\tMASTER_LIST_CHIRPS_10400_10500.csv\n",
      "09:58:44\tMASTER_LIST_CHIRPS_10500_10600.csv\n",
      "09:58:47\tMASTER_LIST_CHIRPS_10600_10700.csv\n",
      "09:58:51\tMASTER_LIST_CHIRPS_10700_10800.csv\n",
      "09:58:55\tMASTER_LIST_CHIRPS_10800_10900.csv\n",
      "09:58:59\tMASTER_LIST_CHIRPS_10900_11000.csv\n",
      "09:59:04\tMASTER_LIST_CHIRPS_11000_11100.csv\n",
      "09:59:08\tMASTER_LIST_CHIRPS_11100_11200.csv\n",
      "09:59:12\tMASTER_LIST_CHIRPS_11200_11300.csv\n",
      "09:59:16\tMASTER_LIST_CHIRPS_11300_11400.csv\n",
      "09:59:19\tMASTER_LIST_CHIRPS_11400_11500.csv\n",
      "09:59:26\tMASTER_LIST_CHIRPS_11500_11600.csv\n",
      "09:59:31\tMASTER_LIST_CHIRPS_11600_11700.csv\n",
      "09:59:37\tMASTER_LIST_CHIRPS_11700_11800.csv\n",
      "09:59:41\tMASTER_LIST_CHIRPS_11800_11900.csv\n",
      "09:59:45\tMASTER_LIST_CHIRPS_11900_12000.csv\n",
      "09:59:49\tMASTER_LIST_CHIRPS_12000_12100.csv\n",
      "09:59:52\tMASTER_LIST_CHIRPS_12100_12200.csv\n",
      "09:59:56\tMASTER_LIST_CHIRPS_12200_12300.csv\n",
      "10:00:01\tMASTER_LIST_CHIRPS_12300_12400.csv\n",
      "10:00:06\tMASTER_LIST_CHIRPS_12400_12500.csv\n",
      "10:00:10\tMASTER_LIST_CHIRPS_12500_12600.csv\n",
      "10:00:13\tMASTER_LIST_CHIRPS_12600_12700.csv\n",
      "10:00:16\tMASTER_LIST_CHIRPS_12700_12800.csv\n",
      "10:00:19\tMASTER_LIST_CHIRPS_12800_12900.csv\n",
      "10:00:21\tMASTER_LIST_CHIRPS_12900_13000.csv\n",
      "10:00:25\tMASTER_LIST_CHIRPS_13000_13100.csv\n",
      "10:00:29\tMASTER_LIST_CHIRPS_13100_13200.csv\n",
      "10:00:32\tMASTER_LIST_CHIRPS_13200_13300.csv\n",
      "10:00:35\tMASTER_LIST_CHIRPS_13300_13400.csv\n",
      "10:00:38\tMASTER_LIST_CHIRPS_13400_13500.csv\n",
      "10:00:41\tMASTER_LIST_CHIRPS_13500_13600.csv\n",
      "10:00:43\tMASTER_LIST_CHIRPS_13600_13700.csv\n",
      "10:00:46\tMASTER_LIST_CHIRPS_13700_13800.csv\n",
      "10:00:50\tMASTER_LIST_CHIRPS_13800_13900.csv\n",
      "10:00:53\tMASTER_LIST_CHIRPS_13900_14000.csv\n",
      "10:00:56\tMASTER_LIST_CHIRPS_14000_14100.csv\n",
      "10:00:59\tMASTER_LIST_CHIRPS_14100_14200.csv\n",
      "10:01:02\tMASTER_LIST_CHIRPS_14200_14300.csv\n",
      "10:01:04\tMASTER_LIST_CHIRPS_14300_14400.csv\n",
      "10:01:08\tMASTER_LIST_CHIRPS_14400_14500.csv\n",
      "10:01:16\tMASTER_LIST_CHIRPS_14500_14600.csv\n",
      "10:01:18\tMASTER_LIST_CHIRPS_14600_14700.csv\n",
      "10:01:21\tMASTER_LIST_CHIRPS_14700_14800.csv\n",
      "10:01:24\tMASTER_LIST_CHIRPS_14800_14900.csv\n",
      "10:01:35\tMASTER_LIST_CHIRPS_14900_15000.csv\n",
      "10:01:37\tMASTER_LIST_CHIRPS_15000_15100.csv\n",
      "10:01:42\tMASTER_LIST_CHIRPS_15100_15200.csv\n",
      "10:01:45\tMASTER_LIST_CHIRPS_15200_15300.csv\n",
      "10:01:48\tMASTER_LIST_CHIRPS_15300_15400.csv\n",
      "10:01:51\tMASTER_LIST_CHIRPS_15400_15500.csv\n",
      "10:01:54\tMASTER_LIST_CHIRPS_15500_15600.csv\n",
      "10:01:57\tMASTER_LIST_CHIRPS_15600_15700.csv\n",
      "10:02:00\tMASTER_LIST_CHIRPS_15700_15800.csv\n",
      "10:02:03\tMASTER_LIST_CHIRPS_15800_15900.csv\n",
      "10:02:06\tMASTER_LIST_CHIRPS_15900_16000.csv\n",
      "10:02:09\tMASTER_LIST_CHIRPS_16000_16100.csv\n",
      "10:02:16\tMASTER_LIST_CHIRPS_16100_16200.csv\n",
      "10:02:18\tMASTER_LIST_CHIRPS_16200_16300.csv\n",
      "10:02:22\tMASTER_LIST_CHIRPS_16300_16400.csv\n",
      "10:02:26\tMASTER_LIST_CHIRPS_16400_16500.csv\n",
      "10:02:29\tMASTER_LIST_CHIRPS_16500_16600.csv\n",
      "10:02:32\tMASTER_LIST_CHIRPS_16600_16700.csv\n",
      "10:02:35\tMASTER_LIST_CHIRPS_16700_16800.csv\n",
      "10:02:39\tMASTER_LIST_CHIRPS_16800_16900.csv\n",
      "10:02:42\tMASTER_LIST_CHIRPS_16900_17000.csv\n",
      "10:02:46\tMASTER_LIST_CHIRPS_17000_17100.csv\n",
      "10:02:48\tMASTER_LIST_CHIRPS_17100_17200.csv\n",
      "10:02:50\tMASTER_LIST_CHIRPS_17200_17300.csv\n",
      "10:02:53\tMASTER_LIST_CHIRPS_17300_17400.csv\n",
      "10:02:56\tMASTER_LIST_CHIRPS_17400_17500.csv\n",
      "10:03:00\tMASTER_LIST_CHIRPS_17500_17600.csv\n",
      "10:03:06\tMASTER_LIST_CHIRPS_17600_17700.csv\n",
      "10:03:12\tMASTER_LIST_CHIRPS_17700_17800.csv\n",
      "10:03:18\tMASTER_LIST_CHIRPS_17800_17900.csv\n",
      "10:03:25\tMASTER_LIST_CHIRPS_17900_18000.csv\n",
      "10:03:31\tMASTER_LIST_CHIRPS_18000_18100.csv\n",
      "10:03:37\tMASTER_LIST_CHIRPS_18100_18200.csv\n",
      "10:03:43\tMASTER_LIST_CHIRPS_18200_18300.csv\n",
      "10:03:45\tMASTER_LIST_CHIRPS_18300_18400.csv\n",
      "10:03:49\tMASTER_LIST_CHIRPS_18400_18500.csv\n",
      "10:03:52\tMASTER_LIST_CHIRPS_18500_18600.csv\n",
      "10:03:54\tMASTER_LIST_CHIRPS_18600_18700.csv\n",
      "10:03:57\tMASTER_LIST_CHIRPS_18700_18800.csv\n",
      "10:03:59\tMASTER_LIST_CHIRPS_18800_18900.csv\n",
      "10:04:03\tMASTER_LIST_CHIRPS_18900_19000.csv\n",
      "10:04:06\tMASTER_LIST_CHIRPS_19000_19100.csv\n",
      "10:04:09\tMASTER_LIST_CHIRPS_19100_19200.csv\n",
      "10:04:12\tMASTER_LIST_CHIRPS_19200_19300.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:04:14\tMASTER_LIST_CHIRPS_19300_19400.csv\n",
      "10:04:17\tMASTER_LIST_CHIRPS_19400_19500.csv\n",
      "10:04:19\tMASTER_LIST_CHIRPS_19500_19600.csv\n",
      "10:04:22\tMASTER_LIST_CHIRPS_19600_19700.csv\n",
      "10:04:24\tMASTER_LIST_CHIRPS_19700_19800.csv\n",
      "10:04:27\tMASTER_LIST_CHIRPS_19800_19900.csv\n",
      "10:04:29\tMASTER_LIST_CHIRPS_19900_20000.csv\n",
      "10:04:33\tMASTER_LIST_CHIRPS_20000_20100.csv\n",
      "10:04:38\tMASTER_LIST_CHIRPS_20100_20200.csv\n",
      "10:04:46\tMASTER_LIST_CHIRPS_20200_20300.csv\n",
      "10:04:54\tMASTER_LIST_CHIRPS_20300_20400.csv\n",
      "10:05:07\tMASTER_LIST_CHIRPS_20400_20500.csv\n",
      "10:05:17\tMASTER_LIST_CHIRPS_20500_20600.csv\n",
      "10:05:27\tMASTER_LIST_CHIRPS_20600_20700.csv\n",
      "10:05:35\tMASTER_LIST_CHIRPS_20700_20800.csv\n",
      "10:05:40\tMASTER_LIST_CHIRPS_20800_20900.csv\n",
      "10:05:43\tMASTER_LIST_CHIRPS_20900_21000.csv\n",
      "10:05:52\tMASTER_LIST_CHIRPS_21000_21100.csv\n",
      "10:05:56\tMASTER_LIST_CHIRPS_21100_21200.csv\n",
      "10:06:00\tMASTER_LIST_CHIRPS_21200_21300.csv\n",
      "10:06:03\tMASTER_LIST_CHIRPS_21300_21400.csv\n",
      "10:06:07\tMASTER_LIST_CHIRPS_21400_21500.csv\n",
      "10:06:10\tMASTER_LIST_CHIRPS_21500_21600.csv\n",
      "10:06:13\tMASTER_LIST_CHIRPS_21600_21700.csv\n",
      "10:06:16\tMASTER_LIST_CHIRPS_21700_21800.csv\n",
      "10:06:20\tMASTER_LIST_CHIRPS_21800_21900.csv\n",
      "10:06:22\tMASTER_LIST_CHIRPS_21900_22000.csv\n",
      "10:06:24\tMASTER_LIST_CHIRPS_22000_22100.csv\n",
      "10:06:28\tMASTER_LIST_CHIRPS_22100_22200.csv\n",
      "10:06:31\tMASTER_LIST_CHIRPS_22200_22300.csv\n",
      "10:06:35\tMASTER_LIST_CHIRPS_22300_22400.csv\n",
      "10:06:38\tMASTER_LIST_CHIRPS_22400_22500.csv\n",
      "10:06:41\tMASTER_LIST_CHIRPS_22500_22600.csv\n",
      "10:06:44\tMASTER_LIST_CHIRPS_22600_22700.csv\n",
      "10:06:47\tMASTER_LIST_CHIRPS_22700_22800.csv\n",
      "10:06:50\tMASTER_LIST_CHIRPS_22800_22900.csv\n",
      "10:06:54\tMASTER_LIST_CHIRPS_22900_23000.csv\n",
      "10:06:59\tMASTER_LIST_CHIRPS_23000_23100.csv\n",
      "10:07:11\tMASTER_LIST_CHIRPS_23100_23200.csv\n",
      "10:07:28\tMASTER_LIST_CHIRPS_23200_23300.csv\n",
      "10:07:38\tMASTER_LIST_CHIRPS_23300_23400.csv\n",
      "10:07:43\tMASTER_LIST_CHIRPS_23400_23500.csv\n",
      "10:07:46\tMASTER_LIST_CHIRPS_23500_23600.csv\n",
      "10:07:50\tMASTER_LIST_CHIRPS_23600_23700.csv\n",
      "10:07:53\tMASTER_LIST_CHIRPS_23700_23800.csv\n",
      "10:07:56\tMASTER_LIST_CHIRPS_23800_23900.csv\n",
      "10:07:59\tMASTER_LIST_CHIRPS_23900_24000.csv\n",
      "10:08:02\tMASTER_LIST_CHIRPS_24000_24100.csv\n",
      "10:08:05\tMASTER_LIST_CHIRPS_24100_24200.csv\n",
      "10:08:09\tMASTER_LIST_CHIRPS_24200_24300.csv\n",
      "10:08:12\tMASTER_LIST_CHIRPS_24300_24400.csv\n",
      "10:08:17\tMASTER_LIST_CHIRPS_24400_24500.csv\n",
      "10:08:22\tMASTER_LIST_CHIRPS_24500_24600.csv\n",
      "10:08:24\tMASTER_LIST_CHIRPS_24600_24700.csv\n",
      "10:08:27\tMASTER_LIST_CHIRPS_24700_24800.csv\n",
      "10:08:30\tMASTER_LIST_CHIRPS_24800_24900.csv\n",
      "10:08:34\tMASTER_LIST_CHIRPS_24900_25000.csv\n",
      "10:08:37\tMASTER_LIST_CHIRPS_25000_25100.csv\n",
      "10:08:40\tMASTER_LIST_CHIRPS_25100_25200.csv\n",
      "10:08:43\tMASTER_LIST_CHIRPS_25200_25300.csv\n",
      "10:08:45\tMASTER_LIST_CHIRPS_25300_25400.csv\n",
      "10:08:49\tMASTER_LIST_CHIRPS_25400_25500.csv\n",
      "10:08:51\tMASTER_LIST_CHIRPS_25500_25600.csv\n",
      "10:08:54\tMASTER_LIST_CHIRPS_25600_25700.csv\n",
      "10:08:56\tMASTER_LIST_CHIRPS_25700_25800.csv\n",
      "10:08:59\tMASTER_LIST_CHIRPS_25800_25900.csv\n",
      "10:09:02\tMASTER_LIST_CHIRPS_25900_26000.csv\n",
      "10:09:04\tMASTER_LIST_CHIRPS_26000_26100.csv\n",
      "10:09:07\tMASTER_LIST_CHIRPS_26100_26200.csv\n",
      "10:09:09\tMASTER_LIST_CHIRPS_26200_26300.csv\n",
      "10:09:12\tMASTER_LIST_CHIRPS_26300_26400.csv\n",
      "10:09:15\tMASTER_LIST_CHIRPS_26400_26500.csv\n",
      "10:09:17\tMASTER_LIST_CHIRPS_26500_26600.csv\n",
      "10:09:20\tMASTER_LIST_CHIRPS_26600_26700.csv\n",
      "10:09:23\tMASTER_LIST_CHIRPS_26700_26800.csv\n",
      "10:09:30\tMASTER_LIST_CHIRPS_26800_26900.csv\n",
      "10:09:48\tMASTER_LIST_CHIRPS_26900_27000.csv\n",
      "10:10:05\tMASTER_LIST_CHIRPS_27000_27100.csv\n",
      "10:10:13\tMASTER_LIST_CHIRPS_27100_27200.csv\n",
      "10:10:17\tMASTER_LIST_CHIRPS_27200_27300.csv\n",
      "10:10:20\tMASTER_LIST_CHIRPS_27300_27400.csv\n",
      "10:10:24\tMASTER_LIST_CHIRPS_27400_27500.csv\n",
      "10:10:27\tMASTER_LIST_CHIRPS_27500_27600.csv\n",
      "10:10:29\tMASTER_LIST_CHIRPS_27600_27700.csv\n",
      "10:10:33\tMASTER_LIST_CHIRPS_27700_27800.csv\n",
      "10:10:36\tMASTER_LIST_CHIRPS_27800_27900.csv\n",
      "10:10:39\tMASTER_LIST_CHIRPS_27900_28000.csv\n",
      "10:10:44\tMASTER_LIST_CHIRPS_28000_28100.csv\n",
      "10:10:46\tMASTER_LIST_CHIRPS_28100_28200.csv\n",
      "10:10:50\tMASTER_LIST_CHIRPS_28200_28300.csv\n",
      "10:10:53\tMASTER_LIST_CHIRPS_28300_28400.csv\n",
      "10:11:02\tMASTER_LIST_CHIRPS_28400_28500.csv\n",
      "10:11:16\tMASTER_LIST_CHIRPS_28500_28600.csv\n",
      "10:11:29\tMASTER_LIST_CHIRPS_28600_28700.csv\n",
      "10:11:41\tMASTER_LIST_CHIRPS_28700_28800.csv\n",
      "10:11:57\tMASTER_LIST_CHIRPS_28800_28900.csv\n",
      "10:12:13\tMASTER_LIST_CHIRPS_28900_29000.csv\n",
      "10:12:26\tMASTER_LIST_CHIRPS_29000_29100.csv\n",
      "10:12:39\tMASTER_LIST_CHIRPS_29100_29200.csv\n",
      "10:12:51\tMASTER_LIST_CHIRPS_29200_29300.csv\n",
      "10:13:05\tMASTER_LIST_CHIRPS_29300_29400.csv\n",
      "10:13:09\tMASTER_LIST_CHIRPS_29400_29500.csv\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(gee)\n",
    "step_count = 100\n",
    "steps = list(range(step_count, inD.shape[0], step_count))\n",
    "steps.append(inD.shape[0])\n",
    "start_idx = 0\n",
    "try:\n",
    "    del brokenD\n",
    "except:\n",
    "    pass\n",
    "for end_idx in steps:\n",
    "    curD = inD.iloc[start_idx:end_idx,]\n",
    "    out_file = os.path.join(chirps_folder, f'MASTER_LIST_CHIRPS_{start_idx}_{end_idx}.csv')\n",
    "    if not os.path.exists(out_file):\n",
    "        try:\n",
    "            tPrint(os.path.basename(out_file))\n",
    "            cur_ee = gpd_to_gee(curD, 'CVEGEO')\n",
    "            # Run analysis on just the L8 data\n",
    "            zs = gee.ZonalStats(collection_id = chirps_collection,\n",
    "                            target_features = cur_ee,\n",
    "                            statistic_type = \"sum\",\n",
    "                            output_name = '',\n",
    "                            scale=1000,\n",
    "                            min_threshold=0,\n",
    "                            water_mask=True,  \n",
    "                            frequency='monthly',\n",
    "                            temporal_stat='max',\n",
    "                            tile_scale = 16\n",
    "                           )\n",
    "            zonal_res = zs.runZonalStats()\n",
    "            res = zonal_res.getInfo()\n",
    "            pd_res = get_zonal_res(res)\n",
    "            pd_res[\"CVEGEO\"] = curD[\"CVEGEO\"].values\n",
    "            pd_res.to_csv(out_file)                        \n",
    "        except:\n",
    "            try:\n",
    "                brokenD = brokenD.append(curD)\n",
    "            except:\n",
    "                brokenD = curD\n",
    "            tPrint(f'***ERROR{os.path.basename(out_file)}')\n",
    "            break\n",
    "            pass\n",
    "    start_idx = end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_ee = gpd_to_gee(curD, 'CVEGEO')\n",
    "# Run analysis on just the L8 data\n",
    "zs = gee.ZonalStats(collection_id = chirps_collection,\n",
    "                target_features = cur_ee,\n",
    "                statistic_type = \"sum\",\n",
    "                output_name = '',\n",
    "                scale=1000,\n",
    "                min_threshold=0,\n",
    "                water_mask=True,  \n",
    "                frequency='monthly',\n",
    "                temporal_stat='max',\n",
    "                tile_scale = 16\n",
    "               )\n",
    "zonal_res = zs.runZonalStats()\n",
    "res = zonal_res.getInfo()\n",
    "pd_res = get_zonal_res(res)\n",
    "pd_res[\"CVEGEO\"] = curD[\"CVEGEO\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inR = rasterio.open(pop_file)\n",
    "\n",
    "res = rMisc.zonalStats(inD, inR, minVal=0)\n",
    "pop_res = pd.DataFrame(res, columns=['SUM','MIN','MAX','MEAN'])\n",
    "pop_res['CVEGEO'] = inD['CVEGEO']\n",
    "pop_res.to_csv(out_pop_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inR = rasterio.open(ghsl_file)\n",
    "inD = inD.to_crs(inR.crs)\n",
    "\n",
    "res = rMisc.zonalStats(inD, inR, rastType='C', unqVals = [1,2,3,4,5,6])\n",
    "ghsl_res = pd.DataFrame(res, columns = [f'c{x}' for x in [1,2,3,4,5,6]])\n",
    "ghsl_res['CVEGEO'] = inD['CVEGEO']\n",
    "ghsl_res.to_csv(out_ghsl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infrastructure Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urbanization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(local_pop):\n",
    "    rMisc.clipRaster(rasterio.open(pop_file), inD, local_pop)\n",
    "    \n",
    "inR = rasterio.open(local_pop)\n",
    "if inD.crs != inR.crs:\n",
    "    inD = inD.to_crs(inR.crs)\n",
    "    \n",
    "urb = UrbanRaster.urbanGriddedPop(local_pop)\n",
    "try:\n",
    "    urban_extents = urb.calculateUrban(densVal=300, totalPopThresh=5000, \n",
    "                                       smooth=False, queen=False, \n",
    "                                       raster=local_urban, raster_pop=local_urban_pop)\n",
    "    if not os.path.exists(urban_pop):\n",
    "        res = rMisc.zonalStats(inD, local_urban_pop, minVal=0)\n",
    "        pop_res = pd.DataFrame(res, columns=['SUM','MIN','MAX','MEAN'])\n",
    "        pop_res['CVEGEO'] = inD['CVEGEO']\n",
    "        pop_res.to_csv(urban_pop)\n",
    "    urban_extents.to_file(urban_extents_file)\n",
    "except:\n",
    "    print(\"Could not calculate urban popualtion\")\n",
    "try:\n",
    "    hd_extents =    urb.calculateUrban(densVal=1500, totalPopThresh=50000, \n",
    "                                   smooth=True, queen=True, \n",
    "                                   raster=local_urban_hd, raster_pop=local_urban_hdpop)\n",
    "    res = rMisc.zonalStats(inD, local_urban_hdpop, minVal=0)\n",
    "    pop_res = pd.DataFrame(res, columns=['SUM','MIN','MAX','MEAN'])\n",
    "    pop_res['CVEGEO'] = inD['CVEGEO']\n",
    "    pop_res.to_csv(hd_pop)\n",
    "    hd_extents.to_file(hd_urban_extents_file)\n",
    "except:\n",
    "    print(\"Could not calculate high density urban popualtion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_dests = gpd.read_file(urban_extents_file)\n",
    "urban_dests['geometry'] = urban_dests['geometry'].apply(lambda x: x.centroid)\n",
    "\n",
    "hd_urban_dests = gpd.read_file(hd_urban_extents_file)\n",
    "hd_urban_dests['geometry'] = hd_urban_dests['geometry'].apply(lambda x: x.centroid)\n",
    "\n",
    "if not os.path.exists(local_access_map):\n",
    "    inD = gpd.read_file(master_agebs)\n",
    "    inD_bounds = gpd.GeoDataFrame(pd.DataFrame([[1,box(*inD.total_bounds)]], \n",
    "                                               columns=['id','geometry']), \n",
    "                                               geometry=\"geometry\", crs=inD.crs)\n",
    "    rMisc.clipRaster(rasterio.open(global_access_map), inD_bounds, local_access_map)\n",
    "    \n",
    "inR = rasterio.open(local_access_map)\n",
    "frictionD = inR.read()[0,:,:] * 1000\n",
    "mcp = graph.MCP_Geometric(frictionD)\n",
    "\n",
    "travel_costs, traceback = ma.calculate_travel_time(inR, mcp, urban_dests, urban_access)\n",
    "travel_costs, traceback = ma.calculate_travel_time(inR, mcp, hd_urban_dests, hd_urban_access)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize population to market access\n",
    "inR1 = rasterio.open(local_pop)\n",
    "inR2 = rasterio.open(urban_access)\n",
    "\n",
    "sPop, metadata = rMisc.standardizeInputRasters(inR1, inR2)\n",
    "access_data = inR2.read()\n",
    "pop_access = sPop * access_data\n",
    "\n",
    "with rMisc.create_rasterio_inmemory(metadata, pop_access) as pop_access_R:\n",
    "    res = rMisc.zonalStats(inD, pop_access_R, minVal=0)\n",
    "    res = pd.DataFrame(res, columns=['SUM','MIN','MAX','MEAN'])\n",
    "    \n",
    "pop_stats = pd.read_csv(out_pop_summaries)\n",
    "res['urban_access'] = res['SUM']/pop_stats['SUM']\n",
    "res.to_csv(urban_access_res)\n",
    "\n",
    "inR2 = rasterio.open(hd_urban_access)\n",
    "access_data = inR2.read()\n",
    "pop_access = sPop * access_data\n",
    "\n",
    "with rMisc.create_rasterio_inmemory(metadata, pop_access) as pop_access_R:\n",
    "    res = rMisc.zonalStats(inD, pop_access_R, minVal=0)\n",
    "    res = pd.DataFrame(res, columns=['SUM','MIN','MAX','MEAN'])\n",
    "    \n",
    "pop_stats = pd.read_csv(out_pop_summaries)\n",
    "res['urban_access'] = res['SUM']/pop_stats['SUM']\n",
    "res.to_csv(hd_urban_access_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nighttime Lights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of the VIIRS images in S3. This example leverages the GOST teams S3 bucket\n",
    "s3_base = 's3://wbgdecinternal-ntl/'\n",
    "ntl_file_list = \"/home/wb411133/temp/YEM/AWS_NTL_S3.txt\"\n",
    "focal_tile = \"TILE1\"\n",
    "\n",
    "all_files = []\n",
    "with open(ntl_file_list, 'r') as in_aws:\n",
    "    for line in in_aws:\n",
    "        if focal_tile in line and 'avg_rade9' in line:\n",
    "            all_files.append(os.path.join(s3_base, line.split(\" \")[-1][:-1]))\n",
    "            \n",
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run zonal statistics against the admin area\n",
    "for cur_tif in all_files:\n",
    "    res = rMisc.zonalStats(inD, cur_tif, minVal=0.05)\n",
    "    res = pd.DataFrame(res,columns=['SUM','MIN','MAX','MEAN'])\n",
    "    inD[cur_tif.split(\"/\")[5]] = res['SUM']\n",
    "    tPrint(os.path.basename(cur_tif))\n",
    "    \n",
    "ntl_res = pd.DataFrame(inD.drop(['geometry'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntl_res.to_csv(ntl_zonal_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Earth Engine",
   "language": "python",
   "name": "ee"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
