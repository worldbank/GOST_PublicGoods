{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Administrative summaries\n",
    "\n",
    "In this notebook, we will import and manipulate the OD matrix - which should have been calculated separately in the previous steps. We assume this has been done, and in turn, that the relevant OD matrix files are under the \"result\" folder in a sbufolder labeled by the data production date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import os, sys, time\n",
    "import importlib\n",
    "# importlib.reload(gn)\n",
    "\n",
    "# Data tools\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import geopandas as gpd\n",
    "\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from shapely.wkt import loads\n",
    "from shapely import wkt\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "# charting tools\n",
    "\n",
    "import palettable\n",
    "from functools import reduce\n",
    "from plotnine import *\n",
    "from mizani.formatters import percent_format\n",
    "\n",
    "# printing dicts in easy to read fashion\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplif_meters = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_epsg = 4326\n",
    "target_epsg = 3106"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario = 'Current'\n",
    "scenario = 'Padma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production date for outputs being used\n",
    "\n",
    "# prod_date = '210312'\n",
    "prod_date = '210329'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WorldPop data determinants\n",
    "\n",
    "constraint_status = 'constrained'\n",
    "# constraint_status = 'unconstrained'\n",
    "wp_res = 100\n",
    "# wp_res = 250\n",
    "# wp_res = '1k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set path locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pth = r'inputs'\n",
    "chart_pth = r'charts'\n",
    "fin_pth = r'final'\n",
    "res_pth = r'results'\n",
    "res_prod_pth = f'results\\\\{prod_date}'\n",
    "table_pth = r'tables'\n",
    "\n",
    "adm_pth = r'../../../GEO/Boundaries'\n",
    "geo_pth = r'../../../GEO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make final prod_date subfolder\n",
    "\n",
    "if not os.path.exists(os.path.join(fin_pth,prod_date)):\n",
    "    os.makedirs(os.path.join(fin_pth,prod_date))\n",
    "\n",
    "# make results prod_date folder\n",
    "\n",
    "if not os.path.exists(os.path.join(res_pth,prod_date)):\n",
    "    os.makedirs(os.path.join(res_pth,prod_date))\n",
    "    os.makedirs(os.path.join(res_pth,prod_date,'spatial'))\n",
    "    os.makedirs(os.path.join(res_pth,prod_date,'tables'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in admin data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load admin spatial data\n",
    "\n",
    "adm2 = gpd.read_file(os.path.join(geo_pth,'Boundaries/bd_adm_bbs.gpkg'),layer='bd_adm2_wgs84')\n",
    "adm2.crs = 'epsg:4326'\n",
    "\n",
    "adm3 = gpd.read_file(os.path.join(geo_pth,'Boundaries/bd_adm_bbs.gpkg'),layer='bd_adm3_wgs84')\n",
    "adm3.crs = 'epsg:4326'\n",
    "\n",
    "adm4 = gpd.read_file(os.path.join(geo_pth,'Boundaries/bd_adm_bbs.gpkg'),layer='bd_adm4_wgs84')\n",
    "adm4.crs = 'epsg:4326'\n",
    "\n",
    "adm5 = gpd.read_file(os.path.join(geo_pth,'Boundaries/bd_adm_bbs.gpkg'),layer='bd_adm5_wgs84')\n",
    "adm5.crs = 'epsg:4326'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix types for later joining\n",
    "adm2['adm2_pcode'] = adm2['adm2_pcode'].astype(str)\n",
    "adm3['adm3_pcode'] = adm3['adm3_pcode'].astype(str)\n",
    "adm4['adm4_pcode'] = adm4['adm4_pcode'].astype(str)\n",
    "adm5['adm5_pcode'] = adm5['adm5_pcode'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm3['adm3_en'] = adm3['adm3_en'].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dest list for looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dests = [\"All_cities\",\"Dhaka_Chitt\",\"Minor_cities\",\\\n",
    "         \"Dry_ports\",\"River_ports\",\"Deep_sea_ports\",\\\n",
    "         \"All_SEZs\",\"Active_SEZs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare OD data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in all the OD matrices for all scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pop_Origins_dct = {}\n",
    "City_Origins_dct = {}\n",
    "All_SEZ_Origins_dct = {}\n",
    "Active_SEZ_Origins_dct = {}\n",
    "\n",
    "for dest in dests:\n",
    "\n",
    "    # DFs\n",
    "    PO_df = f'final_od_grid_{scenario}_{dest}_PopOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "    CO_df = f'final_od_grid_{scenario}_{dest}_CityOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "    AllSEZ_df = f'final_od_grid_{scenario}_{dest}_All_SEZ_Origins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "    ActSEZ_df = f'final_od_grid_{scenario}_{dest}_Active_SEZ_Origins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "\n",
    "    # Key strings\n",
    "    PO_str = scenario + '_PopOrigins_' + dest\n",
    "    CO_str = scenario + '_CityOrigins_' + dest\n",
    "    AllSEZ_str = scenario + '_All_SEZ_Origins_' + dest\n",
    "    ActSEZ_str = scenario + '_Act_SEZ_Origins_' + dest\n",
    "\n",
    "    # Load into dcts\n",
    "    Pop_Origins_dct[PO_str] = PO_df\n",
    "    City_Origins_dct[CO_str] = CO_df\n",
    "    All_SEZ_Origins_dct[AllSEZ_str] = AllSEZ_df\n",
    "    Active_SEZ_Origins_dct[ActSEZ_str] = ActSEZ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Padma_PopOrigins_Active_SEZs': 'final_od_grid_Padma_Active_SEZs_PopOrigins_constrained_100m_res_25m_simplification.csv',\n",
      " 'Padma_PopOrigins_All_SEZs': 'final_od_grid_Padma_All_SEZs_PopOrigins_constrained_100m_res_25m_simplification.csv',\n",
      " 'Padma_PopOrigins_All_cities': 'final_od_grid_Padma_All_cities_PopOrigins_constrained_100m_res_25m_simplification.csv',\n",
      " 'Padma_PopOrigins_Deep_sea_ports': 'final_od_grid_Padma_Deep_sea_ports_PopOrigins_constrained_100m_res_25m_simplification.csv',\n",
      " 'Padma_PopOrigins_Dhaka_Chitt': 'final_od_grid_Padma_Dhaka_Chitt_PopOrigins_constrained_100m_res_25m_simplification.csv',\n",
      " 'Padma_PopOrigins_Dry_ports': 'final_od_grid_Padma_Dry_ports_PopOrigins_constrained_100m_res_25m_simplification.csv',\n",
      " 'Padma_PopOrigins_Minor_cities': 'final_od_grid_Padma_Minor_cities_PopOrigins_constrained_100m_res_25m_simplification.csv',\n",
      " 'Padma_PopOrigins_River_ports': 'final_od_grid_Padma_River_ports_PopOrigins_constrained_100m_res_25m_simplification.csv'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(Pop_Origins_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_PopOrig_all_cities = f'final_od_grid_{scenario}_All_cities_PopOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_PopOrig_minor_cities = f'final_od_grid_{scenario}_Minor_cities_PopOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_PopOrig_DhakaChitt = f'final_od_grid_{scenario}_Dhaka_Chitt_PopOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_PopOrig_dry_ports = f'final_od_grid_{scenario}_Dry_ports_PopOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_PopOrig_river_ports = f'final_od_grid_{scenario}_River_ports_PopOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_PopOrig_deep_sea_ports = f'final_od_grid_{scenario}_Deep_sea_ports_PopOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_PopOrig_all_SEZs = f'final_od_grid_{scenario}_Active_SEZs_PopOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_PopOrig_Active_SEZs = f'final_od_grid_{scenario}_All_SEZs_PopOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "\n",
    "# current_CityOrig_all_cities = f'final_od_grid_{scenario}_All_cities_CityOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_CityOrig_minor_cities = f'final_od_grid_{scenario}_Minor_cities_CityOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_CityOrig_DhakaChitt = f'final_od_grid_{scenario}_Dhaka_Chitt_CityOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_CityOrig_dry_ports = f'final_od_grid_{scenario}_Dry_ports_CityOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_CityOrig_river_ports = f'final_od_grid_{scenario}_River_ports_CityOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_CityOrig_deep_sea_ports = f'final_od_grid_{scenario}_Deep_sea_ports_CityOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_CityOrig_all_SEZs = f'final_od_grid_{scenario}_Active_SEZs_CityOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'\n",
    "# current_CityOrig_Active_SEZs = f'final_od_grid_{scenario}_All_SEZs_CityOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop_Origins_dct = {'current_PopOrig_All_cities' : current_PopOrig_all_cities, \\\n",
    "#                 'current_PopOrig_Minor_cities' : current_PopOrig_minor_cities, \\\n",
    "#                 'current_PopOrig_DhakaChitt' : current_PopOrig_DhakaChitt, \\\n",
    "#                 'current_PopOrig_Dry_ports' : current_PopOrig_dry_ports,  \\\n",
    "#                 'current_PopOrig_River_ports' : current_PopOrig_river_ports,  \\\n",
    "#                 'current_PopOrig_Deep_sea_ports' : current_PopOrig_deep_sea_ports, \\\n",
    "#                 'current_PopOrig_All_SEZs' : current_PopOrig_all_SEZs,  \\\n",
    "#                 'current_PopOrig_Active_SEZs' : current_PopOrig_Active_SEZs }\n",
    "\n",
    "# City_Origins_dct = {'current_CityOrig_All_cities' : current_CityOrig_all_cities, \\\n",
    "#                 'current_CityOrig_Minor_cities' : current_CityOrig_minor_cities, \\\n",
    "#                 'current_CityOrig_DhakaChitt' : current_CityOrig_DhakaChitt, \\\n",
    "#                 'current_CityOrig_Dry_ports' : current_CityOrig_dry_ports,  \\\n",
    "#                 'current_CityOrig_River_ports' : current_CityOrig_river_ports,  \\\n",
    "#                 'current_CityOrig_Deep_sea_ports' : current_CityOrig_deep_sea_ports, \\\n",
    "#                 'current_CityOrig_All_SEZs' : current_CityOrig_all_SEZs,  \\\n",
    "#                 'current_CityOrig_Active_SEZs' : current_CityOrig_Active_SEZs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic data loading and manipuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Origins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the WorldPop data from one output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_orig_pts = pd.read_csv(os.path.join(fin_pth, prod_date,\\\n",
    "                                        f'final_od_grid_{scenario}_All_cities_PopOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'))\n",
    "\n",
    "pop_orig_pts = pop_orig_pts[['O_ID','Row_ID','VALUE','geometry']]\n",
    "pop_orig_pts['geometry'] = pop_orig_pts['geometry'].apply(wkt.loads)\n",
    "pop_orig_pts.set_geometry('geometry')\n",
    "pop_orig_gdf = gpd.GeoDataFrame(pop_orig_pts,crs = 'epsg:4326')\n",
    "# pop_orig_gdf = pop_orig_gdf.to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_orig_pts = pd.read_csv(os.path.join(fin_pth, prod_date,\\\n",
    "#                                         f'final_od_grid_{scenario}_All_cities_CityOrigins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'))\n",
    "\n",
    "# city_orig_pts = city_orig_pts[['O_ID','Row_ID','Pop_all_2011','Pop_all_2021','geometry']]\n",
    "# city_orig_pts['geometry'] = city_orig_pts['geometry'].apply(wkt.loads)\n",
    "# city_orig_pts.set_geometry('geometry')\n",
    "# city_orig_gdf = gpd.GeoDataFrame(city_orig_pts,crs = 'epsg:3106')\n",
    "# city_orig_gdf = city_orig_gdf.to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_SEZ_orig_pts = pd.read_csv(os.path.join(fin_pth, prod_date,\\\n",
    "                                        f'final_od_grid_{scenario}_All_cities_All_SEZ_Origins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'))\n",
    "\n",
    "All_SEZ_orig_pts = All_SEZ_orig_pts[['O_ID','Row_ID','VALUE','geometry']]\n",
    "All_SEZ_orig_pts['geometry'] = All_SEZ_orig_pts['geometry'].apply(wkt.loads)\n",
    "All_SEZ_orig_pts.set_geometry('geometry')\n",
    "All_SEZ_orig_gdf = gpd.GeoDataFrame(All_SEZ_orig_pts,crs = 'epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Active_SEZ_orig_pts = pd.read_csv(os.path.join(fin_pth, prod_date,\\\n",
    "                                        f'final_od_grid_{scenario}_All_cities_Active_SEZ_Origins_{constraint_status}_{wp_res}m_res_{simplif_meters}m_simplification.csv'))\n",
    "\n",
    "Active_SEZ_orig_pts = Active_SEZ_orig_pts[['O_ID','Row_ID','VALUE','geometry']]\n",
    "Active_SEZ_orig_pts['geometry'] = Active_SEZ_orig_pts['geometry'].apply(wkt.loads)\n",
    "Active_SEZ_orig_pts.set_geometry('geometry')\n",
    "Active_SEZ_orig_gdf = gpd.GeoDataFrame(Active_SEZ_orig_pts,crs = 'epsg:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all scenario layers onto single origin gdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidate_to_origins(orig_fil,dct_key,dct_lyr):\n",
    "\n",
    "    print(dct_key)\n",
    "\n",
    "    # read in the CSVs, convert to geometry\n",
    "\n",
    "    nn_lyr = pd.read_csv(os.path.join(fin_pth,prod_date,dct_lyr))\n",
    "    \n",
    "    # create a dict from the Row_ID and the TT to the nearest node, then map that to the origins file\n",
    "    \n",
    "    temp_mins_dct = dict(zip(nn_lyr.Row_ID,nn_lyr.PLOT_TIME_MINS))\n",
    "    orig_fil[f'{dct_key}_mins'] = orig_fil['Row_ID'].map(temp_mins_dct)\n",
    "\n",
    "    \n",
    "def NN_adm_aggregates(orig_fil,dct_key):\n",
    "\n",
    "#     # Start timer\n",
    "#     func_start = time.time()\n",
    "    \n",
    "    print(dct_key)\n",
    "    \n",
    "    # calculate other admin pcodes from adm5\n",
    "\n",
    "    orig_fil['adm1_pcode'] = orig_fil['adm4_pcode'].str[0:2]\n",
    "    orig_fil['adm2_pcode'] = orig_fil['adm4_pcode'].str[0:4]\n",
    "    orig_fil['adm3_pcode'] = orig_fil['adm4_pcode'].str[0:6]\n",
    "\n",
    "    # weight accessibility info by population\n",
    "\n",
    "    orig_fil['adm2_pop'] = orig_fil[orig_fil[f'{dct_key}_mins'] < 150000].groupby('adm2_pcode')['VALUE'].transform(np.nansum)\n",
    "    orig_fil['adm3_pop'] = orig_fil[orig_fil[f'{dct_key}_mins'] < 150000].groupby('adm3_pcode')['VALUE'].transform(np.nansum)\n",
    "    orig_fil['adm4_pop'] = orig_fil[orig_fil[f'{dct_key}_mins'] < 150000].groupby('adm4_pcode')['VALUE'].transform(np.nansum)\n",
    "    orig_fil['adm5_pop'] = orig_fil[orig_fil[f'{dct_key}_mins'] < 150000].groupby('adm5_pcode')['VALUE'].transform(np.nansum)\n",
    "\n",
    "    orig_fil[f'{dct_key}_mins_WT_adm2'] = (orig_fil[f'{dct_key}_mins'] * (orig_fil['VALUE'] / orig_fil['adm2_pop']))\n",
    "    orig_fil[f'{dct_key}_mins_WT_adm3'] = (orig_fil[f'{dct_key}_mins'] * (orig_fil['VALUE'] / orig_fil['adm3_pop']))\n",
    "    orig_fil[f'{dct_key}_mins_WT_adm4'] = (orig_fil[f'{dct_key}_mins'] * (orig_fil['VALUE'] / orig_fil['adm4_pop']))\n",
    "    orig_fil[f'{dct_key}_mins_WT_adm5'] = (orig_fil[f'{dct_key}_mins'] * (orig_fil['VALUE'] / orig_fil['adm5_pop']))\n",
    "\n",
    "#     # Report time\n",
    "\n",
    "#     func_end = time.time()\n",
    "#     print('time elapsed for aggregation function')\n",
    "#     print(str((func_end - func_start) / 60) + ' minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process and export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padma_PopOrigins_All_cities\n",
      "Padma_PopOrigins_Dhaka_Chitt\n",
      "Padma_PopOrigins_Minor_cities\n",
      "Padma_PopOrigins_Dry_ports\n",
      "Padma_PopOrigins_River_ports\n",
      "Padma_PopOrigins_Deep_sea_ports\n",
      "Padma_PopOrigins_All_SEZs\n",
      "Padma_PopOrigins_Active_SEZs\n",
      "Padma_PopOrigins_All_cities\n",
      "Padma_PopOrigins_Dhaka_Chitt\n",
      "Padma_PopOrigins_Minor_cities\n",
      "Padma_PopOrigins_Dry_ports\n",
      "Padma_PopOrigins_River_ports\n",
      "Padma_PopOrigins_Deep_sea_ports\n",
      "Padma_PopOrigins_All_SEZs\n",
      "Padma_PopOrigins_Active_SEZs\n"
     ]
    }
   ],
   "source": [
    "# iterate through the dict\n",
    "\n",
    "for key, layer in Pop_Origins_dct.items():\n",
    "    consolidate_to_origins(orig_fil=pop_orig_gdf,dct_key=key,dct_lyr=layer)\n",
    "    \n",
    "# spatial join admin information\n",
    "\n",
    "pop_orig_gdf = gpd.sjoin(pop_orig_gdf,adm5[['geometry','adm5_pcode']],op=\"within\")\n",
    "pop_orig_gdf = pop_orig_gdf.drop('index_right',axis=1)\n",
    "pop_orig_gdf = gpd.sjoin(pop_orig_gdf,adm4[['geometry','adm4_pcode']],op=\"within\") # codes in adm4 and adm5 differ in critical places so must be joined in\n",
    "pop_orig_gdf = pop_orig_gdf.drop('index_right',axis=1)\n",
    "\n",
    "# Aggregate by admin level \n",
    "\n",
    "for key in Pop_Origins_dct.keys():\n",
    "    NN_adm_aggregates(orig_fil=pop_orig_gdf,dct_key=key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padma_All_SEZ_Origins_All_cities\n",
      "Padma_All_SEZ_Origins_Dhaka_Chitt\n",
      "Padma_All_SEZ_Origins_Minor_cities\n",
      "Padma_All_SEZ_Origins_Dry_ports\n",
      "Padma_All_SEZ_Origins_River_ports\n",
      "Padma_All_SEZ_Origins_Deep_sea_ports\n",
      "Padma_All_SEZ_Origins_All_SEZs\n",
      "Padma_All_SEZ_Origins_Active_SEZs\n",
      "Padma_Act_SEZ_Origins_All_cities\n",
      "Padma_Act_SEZ_Origins_Dhaka_Chitt\n",
      "Padma_Act_SEZ_Origins_Minor_cities\n",
      "Padma_Act_SEZ_Origins_Dry_ports\n",
      "Padma_Act_SEZ_Origins_River_ports\n",
      "Padma_Act_SEZ_Origins_Deep_sea_ports\n",
      "Padma_Act_SEZ_Origins_All_SEZs\n",
      "Padma_Act_SEZ_Origins_Active_SEZs\n"
     ]
    }
   ],
   "source": [
    "# iterate through the dict to consolidate travel stats per origin\n",
    "\n",
    "# for key, layer in City_Origins_dct.items():\n",
    "#     consolidate_to_origins(orig_fil=city_orig_gdf,dct_key=key,dct_lyr=layer)\n",
    "\n",
    "for key, layer in All_SEZ_Origins_dct.items():\n",
    "    consolidate_to_origins(orig_fil=All_SEZ_orig_gdf,dct_key=key,dct_lyr=layer)\n",
    "\n",
    "for key, layer in Active_SEZ_Origins_dct.items():\n",
    "    consolidate_to_origins(orig_fil=Active_SEZ_orig_gdf,dct_key=key,dct_lyr=layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_orig_gdf.to_file(os.path.join(res_prod_pth,'spatial',f'{scenario}_origins_{wp_res}m_TTs.gpkg'),layer=f\"CityOrigins\",driver='GPKG',OVERWRITE=YES)\n",
    "All_SEZ_orig_gdf.to_file(os.path.join(res_prod_pth,'spatial',f'{scenario}_origins_{wp_res}m_TTs.gpkg'),layer=f\"All_SEZ_Origins\",driver='GPKG')\n",
    "Active_SEZ_orig_gdf.to_file(os.path.join(res_prod_pth,'spatial',f'{scenario}_origins_{wp_res}m_TTs.gpkg'),layer=f\"Active_SEZ_Origins\",driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_orig_gdf.to_file(os.path.join(res_prod_pth,'spatial',f'{scenario}_origins_{wp_res}m_TTs.gpkg'),layer=f\"PopOrigins\",driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Administrative aggregates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Population weighting origin grid data by admin and then summarizing per admin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate and weight indicators by admin unit using WorldPop Origins\n",
    "\n",
    "for key in Pop_Origins_dct.keys():\n",
    "\n",
    "#     # Start timer\n",
    "    \n",
    "#     func_start = time.time()\n",
    "\n",
    "    # define variable for avg_time naming\n",
    "    \n",
    "    at = (key + '_avg_time')\n",
    "    \n",
    "    # adm2\n",
    "    \n",
    "    zila = pop_orig_gdf[pop_orig_gdf[f'{key}_mins'] < 150000].groupby(['adm2_pcode']).agg(\n",
    "        at = (f'{key}_mins_WT_adm2',np.nansum),    ) \n",
    "    \n",
    "    zila = zila.rename(columns={'at' : at}).reset_index()\n",
    "    zila['adm2_pcode'] = zila['adm2_pcode'].astype(str)\n",
    "    zila = zila[['adm2_pcode',at]]\n",
    "    \n",
    "    adm2 = pd.merge(adm2,zila,how='left',on=['adm2_pcode'])\n",
    "    \n",
    "    # adm3\n",
    "    \n",
    "    upz = pop_orig_gdf[pop_orig_gdf[f'{key}_mins'] < 150000].groupby(['adm3_pcode']).agg(\n",
    "        at = (f'{key}_mins_WT_adm3',np.nansum),    ) \n",
    "    \n",
    "    upz = upz.rename(columns={'at' : at}).reset_index()\n",
    "    upz['adm3_pcode'] = upz['adm3_pcode'].astype(str)\n",
    "    upz = upz[['adm3_pcode',at]]\n",
    "    \n",
    "    adm3 = pd.merge(adm3,upz,how='left',on=['adm3_pcode'])\n",
    "\n",
    "    # adm4\n",
    "    \n",
    "    union = pop_orig_gdf[pop_orig_gdf[f'{key}_mins'] < 150000].groupby(['adm4_pcode']).agg(\n",
    "        at = (f'{key}_mins_WT_adm4',np.nansum),    ) \n",
    "    \n",
    "    union = union.rename(columns={'at' : at}).reset_index()\n",
    "    union['adm4_pcode'] = union['adm4_pcode'].astype(str)\n",
    "    union = union[['adm4_pcode',at]]\n",
    "    \n",
    "    adm4 = pd.merge(adm4,union,how='left',on=['adm4_pcode'])  \n",
    "\n",
    "    # adm5\n",
    "    \n",
    "    mauza = pop_orig_gdf[pop_orig_gdf[f'{key}_mins'] < 150000].groupby(['adm5_pcode']).agg(\n",
    "        at = (f'{key}_mins_WT_adm5',np.nansum),    ) \n",
    "    \n",
    "    mauza = mauza.rename(columns={'at' : at}).reset_index()\n",
    "    mauza['adm5_pcode'] = mauza['adm5_pcode'].astype(str)\n",
    "    mauza = mauza[['adm5_pcode',at]]\n",
    "    \n",
    "    adm5 = pd.merge(adm5,mauza,how='left',on=['adm5_pcode'])\n",
    "\n",
    "#     # Report function time\n",
    "    \n",
    "#     func_end = time.time()\n",
    "#     print(f'time elapsed for summing {key}')\n",
    "#     print(str((func_end - func_start) / 60) + ' minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export resulting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm2.loc[:, adm2.columns != 'geometry'].to_csv(os.path.join(f'results/{prod_date}/tables/adm2_{scenario}_{constraint_status}_{wp_res}m_res.csv'))\n",
    "adm3.loc[:, adm3.columns != 'geometry'].to_csv(os.path.join(f'results/{prod_date}/tables/adm3_{scenario}_{constraint_status}_{wp_res}m_res.csv'))\n",
    "adm4.loc[:, adm4.columns != 'geometry'].to_csv(os.path.join(f'results/{prod_date}/tables/adm4_{scenario}_{constraint_status}_{wp_res}m_res.csv'))\n",
    "adm5.loc[:, adm5.columns != 'geometry'].to_csv(os.path.join(f'results/{prod_date}/tables/adm5_{scenario}_{constraint_status}_{wp_res}m_res.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adm2.to_file(os.path.join(res_prod_pth,f'spatial/adm2_{constraint_status}_{wp_res}m_res.shp'))\n",
    "# adm3.to_file(os.path.join(res_prod_pth,f'spatial/adm3_{constraint_status}_{wp_res}m_res.shp'))\n",
    "# adm4.to_file(os.path.join(res_prod_pth,f'spatial/adm4_{constraint_status}_{wp_res}m_res.shp'))\n",
    "# adm5.to_file(os.path.join(res_prod_pth,f'spatial/adm5_{constraint_status}_{wp_res}m_res.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm2.to_file(os.path.join(res_prod_pth,f'spatial/adm_{scenario}_{constraint_status}_{wp_res}m_res.gpkg'),layer='adm2',driver='GPKG')\n",
    "adm3.to_file(os.path.join(res_prod_pth,f'spatial/adm_{scenario}_{constraint_status}_{wp_res}m_res.gpkg'),layer='adm3',driver='GPKG')\n",
    "adm4.to_file(os.path.join(res_prod_pth,f'spatial/adm_{scenario}_{constraint_status}_{wp_res}m_res.gpkg'),layer='adm4',driver='GPKG')\n",
    "adm5.to_file(os.path.join(res_prod_pth,f'spatial/adm_{scenario}_{constraint_status}_{wp_res}m_res.gpkg'),layer='adm5',driver='GPKG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
