{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peartree version: 0.6.1 \n",
      "networkx version: 2.3 \n",
      "matplotlib version: 3.0.3 \n",
      "osmnx version: 0.9 \n"
     ]
    }
   ],
   "source": [
    "# Get some libs in your life\n",
    "import sys, os, time\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import rasterio as rt\n",
    "import numpy as np\n",
    "from affine import Affine\n",
    "from shapely.geometry import Point, LineString\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import box\n",
    "from shapely.wkt import loads\n",
    "from rasterio import features\n",
    "import networkx as nx\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST_PublicGoods\\GOSTNets\\GOSTNets')\n",
    "sys.path.append(r'C:\\Users\\charl\\Documents\\GitHub\\GOST')\n",
    "import GOSTnet as gn\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Graph Read In"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpth = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\graphtool'\n",
    "G = nx.read_gpickle(os.path.join(bpth, 'G_salty_time_conflict_adj.pickle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk all tiles, find path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\SRTM\\high_res'\n",
    "tiles = []\n",
    "for root, folder, files in os.walk(pth):\n",
    "    for f in files:\n",
    "        if f[-3:] == 'hgt':\n",
    "            tiles.append(f[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dictionary of tiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrs = {}\n",
    "for t in tiles:\n",
    "    fpath = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\SRTM\\high_res\\{}.hgt\\{}.hgt'.format(t, t)\n",
    "    arrs[t] = rt.open(fpath, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add correct tile for each node into Graph Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = []\n",
    "for u, data in G.nodes(data = True):\n",
    "    E = str(data['x'])[:2]\n",
    "    N = str(data['y'])[:2]\n",
    "    data['code'] = 'N{}E0{}'.format(N, E)\n",
    "    uniques.append('N{}E0{}'.format(N, E))\n",
    "unique_codes = list(set(uniques))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match on High Precision Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_name = 'elevation'\n",
    "for code in unique_codes:\n",
    "    list_of_nodes = {}\n",
    "    for u, data in G.nodes(data=True):\n",
    "        if data['code'] == code:\n",
    "            list_of_nodes.update({u:(data['x'], data['y'])})\n",
    "    dataset = arrs[code]\n",
    "    b = dataset.bounds\n",
    "    datasetBoundary = box(b[0], b[1], b[2], b[3])\n",
    "    selKeys = []\n",
    "    selPts = []\n",
    "    for key, pt in list_of_nodes.items():\n",
    "        if Point(pt[0], pt[1]).intersects(datasetBoundary):\n",
    "            selPts.append(pt)\n",
    "            selKeys.append(key)\n",
    "    raster_values = list(dataset.sample(selPts))\n",
    "    raster_values = [x[0] for x in raster_values]\n",
    "\n",
    "    # generate new dictionary of {node ID: raster values}\n",
    "    ref = dict(zip(selKeys, raster_values))\n",
    "    for u, data in G.nodes(data=True):\n",
    "        if u in ref.keys():\n",
    "            data[property_name] = ref[u]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add on low precision elevation for missed nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u, data in G.nodes(data=True):\n",
    "    if data['elevation'] < -50:\n",
    "        list_of_nodes.update({u:(data['x'], data['y'])})\n",
    "        \n",
    "tifpath = r'C:\\Users\\charl\\Documents\\GOST\\Yemen\\SRTM\\clipped'\n",
    "t = r'clipped_e20N40.tif'\n",
    "tt = os.path.join(tifpath, t)\n",
    "dataset = rt.open(tt, 'r')\n",
    "b = dataset.bounds\n",
    "datasetBoundary = box(b[0], b[1], b[2], b[3])\n",
    "selKeys = []\n",
    "selPts = []\n",
    "for key, pt in list_of_nodes.items():\n",
    "    if Point(pt[0], pt[1]).intersects(datasetBoundary):\n",
    "        selPts.append(pt)\n",
    "        selKeys.append(key)\n",
    "raster_values = list(dataset.sample(selPts))\n",
    "raster_values = [x[0] for x in raster_values]\n",
    "\n",
    "# generate new dictionary of {node ID: raster values}\n",
    "ref = dict(zip(selKeys, raster_values))\n",
    "for u, data in G.nodes(data=True):\n",
    "    if u in ref.keys():\n",
    "        data['elevation'] = ref[u]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the remaining mistakes, set elevation to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u, data in G.nodes(data=True):\n",
    "    if data['elevation'] < 0:\n",
    "        data['elevation'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dictionary of elevations for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elev_dict = {}\n",
    "for u, data in G.nodes(data = True):\n",
    "    if 'elevation' in data.keys(): \n",
    "        if data['elevation'] < 0:\n",
    "            elev_dict[u] = 0\n",
    "        else:\n",
    "            elev_dict[u] = data['elevation']\n",
    "    else:\n",
    "        elev_dict[u] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3652, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sense check - max and minimum elevationr recorded\n",
    "max(list(elev_dict.values())), min(list(elev_dict.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate New Walking Data in existing edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tobler's hiking function: https://en.wikipedia.org/wiki/Tobler%27s_hiking_function\n",
    "def speed(incline_ratio, max_speed):\n",
    "    walkspeed = max_speed * np.exp(-3.5 * abs(incline_ratio + 0.05)) \n",
    "    return walkspeed\n",
    "\n",
    "max_walkspeed = 6\n",
    "min_speed = 0.1\n",
    "\n",
    "for u, v, data in G.edges(data = True):\n",
    "    data['elev_start'] = elev_dict[u]\n",
    "    data['elev_end'] = elev_dict[v]\n",
    "    if data['length'] == 0:\n",
    "        data['walkspeed'] = 0\n",
    "        data['walk_time'] = 0\n",
    "    else:\n",
    "        delta_elevation = data['elev_end'] - data['elev_start']\n",
    "        incline_ratio = delta_elevation / data['length']\n",
    "        speed_kmph = speed(incline_ratio = incline_ratio, max_speed = max_walkspeed)\n",
    "        speed_kmph = max(speed_kmph, min_speed)\n",
    "        data['walkspeed'] = speed_kmph\n",
    "        data['walk_time'] = data['length'] / 1000 * 3600 / speed_kmph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gn.save(G, 'walk_graph', bpth, nodes = False, edges = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Cfox2)",
   "language": "python",
   "name": "cfox2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
